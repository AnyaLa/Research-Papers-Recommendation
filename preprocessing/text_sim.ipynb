{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from stop_words import get_stop_words\n",
    "stopwords = get_stop_words('english') \n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = pd.read_csv('papers_with_abstract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03-1062</td>\n",
       "      <td>This paper describes the NECA MNLG;\\r\\r\\na ful...</td>\n",
       "      <td>15690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06-1001</td>\n",
       "      <td>I propose a uniform approach to the elim-\\r\\r\\...</td>\n",
       "      <td>28328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06-1002</td>\n",
       "      <td>We present a new method for detecting and\\r\\r\\...</td>\n",
       "      <td>33424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1003</td>\n",
       "      <td>We present a weakly supervised approach\\r\\r\\nt...</td>\n",
       "      <td>31859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06-1004</td>\n",
       "      <td>In this paper we study a set of prob-\\r\\r\\nlem...</td>\n",
       "      <td>26466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  text_len\n",
       "0  E03-1062  This paper describes the NECA MNLG;\\r\\r\\na ful...     15690\n",
       "1  E06-1001  I propose a uniform approach to the elim-\\r\\r\\...     28328\n",
       "2  E06-1002  We present a new method for detecting and\\r\\r\\...     33424\n",
       "3  E06-1003  We present a weakly supervised approach\\r\\r\\nt...     31859\n",
       "4  E06-1004  In this paper we study a set of prob-\\r\\r\\nlem...     26466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_abstract = lambda x: x.split('\\nAbstract\\n')[-1].split('\\n1 ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper describes the NECA MNLG;\\r\\r\\na fully implemented Multimodal Natu-\\r\\r\\nral Language Generation module. The\\r\\r\\nMNLG is deployed as part of the NECA\\r\\r\\nsystem which generates dialogues be-\\r\\r\\ntween animated agents. The genera-\\r\\r\\ntion module supports the seamless inte-\\r\\r\\ngration of full grammar rules, templates\\r\\r\\nand canned text. The generator takes in-\\r\\r\\nput which allows for the specification of\\r\\r\\nsyntactic, semantic and pragmatic con-\\r\\r\\nstraints on the output.\\r\\r'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.iloc[0].text.split('\\nAbstract\\n')[-1].split('\\n1')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts['abstract'] = abstracts['text'].apply(get_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stopwords):\n",
    "    text = text.replace('\\r','').replace('-\\n', '').replace('\\n', ' ').lower()\n",
    "    tokens = re.findall(r'[a-z]+', text)\n",
    "    return ' '.join([token for token in tokens if token not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper describes neca mnlg fully implemented multimodal natural language generation module mnlg deployed part neca system generates dialogues animated agents generation module supports seamless integration full grammar rules templates canned text generator takes input allows specification syntactic semantic pragmatic constraints output'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(abstracts.iloc[0]['abstract'], stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd673d8bfb81478c93ee2f87b4c95a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16268), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "abstracts['abstract'] = [clean(abstr, stopwords) for abstr in tqdm_notebook(abstracts['abstract'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'limited coverage lexical semantic resources significant problem nlp systems can alleviated automatically classifying unknown words supersense tagging assigns unknown nouns one broad semantic categories used lexicographers organise manual insertion wordnet ciaramita johnson present tagger uses synonym set glosses annotated training examples describe unsupervised approach based vector space similarity require annotated examples significantly outperforms tagger also demonstrate use extremely large shallow parsed corpus calculating vector space semantic similarity'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.iloc[1000].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./asymproj_edge_dnn-master/datasets/aan_graph/index.pkl', 'rb') as f:\n",
    "    index_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_graph['index'][abstracts.iloc[1000].id] #for node in aan_links_connected['citing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_node_id(node, map_dict):\n",
    "    node_id = None\n",
    "    try:\n",
    "        node_id = map_dict[node]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbac3b87ba24942b2a146a378a3ad0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16268), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "node_ids = [map_node_id(node, index_graph['index']) for node in tqdm_notebook(abstracts['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2517"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_node_id(abstracts.iloc[0].id, index_graph['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts['node_id'] = node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16268, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>abstract</th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03-1062</td>\n",
       "      <td>This paper describes the NECA MNLG;\\r\\r\\na ful...</td>\n",
       "      <td>15690</td>\n",
       "      <td>paper describes neca mnlg fully implemented mu...</td>\n",
       "      <td>2517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06-1001</td>\n",
       "      <td>I propose a uniform approach to the elim-\\r\\r\\...</td>\n",
       "      <td>28328</td>\n",
       "      <td>propose uniform approach elimination redundanc...</td>\n",
       "      <td>2518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06-1002</td>\n",
       "      <td>We present a new method for detecting and\\r\\r\\...</td>\n",
       "      <td>33424</td>\n",
       "      <td>present new method detecting disambiguating na...</td>\n",
       "      <td>2519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1003</td>\n",
       "      <td>We present a weakly supervised approach\\r\\r\\nt...</td>\n",
       "      <td>31859</td>\n",
       "      <td>present weakly supervised approach automatic o...</td>\n",
       "      <td>2520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06-1004</td>\n",
       "      <td>In this paper we study a set of prob-\\r\\r\\nlem...</td>\n",
       "      <td>26466</td>\n",
       "      <td>paper study set problems considerable importan...</td>\n",
       "      <td>2521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E06-1005</td>\n",
       "      <td>This paper describes a novel method for\\r\\r\\nc...</td>\n",
       "      <td>28598</td>\n",
       "      <td>paper describes novel method computing consens...</td>\n",
       "      <td>2522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E06-1006</td>\n",
       "      <td>We propose a backoff model for phrase-\\r\\r\\nba...</td>\n",
       "      <td>31962</td>\n",
       "      <td>propose backoff model phrasebased machine tran...</td>\n",
       "      <td>2523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E06-1007</td>\n",
       "      <td>We present an implemented machine\\r\\r\\nlearnin...</td>\n",
       "      <td>35869</td>\n",
       "      <td>present implemented machine learning system au...</td>\n",
       "      <td>2524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E06-1008</td>\n",
       "      <td>In this paper, we explore statistical lan-\\r\\r...</td>\n",
       "      <td>33343</td>\n",
       "      <td>paper explore statistical language modelling s...</td>\n",
       "      <td>2525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E06-1009</td>\n",
       "      <td>To tackle the problem of presenting a\\r\\r\\nlar...</td>\n",
       "      <td>35245</td>\n",
       "      <td>tackle problem presenting large number options...</td>\n",
       "      <td>2526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E06-1010</td>\n",
       "      <td>We investigate a series of graph-theoretic\\r\\r...</td>\n",
       "      <td>28045</td>\n",
       "      <td>investigate series graph theoretic constraints...</td>\n",
       "      <td>2527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E06-1011</td>\n",
       "      <td>In this paper we extend the maximum\\r\\r\\nspann...</td>\n",
       "      <td>32557</td>\n",
       "      <td>paper extend maximum spanning tree mst depende...</td>\n",
       "      <td>2528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E06-1012</td>\n",
       "      <td>This paper presents results from the first\\r\\r...</td>\n",
       "      <td>31646</td>\n",
       "      <td>paper presents results first statistical depen...</td>\n",
       "      <td>2529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E06-1013</td>\n",
       "      <td>An algorithm based on the Generalized\\r\\r\\nHeb...</td>\n",
       "      <td>30680</td>\n",
       "      <td>algorithm based generalized hebbian algorithm ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E06-1014</td>\n",
       "      <td>Probabilistic Latent Semantic Analysis\\r\\r\\n(P...</td>\n",
       "      <td>32288</td>\n",
       "      <td>probabilistic latent semantic analysis plsa mo...</td>\n",
       "      <td>2530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E06-1015</td>\n",
       "      <td>In recent years tree kernels have been pro-\\r\\...</td>\n",
       "      <td>33454</td>\n",
       "      <td>recent years tree kernels proposed automatic l...</td>\n",
       "      <td>2531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E06-1016</td>\n",
       "      <td>The degree of dominance of a sense of a\\r\\r\\nw...</td>\n",
       "      <td>33893</td>\n",
       "      <td>degree dominance sense word proportion occurre...</td>\n",
       "      <td>2532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E06-1018</td>\n",
       "      <td>In this paper a novel solution to auto-\\r\\r\\nm...</td>\n",
       "      <td>34440</td>\n",
       "      <td>paper novel solution automatic unsupervised wo...</td>\n",
       "      <td>2533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E06-1019</td>\n",
       "      <td>This work is concerned with the space of\\r\\r\\n...</td>\n",
       "      <td>33547</td>\n",
       "      <td>work concerned space alignments searched word ...</td>\n",
       "      <td>2534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E06-1020</td>\n",
       "      <td>We describe a word alignment platform\\r\\r\\nwhi...</td>\n",
       "      <td>33724</td>\n",
       "      <td>describe word alignment platform ensures text ...</td>\n",
       "      <td>2535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>E06-1021</td>\n",
       "      <td>Aligning sentences belonging to compa-\\r\\r\\nra...</td>\n",
       "      <td>33242</td>\n",
       "      <td>aligning sentences belonging comparable monoli...</td>\n",
       "      <td>2536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E06-1022</td>\n",
       "      <td>We present results on addressee identifica-\\r\\...</td>\n",
       "      <td>35620</td>\n",
       "      <td>present results addressee identification four ...</td>\n",
       "      <td>2537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>E06-1023</td>\n",
       "      <td>This paper proposes a method for deal-\\r\\r\\nin...</td>\n",
       "      <td>31869</td>\n",
       "      <td>paper proposes method dealing repairs action c...</td>\n",
       "      <td>2538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>E06-1024</td>\n",
       "      <td>In this paper, we address the problem\\r\\r\\nof ...</td>\n",
       "      <td>36374</td>\n",
       "      <td>paper address problem reducing unpredictabilit...</td>\n",
       "      <td>2539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>E06-1025</td>\n",
       "      <td>Opinion mining is a recent subdiscipline\\r\\r\\n...</td>\n",
       "      <td>39548</td>\n",
       "      <td>opinion mining recent subdiscipline computatio...</td>\n",
       "      <td>2540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>E06-1026</td>\n",
       "      <td>We propose models for semantic orienta-\\r\\r\\nt...</td>\n",
       "      <td>30778</td>\n",
       "      <td>propose models semantic orientations phrases w...</td>\n",
       "      <td>2541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>E06-1027</td>\n",
       "      <td>Many of the tasks required for semantic\\r\\r\\nt...</td>\n",
       "      <td>31575</td>\n",
       "      <td>many tasks required semantic tagging phrases t...</td>\n",
       "      <td>2542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>E06-1028</td>\n",
       "      <td>In this paper, we present an automated,\\r\\r\\nq...</td>\n",
       "      <td>34933</td>\n",
       "      <td>paper present automated quantitative knowledge...</td>\n",
       "      <td>2543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>E06-1029</td>\n",
       "      <td>We propose a method for compiling bi-\\r\\r\\nlin...</td>\n",
       "      <td>33307</td>\n",
       "      <td>propose method compiling bilingual terminologi...</td>\n",
       "      <td>2544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>E06-1030</td>\n",
       "      <td>Web text has been successfully used as\\r\\r\\ntr...</td>\n",
       "      <td>34147</td>\n",
       "      <td>web text successfully used training data many ...</td>\n",
       "      <td>2545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16238</th>\n",
       "      <td>W14-3908</td>\n",
       "      <td>We describe a CRF based system for\\r\\r\\nword-l...</td>\n",
       "      <td>25139</td>\n",
       "      <td>describe crf based system word level language ...</td>\n",
       "      <td>13083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>W14-3909</td>\n",
       "      <td>We describe the CMU submission for\\r\\r\\nthe 20...</td>\n",
       "      <td>25321</td>\n",
       "      <td>describe cmu submission shared task language i...</td>\n",
       "      <td>13084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16240</th>\n",
       "      <td>W14-3910</td>\n",
       "      <td>This paper describes a CRF based token\\r\\r\\nle...</td>\n",
       "      <td>25033</td>\n",
       "      <td>paper describes crf based token level language...</td>\n",
       "      <td>13085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>W14-3911</td>\n",
       "      <td>In this paper, we present the latest version\\r...</td>\n",
       "      <td>28069</td>\n",
       "      <td>paper present latest version system identifyin...</td>\n",
       "      <td>13086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16242</th>\n",
       "      <td>W14-3912</td>\n",
       "      <td>We describe the IUCL+ system for the shared\\r\\...</td>\n",
       "      <td>22256</td>\n",
       "      <td>describe iucl system shared task first worksho...</td>\n",
       "      <td>13087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16243</th>\n",
       "      <td>W14-3913</td>\n",
       "      <td>While there has been lots of interest in\\r\\r\\n...</td>\n",
       "      <td>33710</td>\n",
       "      <td>lots interest code switching informal text twe...</td>\n",
       "      <td>13088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16244</th>\n",
       "      <td>W14-3915</td>\n",
       "      <td>This paper describes the DCU-UVT\\r\\r\\nteam?s p...</td>\n",
       "      <td>22515</td>\n",
       "      <td>paper describes dcu uvt team s participation l...</td>\n",
       "      <td>13089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>W14-3916</td>\n",
       "      <td>A multilingual person writing a sentence\\r\\r\\n...</td>\n",
       "      <td>21832</td>\n",
       "      <td>multilingual person writing sentence piece tex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>W14-3917</td>\n",
       "      <td>We describe our entry in the EMNLP 2014\\r\\r\\nc...</td>\n",
       "      <td>16407</td>\n",
       "      <td>describe entry emnlp code switching shared tas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16247</th>\n",
       "      <td>W14-4101</td>\n",
       "      <td>Data archeology is a theoretically-\\r\\r\\ninfor...</td>\n",
       "      <td>6414</td>\n",
       "      <td>data archeology theoreticallyinformed approach...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16248</th>\n",
       "      <td>W14-4102</td>\n",
       "      <td>In this work, we explore video lec-\\r\\r\\nture ...</td>\n",
       "      <td>48179</td>\n",
       "      <td>work explore video lecture interaction massive...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>W14-4103</td>\n",
       "      <td>Identifying and understanding the motiva-\\r\\r\\...</td>\n",
       "      <td>22196</td>\n",
       "      <td>identifying understanding motivations student ...</td>\n",
       "      <td>13108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>W14-4104</td>\n",
       "      <td>One important function of the discussion\\r\\r\\n...</td>\n",
       "      <td>46160</td>\n",
       "      <td>one important function discussion forums massi...</td>\n",
       "      <td>13109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16251</th>\n",
       "      <td>W14-4105</td>\n",
       "      <td>This paper explores the cognitive presence\\r\\r...</td>\n",
       "      <td>21698</td>\n",
       "      <td>paper explores cognitive presence learners moo...</td>\n",
       "      <td>13110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16252</th>\n",
       "      <td>W14-4107</td>\n",
       "      <td>The shared task on Prediction of Dropout\\r\\r\\n...</td>\n",
       "      <td>13179</td>\n",
       "      <td>shared task prediction dropout time moocs invo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16253</th>\n",
       "      <td>W14-4108</td>\n",
       "      <td>This work is an attempt to discover hidden\\r\\r...</td>\n",
       "      <td>32963</td>\n",
       "      <td>work attempt discover hidden structural config...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16254</th>\n",
       "      <td>W14-4109</td>\n",
       "      <td>The goal of this shared task was to predict\\r\\...</td>\n",
       "      <td>16944</td>\n",
       "      <td>goal shared task predict attrition mooc use da...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16255</th>\n",
       "      <td>W14-4110</td>\n",
       "      <td>Discussion forum and clickstream are two prima...</td>\n",
       "      <td>17899</td>\n",
       "      <td>discussion forum clickstream two primary data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16256</th>\n",
       "      <td>W14-4111</td>\n",
       "      <td>With high dropout rates as observed in\\r\\r\\nma...</td>\n",
       "      <td>18684</td>\n",
       "      <td>high dropout rates observed many current large...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16257</th>\n",
       "      <td>W14-4202</td>\n",
       "      <td>We present a new dependency parsing\\r\\r\\nmetho...</td>\n",
       "      <td>44954</td>\n",
       "      <td>present new dependency parsing method korean a...</td>\n",
       "      <td>13111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16258</th>\n",
       "      <td>W14-4203</td>\n",
       "      <td>This paper addresses cross-lingual depen-\\r\\r\\...</td>\n",
       "      <td>51262</td>\n",
       "      <td>paper addresses cross lingual dependency parsi...</td>\n",
       "      <td>13112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16259</th>\n",
       "      <td>W14-4204</td>\n",
       "      <td>We study the problem of language vari-\\r\\r\\nan...</td>\n",
       "      <td>43434</td>\n",
       "      <td>study problem language variant identification ...</td>\n",
       "      <td>13113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16260</th>\n",
       "      <td>W14-4205</td>\n",
       "      <td>In this paper, the development and evalua-\\r\\r...</td>\n",
       "      <td>45711</td>\n",
       "      <td>paper development evaluation urdu parser prese...</td>\n",
       "      <td>13114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16261</th>\n",
       "      <td>W14-4206</td>\n",
       "      <td>Hindi and Urdu are two standardized reg-\\r\\r\\n...</td>\n",
       "      <td>31112</td>\n",
       "      <td>hindi urdu two standardized registers called h...</td>\n",
       "      <td>13115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16262</th>\n",
       "      <td>W14-4207</td>\n",
       "      <td>This paper addresses the problems of mea-\\r\\r\\...</td>\n",
       "      <td>43936</td>\n",
       "      <td>paper addresses problems measuring similarity ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16263</th>\n",
       "      <td>W14-4209</td>\n",
       "      <td>This paper describes machine transla-\\r\\r\\ntio...</td>\n",
       "      <td>27747</td>\n",
       "      <td>paper describes machine translation proper nam...</td>\n",
       "      <td>13116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16264</th>\n",
       "      <td>W14-4210</td>\n",
       "      <td>This work investigates the use of cross-\\r\\r\\n...</td>\n",
       "      <td>29317</td>\n",
       "      <td>work investigates use crosslanguage resources ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16265</th>\n",
       "      <td>W14-4211</td>\n",
       "      <td>Statistical Machine Translation (SMT)\\r\\r\\nsys...</td>\n",
       "      <td>24281</td>\n",
       "      <td>statistical machine translation smt systems he...</td>\n",
       "      <td>13117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16266</th>\n",
       "      <td>W14-4212</td>\n",
       "      <td>This paper describes an experiment compar-\\r\\r...</td>\n",
       "      <td>35790</td>\n",
       "      <td>paper describes experiment comparing results m...</td>\n",
       "      <td>13118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16267</th>\n",
       "      <td>W14-4213</td>\n",
       "      <td>Dialects and standard forms of a language\\r\\r\\...</td>\n",
       "      <td>35502</td>\n",
       "      <td>dialects standard forms language typically sha...</td>\n",
       "      <td>13119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  text_len  \\\n",
       "0      E03-1062  This paper describes the NECA MNLG;\\r\\r\\na ful...     15690   \n",
       "1      E06-1001  I propose a uniform approach to the elim-\\r\\r\\...     28328   \n",
       "2      E06-1002  We present a new method for detecting and\\r\\r\\...     33424   \n",
       "3      E06-1003  We present a weakly supervised approach\\r\\r\\nt...     31859   \n",
       "4      E06-1004  In this paper we study a set of prob-\\r\\r\\nlem...     26466   \n",
       "5      E06-1005  This paper describes a novel method for\\r\\r\\nc...     28598   \n",
       "6      E06-1006  We propose a backoff model for phrase-\\r\\r\\nba...     31962   \n",
       "7      E06-1007  We present an implemented machine\\r\\r\\nlearnin...     35869   \n",
       "8      E06-1008  In this paper, we explore statistical lan-\\r\\r...     33343   \n",
       "9      E06-1009  To tackle the problem of presenting a\\r\\r\\nlar...     35245   \n",
       "10     E06-1010  We investigate a series of graph-theoretic\\r\\r...     28045   \n",
       "11     E06-1011  In this paper we extend the maximum\\r\\r\\nspann...     32557   \n",
       "12     E06-1012  This paper presents results from the first\\r\\r...     31646   \n",
       "13     E06-1013  An algorithm based on the Generalized\\r\\r\\nHeb...     30680   \n",
       "14     E06-1014  Probabilistic Latent Semantic Analysis\\r\\r\\n(P...     32288   \n",
       "15     E06-1015  In recent years tree kernels have been pro-\\r\\...     33454   \n",
       "16     E06-1016  The degree of dominance of a sense of a\\r\\r\\nw...     33893   \n",
       "17     E06-1018  In this paper a novel solution to auto-\\r\\r\\nm...     34440   \n",
       "18     E06-1019  This work is concerned with the space of\\r\\r\\n...     33547   \n",
       "19     E06-1020  We describe a word alignment platform\\r\\r\\nwhi...     33724   \n",
       "20     E06-1021  Aligning sentences belonging to compa-\\r\\r\\nra...     33242   \n",
       "21     E06-1022  We present results on addressee identifica-\\r\\...     35620   \n",
       "22     E06-1023  This paper proposes a method for deal-\\r\\r\\nin...     31869   \n",
       "23     E06-1024  In this paper, we address the problem\\r\\r\\nof ...     36374   \n",
       "24     E06-1025  Opinion mining is a recent subdiscipline\\r\\r\\n...     39548   \n",
       "25     E06-1026  We propose models for semantic orienta-\\r\\r\\nt...     30778   \n",
       "26     E06-1027  Many of the tasks required for semantic\\r\\r\\nt...     31575   \n",
       "27     E06-1028  In this paper, we present an automated,\\r\\r\\nq...     34933   \n",
       "28     E06-1029  We propose a method for compiling bi-\\r\\r\\nlin...     33307   \n",
       "29     E06-1030  Web text has been successfully used as\\r\\r\\ntr...     34147   \n",
       "...         ...                                                ...       ...   \n",
       "16238  W14-3908  We describe a CRF based system for\\r\\r\\nword-l...     25139   \n",
       "16239  W14-3909  We describe the CMU submission for\\r\\r\\nthe 20...     25321   \n",
       "16240  W14-3910  This paper describes a CRF based token\\r\\r\\nle...     25033   \n",
       "16241  W14-3911  In this paper, we present the latest version\\r...     28069   \n",
       "16242  W14-3912  We describe the IUCL+ system for the shared\\r\\...     22256   \n",
       "16243  W14-3913  While there has been lots of interest in\\r\\r\\n...     33710   \n",
       "16244  W14-3915  This paper describes the DCU-UVT\\r\\r\\nteam?s p...     22515   \n",
       "16245  W14-3916  A multilingual person writing a sentence\\r\\r\\n...     21832   \n",
       "16246  W14-3917  We describe our entry in the EMNLP 2014\\r\\r\\nc...     16407   \n",
       "16247  W14-4101  Data archeology is a theoretically-\\r\\r\\ninfor...      6414   \n",
       "16248  W14-4102  In this work, we explore video lec-\\r\\r\\nture ...     48179   \n",
       "16249  W14-4103  Identifying and understanding the motiva-\\r\\r\\...     22196   \n",
       "16250  W14-4104  One important function of the discussion\\r\\r\\n...     46160   \n",
       "16251  W14-4105  This paper explores the cognitive presence\\r\\r...     21698   \n",
       "16252  W14-4107  The shared task on Prediction of Dropout\\r\\r\\n...     13179   \n",
       "16253  W14-4108  This work is an attempt to discover hidden\\r\\r...     32963   \n",
       "16254  W14-4109  The goal of this shared task was to predict\\r\\...     16944   \n",
       "16255  W14-4110  Discussion forum and clickstream are two prima...     17899   \n",
       "16256  W14-4111  With high dropout rates as observed in\\r\\r\\nma...     18684   \n",
       "16257  W14-4202  We present a new dependency parsing\\r\\r\\nmetho...     44954   \n",
       "16258  W14-4203  This paper addresses cross-lingual depen-\\r\\r\\...     51262   \n",
       "16259  W14-4204  We study the problem of language vari-\\r\\r\\nan...     43434   \n",
       "16260  W14-4205  In this paper, the development and evalua-\\r\\r...     45711   \n",
       "16261  W14-4206  Hindi and Urdu are two standardized reg-\\r\\r\\n...     31112   \n",
       "16262  W14-4207  This paper addresses the problems of mea-\\r\\r\\...     43936   \n",
       "16263  W14-4209  This paper describes machine transla-\\r\\r\\ntio...     27747   \n",
       "16264  W14-4210  This work investigates the use of cross-\\r\\r\\n...     29317   \n",
       "16265  W14-4211  Statistical Machine Translation (SMT)\\r\\r\\nsys...     24281   \n",
       "16266  W14-4212  This paper describes an experiment compar-\\r\\r...     35790   \n",
       "16267  W14-4213  Dialects and standard forms of a language\\r\\r\\...     35502   \n",
       "\n",
       "                                                abstract  node_id  \n",
       "0      paper describes neca mnlg fully implemented mu...   2517.0  \n",
       "1      propose uniform approach elimination redundanc...   2518.0  \n",
       "2      present new method detecting disambiguating na...   2519.0  \n",
       "3      present weakly supervised approach automatic o...   2520.0  \n",
       "4      paper study set problems considerable importan...   2521.0  \n",
       "5      paper describes novel method computing consens...   2522.0  \n",
       "6      propose backoff model phrasebased machine tran...   2523.0  \n",
       "7      present implemented machine learning system au...   2524.0  \n",
       "8      paper explore statistical language modelling s...   2525.0  \n",
       "9      tackle problem presenting large number options...   2526.0  \n",
       "10     investigate series graph theoretic constraints...   2527.0  \n",
       "11     paper extend maximum spanning tree mst depende...   2528.0  \n",
       "12     paper presents results first statistical depen...   2529.0  \n",
       "13     algorithm based generalized hebbian algorithm ...      NaN  \n",
       "14     probabilistic latent semantic analysis plsa mo...   2530.0  \n",
       "15     recent years tree kernels proposed automatic l...   2531.0  \n",
       "16     degree dominance sense word proportion occurre...   2532.0  \n",
       "17     paper novel solution automatic unsupervised wo...   2533.0  \n",
       "18     work concerned space alignments searched word ...   2534.0  \n",
       "19     describe word alignment platform ensures text ...   2535.0  \n",
       "20     aligning sentences belonging comparable monoli...   2536.0  \n",
       "21     present results addressee identification four ...   2537.0  \n",
       "22     paper proposes method dealing repairs action c...   2538.0  \n",
       "23     paper address problem reducing unpredictabilit...   2539.0  \n",
       "24     opinion mining recent subdiscipline computatio...   2540.0  \n",
       "25     propose models semantic orientations phrases w...   2541.0  \n",
       "26     many tasks required semantic tagging phrases t...   2542.0  \n",
       "27     paper present automated quantitative knowledge...   2543.0  \n",
       "28     propose method compiling bilingual terminologi...   2544.0  \n",
       "29     web text successfully used training data many ...   2545.0  \n",
       "...                                                  ...      ...  \n",
       "16238  describe crf based system word level language ...  13083.0  \n",
       "16239  describe cmu submission shared task language i...  13084.0  \n",
       "16240  paper describes crf based token level language...  13085.0  \n",
       "16241  paper present latest version system identifyin...  13086.0  \n",
       "16242  describe iucl system shared task first worksho...  13087.0  \n",
       "16243  lots interest code switching informal text twe...  13088.0  \n",
       "16244  paper describes dcu uvt team s participation l...  13089.0  \n",
       "16245  multilingual person writing sentence piece tex...      NaN  \n",
       "16246  describe entry emnlp code switching shared tas...      NaN  \n",
       "16247  data archeology theoreticallyinformed approach...      NaN  \n",
       "16248  work explore video lecture interaction massive...      NaN  \n",
       "16249  identifying understanding motivations student ...  13108.0  \n",
       "16250  one important function discussion forums massi...  13109.0  \n",
       "16251  paper explores cognitive presence learners moo...  13110.0  \n",
       "16252  shared task prediction dropout time moocs invo...      NaN  \n",
       "16253  work attempt discover hidden structural config...      NaN  \n",
       "16254  goal shared task predict attrition mooc use da...      NaN  \n",
       "16255  discussion forum clickstream two primary data ...      NaN  \n",
       "16256  high dropout rates observed many current large...      NaN  \n",
       "16257  present new dependency parsing method korean a...  13111.0  \n",
       "16258  paper addresses cross lingual dependency parsi...  13112.0  \n",
       "16259  study problem language variant identification ...  13113.0  \n",
       "16260  paper development evaluation urdu parser prese...  13114.0  \n",
       "16261  hindi urdu two standardized registers called h...  13115.0  \n",
       "16262  paper addresses problems measuring similarity ...      NaN  \n",
       "16263  paper describes machine translation proper nam...  13116.0  \n",
       "16264  work investigates use crosslanguage resources ...      NaN  \n",
       "16265  statistical machine translation smt systems he...  13117.0  \n",
       "16266  paper describes experiment comparing results m...  13118.0  \n",
       "16267  dialects standard forms language typically sha...  13119.0  \n",
       "\n",
       "[16268 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = abstracts[abstracts['node_id'].notnull()][['id','node_id','abstract']].sort_values(by = 'node_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text['node_id'] = input_text['node_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>A00-1002</td>\n",
       "      <td>0</td>\n",
       "      <td>using examples transfer based mt system czech ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8091</th>\n",
       "      <td>A00-1005</td>\n",
       "      <td>1</td>\n",
       "      <td>paper describes system provides customer servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8092</th>\n",
       "      <td>A00-1006</td>\n",
       "      <td>2</td>\n",
       "      <td>paper proposes way improve translation quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8093</th>\n",
       "      <td>A00-1008</td>\n",
       "      <td>3</td>\n",
       "      <td>paper describes application ape atlas planning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>A00-1009</td>\n",
       "      <td>4</td>\n",
       "      <td>paper describe implemented framework developin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>A00-1010</td>\n",
       "      <td>5</td>\n",
       "      <td>describe talk n travel spoken dialogue languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>A00-1011</td>\n",
       "      <td>6</td>\n",
       "      <td>paper reports large scale end toend relation e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>A00-1014</td>\n",
       "      <td>7</td>\n",
       "      <td>paper describes mimic adaptive mixed initiativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>A00-1018</td>\n",
       "      <td>8</td>\n",
       "      <td>past decade lot work computational linguistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8100</th>\n",
       "      <td>A00-1021</td>\n",
       "      <td>9</td>\n",
       "      <td>paper describe system rank suspected answers n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101</th>\n",
       "      <td>A00-1022</td>\n",
       "      <td>10</td>\n",
       "      <td>customer care technical domains increasingly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td>A00-1023</td>\n",
       "      <td>11</td>\n",
       "      <td>paper discusses information extraction ie syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td>A00-1025</td>\n",
       "      <td>12</td>\n",
       "      <td>describe evaluate implemented system general k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>A00-1026</td>\n",
       "      <td>13</td>\n",
       "      <td>arbiter prolog program extracts assertions mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td>A00-1030</td>\n",
       "      <td>14</td>\n",
       "      <td>paper describes approach providing lexical inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8107</th>\n",
       "      <td>A00-1032</td>\n",
       "      <td>15</td>\n",
       "      <td>paper proposes framework language independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8108</th>\n",
       "      <td>A00-1034</td>\n",
       "      <td>16</td>\n",
       "      <td>paper presents hybrid approach named entity ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>A00-1036</td>\n",
       "      <td>17</td>\n",
       "      <td>paper describes results experiments using new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>A00-1043</td>\n",
       "      <td>18</td>\n",
       "      <td>present novel sentence reduction system automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>A00-1044</td>\n",
       "      <td>19</td>\n",
       "      <td>paper analyze performance name finding context...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>A00-2003</td>\n",
       "      <td>20</td>\n",
       "      <td>aim paper identify genreindependent factors in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>A00-2006</td>\n",
       "      <td>21</td>\n",
       "      <td>goal paper describe eurowordnet framework repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>A00-2008</td>\n",
       "      <td>22</td>\n",
       "      <td>paper presents syntactic semantic tags used an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>A00-2011</td>\n",
       "      <td>23</td>\n",
       "      <td>many corpus based machine translation systems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>A00-2012</td>\n",
       "      <td>24</td>\n",
       "      <td>arabic inflectional morphology requires infixa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>A00-2018</td>\n",
       "      <td>25</td>\n",
       "      <td>present new parser parsing penn tree bank styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>A00-2019</td>\n",
       "      <td>26</td>\n",
       "      <td>present unsupervised method detecting rammatic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>A00-2022</td>\n",
       "      <td>27</td>\n",
       "      <td>describe novel approach packing local ambiguit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>A00-2025</td>\n",
       "      <td>28</td>\n",
       "      <td>automatic generation text summaries spoken lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>A00-2026</td>\n",
       "      <td>29</td>\n",
       "      <td>present hree systems surface natural anguage g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12584</th>\n",
       "      <td>W99-0507</td>\n",
       "      <td>13476</td>\n",
       "      <td>simple large scale emopean lexicon project fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585</th>\n",
       "      <td>W99-0508</td>\n",
       "      <td>13477</td>\n",
       "      <td>article reports results prehmlnary analysis tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12586</th>\n",
       "      <td>W99-0511</td>\n",
       "      <td>13478</td>\n",
       "      <td>using standard methods formats established lad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>W99-0603</td>\n",
       "      <td>13479</td>\n",
       "      <td>paper explores automatic onstruction multiling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14099</th>\n",
       "      <td>W99-0606</td>\n",
       "      <td>13480</td>\n",
       "      <td>boosting machine learning algorithm well known...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>W99-0609</td>\n",
       "      <td>13481</td>\n",
       "      <td>work use large text corpus order nouns level s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>W99-0613</td>\n",
       "      <td>13482</td>\n",
       "      <td>paper discusses use unlabeled examples problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>W99-0617</td>\n",
       "      <td>13483</td>\n",
       "      <td>language models speech recognition concentrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14103</th>\n",
       "      <td>W99-0618</td>\n",
       "      <td>13484</td>\n",
       "      <td>years many proposals made incorporate assorted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>W99-0619</td>\n",
       "      <td>13485</td>\n",
       "      <td>intonational phonology speech synthesis resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14105</th>\n",
       "      <td>W99-0628</td>\n",
       "      <td>13486</td>\n",
       "      <td>paper use various methods multiple neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14106</th>\n",
       "      <td>W99-0630</td>\n",
       "      <td>13487</td>\n",
       "      <td>present new method automatically merge lexicon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>W99-0631</td>\n",
       "      <td>13488</td>\n",
       "      <td>paper concerned using semantic hierarchy estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>W99-0632</td>\n",
       "      <td>13489</td>\n",
       "      <td>levin s taxonomy verbs classes widely used res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14109</th>\n",
       "      <td>W99-0633</td>\n",
       "      <td>13490</td>\n",
       "      <td>paper brill s rule based pos tagger tested ada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11588</th>\n",
       "      <td>W99-0703</td>\n",
       "      <td>13491</td>\n",
       "      <td>paper presents semi automatic technique develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11589</th>\n",
       "      <td>W99-0704</td>\n",
       "      <td>13492</td>\n",
       "      <td>constructive induction transforms representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11590</th>\n",
       "      <td>W99-0705</td>\n",
       "      <td>13493</td>\n",
       "      <td>u tbl system represents attempt o use search d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11591</th>\n",
       "      <td>W99-0706</td>\n",
       "      <td>13494</td>\n",
       "      <td>grammatical relationships important level natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11592</th>\n",
       "      <td>W99-0708</td>\n",
       "      <td>13495</td>\n",
       "      <td>introduce learner capable automatically extend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>W99-0807</td>\n",
       "      <td>13496</td>\n",
       "      <td>describe work progress corpus based tutoring s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12559</th>\n",
       "      <td>W99-0901</td>\n",
       "      <td>13497</td>\n",
       "      <td>introduce new model selectional preference ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561</th>\n",
       "      <td>W99-0904</td>\n",
       "      <td>13498</td>\n",
       "      <td>present paper unsupervised method learn suffix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12562</th>\n",
       "      <td>W99-0905</td>\n",
       "      <td>13499</td>\n",
       "      <td>paper presents unsupervised method choosing co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>W99-0906</td>\n",
       "      <td>13500</td>\n",
       "      <td>propose evaluate computational techniques deci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12564</th>\n",
       "      <td>W99-0907</td>\n",
       "      <td>13501</td>\n",
       "      <td>ido dagan institute info retrieval computation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11244</th>\n",
       "      <td>X96-1039</td>\n",
       "      <td>13502</td>\n",
       "      <td>tipster architecture standardized interface pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246</th>\n",
       "      <td>X98-1016</td>\n",
       "      <td>13503</td>\n",
       "      <td>information extraction ie systems today common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11249</th>\n",
       "      <td>X98-1026</td>\n",
       "      <td>13504</td>\n",
       "      <td>extract text background just news regular keyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250</th>\n",
       "      <td>X98-1028</td>\n",
       "      <td>13505</td>\n",
       "      <td>present automated method generating human read...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  node_id                                           abstract\n",
       "8090   A00-1002        0  using examples transfer based mt system czech ...\n",
       "8091   A00-1005        1  paper describes system provides customer servi...\n",
       "8092   A00-1006        2  paper proposes way improve translation quality...\n",
       "8093   A00-1008        3  paper describes application ape atlas planning...\n",
       "8094   A00-1009        4  paper describe implemented framework developin...\n",
       "8095   A00-1010        5  describe talk n travel spoken dialogue languag...\n",
       "8096   A00-1011        6  paper reports large scale end toend relation e...\n",
       "8098   A00-1014        7  paper describes mimic adaptive mixed initiativ...\n",
       "8099   A00-1018        8  past decade lot work computational linguistics...\n",
       "8100   A00-1021        9  paper describe system rank suspected answers n...\n",
       "8101   A00-1022       10  customer care technical domains increasingly b...\n",
       "8102   A00-1023       11  paper discusses information extraction ie syst...\n",
       "8103   A00-1025       12  describe evaluate implemented system general k...\n",
       "8104   A00-1026       13  arbiter prolog program extracts assertions mac...\n",
       "8106   A00-1030       14  paper describes approach providing lexical inf...\n",
       "8107   A00-1032       15  paper proposes framework language independent ...\n",
       "8108   A00-1034       16  paper presents hybrid approach named entity ne...\n",
       "8109   A00-1036       17  paper describes results experiments using new ...\n",
       "8111   A00-1043       18  present novel sentence reduction system automa...\n",
       "8112   A00-1044       19  paper analyze performance name finding context...\n",
       "8114   A00-2003       20  aim paper identify genreindependent factors in...\n",
       "8115   A00-2006       21  goal paper describe eurowordnet framework repr...\n",
       "8116   A00-2008       22  paper presents syntactic semantic tags used an...\n",
       "8117   A00-2011       23  many corpus based machine translation systems ...\n",
       "8118   A00-2012       24  arabic inflectional morphology requires infixa...\n",
       "8119   A00-2018       25  present new parser parsing penn tree bank styl...\n",
       "8120   A00-2019       26  present unsupervised method detecting rammatic...\n",
       "8121   A00-2022       27  describe novel approach packing local ambiguit...\n",
       "8122   A00-2025       28  automatic generation text summaries spoken lan...\n",
       "8123   A00-2026       29  present hree systems surface natural anguage g...\n",
       "...         ...      ...                                                ...\n",
       "12584  W99-0507    13476  simple large scale emopean lexicon project fun...\n",
       "12585  W99-0508    13477  article reports results prehmlnary analysis tr...\n",
       "12586  W99-0511    13478  using standard methods formats established lad...\n",
       "14098  W99-0603    13479  paper explores automatic onstruction multiling...\n",
       "14099  W99-0606    13480  boosting machine learning algorithm well known...\n",
       "14100  W99-0609    13481  work use large text corpus order nouns level s...\n",
       "14101  W99-0613    13482  paper discusses use unlabeled examples problem...\n",
       "14102  W99-0617    13483  language models speech recognition concentrate...\n",
       "14103  W99-0618    13484  years many proposals made incorporate assorted...\n",
       "14104  W99-0619    13485  intonational phonology speech synthesis resear...\n",
       "14105  W99-0628    13486  paper use various methods multiple neural netw...\n",
       "14106  W99-0630    13487  present new method automatically merge lexicon...\n",
       "14107  W99-0631    13488  paper concerned using semantic hierarchy estim...\n",
       "14108  W99-0632    13489  levin s taxonomy verbs classes widely used res...\n",
       "14109  W99-0633    13490  paper brill s rule based pos tagger tested ada...\n",
       "11588  W99-0703    13491  paper presents semi automatic technique develo...\n",
       "11589  W99-0704    13492  constructive induction transforms representati...\n",
       "11590  W99-0705    13493  u tbl system represents attempt o use search d...\n",
       "11591  W99-0706    13494  grammatical relationships important level natu...\n",
       "11592  W99-0708    13495  introduce learner capable automatically extend...\n",
       "13904  W99-0807    13496  describe work progress corpus based tutoring s...\n",
       "12559  W99-0901    13497  introduce new model selectional preference ind...\n",
       "12561  W99-0904    13498  present paper unsupervised method learn suffix...\n",
       "12562  W99-0905    13499  paper presents unsupervised method choosing co...\n",
       "12563  W99-0906    13500  propose evaluate computational techniques deci...\n",
       "12564  W99-0907    13501  ido dagan institute info retrieval computation...\n",
       "11244  X96-1039    13502  tipster architecture standardized interface pr...\n",
       "11246  X98-1016    13503  information extraction ie systems today common...\n",
       "11249  X98-1026    13504  extract text background just news regular keyw...\n",
       "11250  X98-1028    13505  present automated method generating human read...\n",
       "\n",
       "[13506 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text[['abstract']].to_csv('aan_text.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !pctadw --input_text aan_text.txt --input_edges aan_connected.edgelist --split_sample_size 10000 --model_name PCTADW-2 --output pctadw.embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>abstract</th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03-1062</td>\n",
       "      <td>This paper describes the NECA MNLG;\\r\\r\\na ful...</td>\n",
       "      <td>15690</td>\n",
       "      <td>paper describes neca mnlg fully implemented mu...</td>\n",
       "      <td>2517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06-1001</td>\n",
       "      <td>I propose a uniform approach to the elim-\\r\\r\\...</td>\n",
       "      <td>28328</td>\n",
       "      <td>propose uniform approach elimination redundanc...</td>\n",
       "      <td>2518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06-1002</td>\n",
       "      <td>We present a new method for detecting and\\r\\r\\...</td>\n",
       "      <td>33424</td>\n",
       "      <td>present new method detecting disambiguating na...</td>\n",
       "      <td>2519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1003</td>\n",
       "      <td>We present a weakly supervised approach\\r\\r\\nt...</td>\n",
       "      <td>31859</td>\n",
       "      <td>present weakly supervised approach automatic o...</td>\n",
       "      <td>2520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06-1004</td>\n",
       "      <td>In this paper we study a set of prob-\\r\\r\\nlem...</td>\n",
       "      <td>26466</td>\n",
       "      <td>paper study set problems considerable importan...</td>\n",
       "      <td>2521.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  text_len  \\\n",
       "0  E03-1062  This paper describes the NECA MNLG;\\r\\r\\na ful...     15690   \n",
       "1  E06-1001  I propose a uniform approach to the elim-\\r\\r\\...     28328   \n",
       "2  E06-1002  We present a new method for detecting and\\r\\r\\...     33424   \n",
       "3  E06-1003  We present a weakly supervised approach\\r\\r\\nt...     31859   \n",
       "4  E06-1004  In this paper we study a set of prob-\\r\\r\\nlem...     26466   \n",
       "\n",
       "                                            abstract  node_id  \n",
       "0  paper describes neca mnlg fully implemented mu...   2517.0  \n",
       "1  propose uniform approach elimination redundanc...   2518.0  \n",
       "2  present new method detecting disambiguating na...   2519.0  \n",
       "3  present weakly supervised approach automatic o...   2520.0  \n",
       "4  paper study set problems considerable importan...   2521.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_embed = 'D:/wiki.en.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79460ee245734d5ea390f893fb155fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "embeddings_index = {}\n",
    "fo = open(root_embed, encoding = 'utf-8')\n",
    "for line in tqdm_notebook(fo):\n",
    "    values = line.split()\n",
    "    if len(values) == 301:\n",
    "        word = values[0]\n",
    "        words.append(word)\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_text_embedding(text, model, dim):\n",
    "    text = text.split()\n",
    "    words = Counter(text)\n",
    "    total = len(text)\n",
    "    vectors = np.zeros((len(words), dim))\n",
    "    \n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            v = model[word]\n",
    "            vectors[i] = v*(words[word]/total) \n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "X_mean_text_emb = np.zeros((len(input_text['abstract']), dim))\n",
    "\n",
    "for i, text in enumerate(input_text['abstract'].values):\n",
    "    X_mean_text_emb[i] = mean_text_embedding(text, embeddings_index, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 300)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean_text_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_text_emb = np.load('X_mean_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean_text_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_mean_text_emb.npy', X_mean_text_emb)\n",
    "np.save('X_mean_text_emb_13506.npy', X_mean_text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_text_emb = np.load('X_mean_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 300)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean_text_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = pd.DataFrame(data = X_mean_text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.to_csv('mean_emb_features.txt', sep = ' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.4, max_features = 20000)\n",
    "X_tfidf = tfidf.fit_transform(input_text['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baselin'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arises'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer.lemmatize('arises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict = dict([(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_text_embedding(text, model, dim, idf):\n",
    "    text = text.split()\n",
    "    \n",
    "    words = Counter(text)\n",
    "    total = len(text)\n",
    "    vectors = np.zeros((len(words), dim))\n",
    "    \n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            v = model[word]\n",
    "            vectors[i] = v*(words[word]/total)*idf[word] \n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "X_mean_text_emb = np.zeros((len(input_text['abstract']), dim))\n",
    "\n",
    "for i, text in enumerate(input_text['abstract'].values):\n",
    "    X_mean_text_emb[i] = tfidf_text_embedding(text, embeddings_index, dim, idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_tfidf_text_emb.npy', X_mean_text_emb)\n",
    "np.save('X_tfidf_text_emb_13506.npy', X_mean_text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_weighted_text_emb = np.load('X_tfidf_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(input_text['abstract'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = Doc2Vec(documents, vector_size=300, window=4, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.doc2vec.Doc2Vec"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.save('d2v_embed_13506_300')\n",
    "# model = Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = Doc2Vec.load('d2v_embed_13506')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.4, max_features = 20000)\n",
    "X_tfidf = tfidf.fit_transform(input_text['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 20000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y = pd.read_csv('test_x_y_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22900, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 20000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf[index_graph['index'][test_x_y.iloc[0]['citing']]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333610014967234"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(cosine_similarity(X_tfidf[index_graph['index'][test_x_y.iloc[3]['citing']]], X_tfidf[index_graph['index'][test_x_y.iloc[3]['cited']]])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011053233025877"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(cosine_similarity(X_tfidf[index_graph['index'][test_x_y.iloc[0]['citing']]], X_tfidf[index_graph['index'][test_x_y.iloc[0]['cited']]])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0044213004125975165"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(X_tfidf[index_graph['index'][test_x_y.iloc[0]['citing']]], X_tfidf[index_graph['index'][test_x_y.iloc[0]['cited']]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tfidf = np.load('X_tfidf_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13506x20000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 977047 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = X_tfidf\n",
    "link_to_matrix_id_dict = index_graph['index']\n",
    "cos_sim = lambda x: cosine_similarity(tfidf_matrix[link_to_matrix_id_dict[x['citing']]],\n",
    "                                                  tfidf_matrix[link_to_matrix_id_dict[x['cited']]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x20000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 66 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf[1080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 20000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "sparse.save_npz(\"X_tfidf_13506.npz\", tfidf_matrix)\n",
    "# tfidf_matrix = sparse.load_npz(\"X_tfidf_13506.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x20000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 66 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[link_to_matrix_id_dict[test_x_y.iloc[0]['citing']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>class</th>\n",
       "      <th>sim_d2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C14-1216</td>\n",
       "      <td>W07-1019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W13-2002</td>\n",
       "      <td>D08-1027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D13-1041</td>\n",
       "      <td>W14-1304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P14-2095</td>\n",
       "      <td>P13-2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C14-1089</td>\n",
       "      <td>W04-3217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  class   sim_d2v\n",
       "0  C14-1216  W07-1019      0  0.454362\n",
       "1  W13-2002  D08-1027      0  0.547518\n",
       "2  D13-1041  W14-1304      0  0.604749\n",
       "3  P14-2095  P13-2017      1  0.260585\n",
       "4  C14-1089  W04-3217      0  0.505673"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_links = test_x_y.apply(cos_sim, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cos_sim_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.074857714621801"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cos_sim_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22900, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10449"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i, s in enumerate(cos_sim_links) if s > 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citing    W13-3102\n",
       "cited     W13-3102\n",
       "class            1\n",
       "Name: 21004, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y.iloc[21004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668837207528461"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_x_y['class'], cos_sim_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3964500520303407"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_x_y['class'], cos_sim_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FastTexxt + CosSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# emb_matrix[link_to_matrix_id_dict[test_x_y.iloc[0]['citing']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78537427]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([emb_matrix[link_to_matrix_id_dict[test_x_y.iloc[0]['citing']]]],\\\n",
    "                  [emb_matrix[link_to_matrix_id_dict[test_x_y.iloc[0]['cited']]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_text_emb = np.load('X_mean_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = X_mean_text_emb\n",
    "link_to_matrix_id_dict = index_graph['index']\n",
    "cos_sim_emb = lambda x: cosine_similarity([emb_matrix[link_to_matrix_id_dict[x['citing']]]],\n",
    "                                                  [emb_matrix[link_to_matrix_id_dict[x['cited']]]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_links_ft = test_x_y.apply(cos_sim_emb, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7376886710779733"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_x_y['class'], cos_sim_links_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.146666899129114"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_x_y['class'], cos_sim_links_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_weighted_text_emb = np.load('X_tfidf_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = X_tfidf_weighted_text_emb\n",
    "link_to_matrix_id_dict = index_graph['index']\n",
    "cos_sim_emb = lambda x: cosine_similarity([emb_matrix[link_to_matrix_id_dict[x['citing']]]],\n",
    "                                                  [emb_matrix[link_to_matrix_id_dict[x['cited']]]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_links_ft_weighted = test_x_y.apply(cos_sim_emb, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7199453557331096"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_x_y['class'], cos_sim_links_ft_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0660873099570318"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_x_y['class'], cos_sim_links_ft_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = d2v\n",
    "link_to_matrix_id_dict = index_graph['index']\n",
    "cos_sim_emb = lambda x: cosine_similarity([emb_matrix[link_to_matrix_id_dict[x['citing']]]],\n",
    "                                                  [emb_matrix[link_to_matrix_id_dict[x['cited']]]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_links_d2v = test_x_y.apply(cos_sim_emb, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589450891478042"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_x_y['class'], cos_sim_links_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336357228573841"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_x_y['class'], cos_sim_links_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_x_y['class'], cos_sim_links_ft_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.95637849, 0.95629264, ..., 0.6291629 , 0.62070531,\n",
       "       0.54346961])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 8.73362445e-05, ...,\n",
       "       9.99825328e-01, 9.99825328e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74672489e-04, 6.63755459e-03, 6.63755459e-03, ...,\n",
       "       9.99912664e-01, 1.00000000e+00, 1.00000000e+00])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.5, 0.3, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted_labels = cos_sim_links_ft_weighted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_labels[weighted_labels < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_labels[weighted_labels > 0.1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5434696145883092"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(weighted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y['sim_tfidf'] = cos_sim_links\n",
    "test_x_y['sim_ft_mean'] = cos_sim_links_ft\n",
    "test_x_y['sim_ft_weighted'] = cos_sim_links_ft_weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y = pd.read_csv('test_links_class_similarities_2505.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y['sim_d2v'] = cos_sim_links_d2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y.to_csv('test_links_class_similarities_2505.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8544602281675031"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_links_ft_weighted[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citing             C14-1002\n",
       "cited              C02-2020\n",
       "class                     1\n",
       "sim_tfidf                 0\n",
       "sim_ft_mean        0.731348\n",
       "sim_ft_weighted    0.620705\n",
       "dtype: object"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y[test_x_y['class'] == 1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citing             C14-1002\n",
       "cited              A00-1009\n",
       "class                     0\n",
       "sim_tfidf                 0\n",
       "sim_ft_mean        0.596118\n",
       "sim_ft_weighted     0.54347\n",
       "dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y[test_x_y['class'] == 0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class              1.000000\n",
       "sim_tfidf          0.120710\n",
       "sim_ft_mean        0.910623\n",
       "sim_ft_weighted    0.890859\n",
       "dtype: float64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y[test_x_y['class'] == 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class              0.000000\n",
       "sim_tfidf          0.029006\n",
       "sim_ft_mean        0.884889\n",
       "sim_ft_weighted    0.861149\n",
       "dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y[test_x_y['class'] == 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citing             W14-6206\n",
       "cited              X98-1026\n",
       "class                     1\n",
       "sim_tfidf                 1\n",
       "sim_ft_mean               1\n",
       "sim_ft_weighted           1\n",
       "dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y[test_x_y['class'] == 1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text.to_csv('graph_id_clean_text.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = pd.read_csv('graph_id_clean_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citing             W14-6205\n",
       "cited              X98-1028\n",
       "class                     0\n",
       "sim_tfidf          0.312674\n",
       "sim_ft_mean        0.960478\n",
       "sim_ft_weighted    0.956293\n",
       "dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y[test_x_y['class'] == 0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y.to_csv('test_links_class_similarities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
