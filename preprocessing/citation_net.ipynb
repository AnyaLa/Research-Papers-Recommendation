{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/Анна/Desktop/cite_data/aan_release2014/aan/release/2014/acl-metadata.txt', 'r', encoding = 'latin-1') as f:\n",
    "    meta = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta = meta.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('b', 'h', 'm', 'k', 'i', '')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple('bahamakaia'.split('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = [tuple(meta_i.split('\\n')) for meta_i in meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id = {E03-1001}',\n",
       "  'author = {Oard, Douglas W.}',\n",
       "  'title = {Multilingual Access To Large Spoken Archives (Invited Talk)}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1002}',\n",
       "  'author = {Henderson, James B.}',\n",
       "  'title = {Neural Network Probability Estimation For Broad Coverage Parsing}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1003}',\n",
       "  'author = {Burstein, Jill; Wolska, Magdalena}',\n",
       "  'title = {Toward Evaluation Of Writing Style: Overly Repetitious Word Use}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1004}',\n",
       "  'author = {Cmejrek, Martin; Curin, Jan; Havelka, Jiri}',\n",
       "  'title = {Czech-English Dependency Tree-Based Machine Translation}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1005}',\n",
       "  'author = {Bod, Rens}',\n",
       "  'title = {An Efficient Implementation Of A New DOP Model}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1006}',\n",
       "  'author = {Smets, Martine; Gamon, Michael; Corston-Oliver, Simon H.; Ringger, Eric K.}',\n",
       "  'title = {French Amalgam: A Quick Adaptation Of A Sentence Realization System To French}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1007}',\n",
       "  'author = {Ueffing, Nicola; Ney, Hermann}',\n",
       "  'title = {Using POS Information For SMT Into Morphologically Rich Languages}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1008}',\n",
       "  'author = {Steedman, Mark; Osborne, Miles; Sarkar, Anoop; Clark, Stephen; Hwa, Rebecca; Hockenmaier, Julia; Ruhlen, Paul; Baker, Steven; Crim, Jeremiah}',\n",
       "  'title = {Bootstrapping Statistical Parsers From Small Datasets}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1009}',\n",
       "  'author = {Clark, Alexander}',\n",
       "  'title = {Combining Distributional And Morphological Information For Part Of Speech Induction}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1010}',\n",
       "  'author = {Yasuda, Keiji; Sugaya, Fumiaki; Takezawa, Toshiyuki; Yamamoto, Seiichi; Yanagida, Masuzo}',\n",
       "  \"title = {Automatic Evaluation For A Palpable Measure Of A Speech Translation System's Capability}\",\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1011}',\n",
       "  'author = {Dingli, Alexiei; Ciravegna, Fabio; Guthrie, David; Wilks, Yorick}',\n",
       "  'title = {Mining Web Sites Using Unsupervised Adaptive Information Extraction}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1012}',\n",
       "  'author = {Alexin, Zoltan; Gyimothy, Tibor; Hatvani, Csaba; Tihanyi, L&aacute;szl&oacute;; Csirik, J&aacute;nos; Bibok, Karoly; Pr&oacute;sz&eacute;ky, G&aacute;bor}',\n",
       "  'title = {Manually Annotated Hungarian Corpus}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1013}',\n",
       "  'author = {Hosaka, Junko; Koh, Judice; Konagaya, Akihiko}',\n",
       "  'title = {Effect Of Utilizing Terminology On Extraction Of Protein-Protein Interaction Information From Biomedical Literature}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1014}',\n",
       "  'author = {&#x17D;abokrtsk&yacute;, Zden&#x11B;k; Smr&zcaron;, Otakar}',\n",
       "  'title = {Arabic Syntactic Trees: From Constituency To Dependency}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1015}',\n",
       "  'author = {Poibeau, Thierry}',\n",
       "  'title = {The Multilingual Named Entity Recognition Framework}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1017}',\n",
       "  'author = {Horacek, Helmut}',\n",
       "  'title = {A Best-First Search Algorithm For Generating Referring Expressions}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1018}',\n",
       "  'author = {Bentivogli, Luisa; Pianta, Emanuele}',\n",
       "  'title = {Beyond Lexical Units: Enriching WordNets With Phrasets}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1019}',\n",
       "  'author = {Piwek, Paul}',\n",
       "  'title = {A Flexible Pragmatics-Driven Language Generator For Animated Agents}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1020}',\n",
       "  'author = {Dorow, Beate; Widdows, Dominic}',\n",
       "  'title = {Discovering Corpus-Specific Word Senses}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}'),\n",
       " ('id = {E03-1021}',\n",
       "  'author = {Sripada, Somayajulu G.; Reiter, Ehud; Hunter, Jim; Yu, Jin}',\n",
       "  'title = {Summarizing Neonatal Time Series Data}',\n",
       "  'venue = {EACL}',\n",
       "  'year = {2003}')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame(data = meta, columns = ['id','author', 'title', 'venue', 'year', 'nn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15204</th>\n",
       "      <td>id = {J11-2003}</td>\n",
       "      <td>author = {Surdeanu, Mihai; Ciaramita, Massimil...</td>\n",
       "      <td>title = {Learning to Rank Answers to Non-Factoid</td>\n",
       "      <td>Questions from Web Collections}</td>\n",
       "      <td>venue = {CL}</td>\n",
       "      <td>year = {2011}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                             author  \\\n",
       "15204  id = {J11-2003}  author = {Surdeanu, Mihai; Ciaramita, Massimil...   \n",
       "\n",
       "                                                  title  \\\n",
       "15204  title = {Learning to Rank Answers to Non-Factoid   \n",
       "\n",
       "                                 venue          year             nn  \n",
       "15204  Questions from Web Collections}  venue = {CL}  year = {2011}  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[metadata.nn.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title = {Learning to Rank Answers to Non-Factoid. Questions from Web Collections}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.iloc[15204].title + '. ' + metadata.iloc[15204].venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "metadata.ix[15204, 'title'] = metadata.iloc[15204].title + '. ' + metadata.iloc[15204].venue\n",
    "metadata.ix[15204, 'venue'] = metadata.iloc[15204].year\n",
    "metadata.ix[15204, 'year'] = metadata.iloc[15204].nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop('nn', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26059, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id = {E03-1001}</td>\n",
       "      <td>author = {Oard, Douglas W.}</td>\n",
       "      <td>title = {Multilingual Access To Large Spoken A...</td>\n",
       "      <td>venue = {EACL}</td>\n",
       "      <td>year = {2003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id = {E03-1002}</td>\n",
       "      <td>author = {Henderson, James B.}</td>\n",
       "      <td>title = {Neural Network Probability Estimation...</td>\n",
       "      <td>venue = {EACL}</td>\n",
       "      <td>year = {2003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id = {E03-1003}</td>\n",
       "      <td>author = {Burstein, Jill; Wolska, Magdalena}</td>\n",
       "      <td>title = {Toward Evaluation Of Writing Style: O...</td>\n",
       "      <td>venue = {EACL}</td>\n",
       "      <td>year = {2003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id = {E03-1004}</td>\n",
       "      <td>author = {Cmejrek, Martin; Curin, Jan; Havelka...</td>\n",
       "      <td>title = {Czech-English Dependency Tree-Based M...</td>\n",
       "      <td>venue = {EACL}</td>\n",
       "      <td>year = {2003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id = {E03-1005}</td>\n",
       "      <td>author = {Bod, Rens}</td>\n",
       "      <td>title = {An Efficient Implementation Of A New ...</td>\n",
       "      <td>venue = {EACL}</td>\n",
       "      <td>year = {2003}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                             author  \\\n",
       "0  id = {E03-1001}                        author = {Oard, Douglas W.}   \n",
       "1  id = {E03-1002}                     author = {Henderson, James B.}   \n",
       "2  id = {E03-1003}       author = {Burstein, Jill; Wolska, Magdalena}   \n",
       "3  id = {E03-1004}  author = {Cmejrek, Martin; Curin, Jan; Havelka...   \n",
       "4  id = {E03-1005}                               author = {Bod, Rens}   \n",
       "\n",
       "                                               title           venue  \\\n",
       "0  title = {Multilingual Access To Large Spoken A...  venue = {EACL}   \n",
       "1  title = {Neural Network Probability Estimation...  venue = {EACL}   \n",
       "2  title = {Toward Evaluation Of Writing Style: O...  venue = {EACL}   \n",
       "3  title = {Czech-English Dependency Tree-Based M...  venue = {EACL}   \n",
       "4  title = {An Efficient Implementation Of A New ...  venue = {EACL}   \n",
       "\n",
       "            year  \n",
       "0  year = {2003}  \n",
       "1  year = {2003}  \n",
       "2  year = {2003}  \n",
       "3  year = {2003}  \n",
       "4  year = {2003}  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E03-1001'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.iloc[0].id.split(' = ')[1].strip('{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x.split(' = ')[-1].strip('{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop(index=26058, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.applymap(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03-1001</td>\n",
       "      <td>Oard, Douglas W.</td>\n",
       "      <td>Multilingual Access To Large Spoken Archives (...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E03-1002</td>\n",
       "      <td>Henderson, James B.</td>\n",
       "      <td>Neural Network Probability Estimation For Broa...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E03-1003</td>\n",
       "      <td>Burstein, Jill; Wolska, Magdalena</td>\n",
       "      <td>Toward Evaluation Of Writing Style: Overly Rep...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E03-1004</td>\n",
       "      <td>Cmejrek, Martin; Curin, Jan; Havelka, Jiri</td>\n",
       "      <td>Czech-English Dependency Tree-Based Machine Tr...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E03-1005</td>\n",
       "      <td>Bod, Rens</td>\n",
       "      <td>An Efficient Implementation Of A New DOP Model</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E03-1006</td>\n",
       "      <td>Smets, Martine; Gamon, Michael; Corston-Oliver...</td>\n",
       "      <td>French Amalgam: A Quick Adaptation Of A Senten...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E03-1007</td>\n",
       "      <td>Ueffing, Nicola; Ney, Hermann</td>\n",
       "      <td>Using POS Information For SMT Into Morphologic...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E03-1008</td>\n",
       "      <td>Steedman, Mark; Osborne, Miles; Sarkar, Anoop;...</td>\n",
       "      <td>Bootstrapping Statistical Parsers From Small D...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E03-1009</td>\n",
       "      <td>Clark, Alexander</td>\n",
       "      <td>Combining Distributional And Morphological Inf...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E03-1010</td>\n",
       "      <td>Yasuda, Keiji; Sugaya, Fumiaki; Takezawa, Tosh...</td>\n",
       "      <td>Automatic Evaluation For A Palpable Measure Of...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E03-1011</td>\n",
       "      <td>Dingli, Alexiei; Ciravegna, Fabio; Guthrie, Da...</td>\n",
       "      <td>Mining Web Sites Using Unsupervised Adaptive I...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E03-1012</td>\n",
       "      <td>Alexin, Zoltan; Gyimothy, Tibor; Hatvani, Csab...</td>\n",
       "      <td>Manually Annotated Hungarian Corpus</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E03-1013</td>\n",
       "      <td>Hosaka, Junko; Koh, Judice; Konagaya, Akihiko</td>\n",
       "      <td>Effect Of Utilizing Terminology On Extraction ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E03-1014</td>\n",
       "      <td>&amp;#x17D;abokrtsk&amp;yacute;, Zden&amp;#x11B;k; Smr&amp;zca...</td>\n",
       "      <td>Arabic Syntactic Trees: From Constituency To D...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E03-1015</td>\n",
       "      <td>Poibeau, Thierry</td>\n",
       "      <td>The Multilingual Named Entity Recognition Fram...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E03-1017</td>\n",
       "      <td>Horacek, Helmut</td>\n",
       "      <td>A Best-First Search Algorithm For Generating R...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E03-1018</td>\n",
       "      <td>Bentivogli, Luisa; Pianta, Emanuele</td>\n",
       "      <td>Beyond Lexical Units: Enriching WordNets With ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E03-1019</td>\n",
       "      <td>Piwek, Paul</td>\n",
       "      <td>A Flexible Pragmatics-Driven Language Generato...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E03-1020</td>\n",
       "      <td>Dorow, Beate; Widdows, Dominic</td>\n",
       "      <td>Discovering Corpus-Specific Word Senses</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E03-1021</td>\n",
       "      <td>Sripada, Somayajulu G.; Reiter, Ehud; Hunter, ...</td>\n",
       "      <td>Summarizing Neonatal Time Series Data</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>E03-1022</td>\n",
       "      <td>Nerima, Luka; Seretan, Violeta; Wehrli, Eric</td>\n",
       "      <td>Creating A Multilingual Collocations Dictionar...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E03-1023</td>\n",
       "      <td>Utsuro, Takehito; Horiuchi, Takashi; Hamamoto,...</td>\n",
       "      <td>Effect Of Cross-Language IR In Bilingual Lexic...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>E03-1024</td>\n",
       "      <td>Koller, Alexander; Niehren, Joachim; Thater, S...</td>\n",
       "      <td>Underspecification Formalisms: Hole Semantics ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>E03-1025</td>\n",
       "      <td>Preiss, Judita</td>\n",
       "      <td>Using Grammatical Relations To Compare Parsers</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>E03-1026</td>\n",
       "      <td>Tiedemann, J&amp;ouml;rg</td>\n",
       "      <td>Combining Clues For Word Alignment</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>E03-1027</td>\n",
       "      <td>Erk, Katrin; Niehren, Joachim</td>\n",
       "      <td>Well-Nested Parallelism Constraints For Ellips...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>E03-1028</td>\n",
       "      <td>Penn, Gerald</td>\n",
       "      <td>AVM Description Compilation Using Types As Modes</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>E03-1029</td>\n",
       "      <td>Imamura, Kenji; Sumita, Eiichiro; Matsumoto, Yuji</td>\n",
       "      <td>Automatic Construction Of Machine Translation ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>E03-1030</td>\n",
       "      <td>Gardent, Claire; Kallmeyer, Laura</td>\n",
       "      <td>Semantic Construction In F-TAG</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>E03-1031</td>\n",
       "      <td>Yli-Jyra, Anssi</td>\n",
       "      <td>Describing Syntax With Star-Free Regular Expre...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26028</th>\n",
       "      <td>W14-3912</td>\n",
       "      <td>King, Levi; Baucom, Eric; Gilmanov, Timur; KÃ¼...</td>\n",
       "      <td>The IUCL+ System: Word-Level Language Identifi...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26029</th>\n",
       "      <td>W14-3913</td>\n",
       "      <td>Carpuat, Marine</td>\n",
       "      <td>Mixed Language and Code-Switching in the Canad...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26030</th>\n",
       "      <td>W14-3914</td>\n",
       "      <td>Bali, Kalika; Sharma, Jatin; Choudhury, Monoji...</td>\n",
       "      <td>I am borrowing ya mixing ? An Analysis of Engl...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26031</th>\n",
       "      <td>W14-3915</td>\n",
       "      <td>Barman, Utsab; Wagner, Joachim; ChrupaÅa, Grz...</td>\n",
       "      <td>DCU-UVT: Word-Level Language Classification wi...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>W14-3916</td>\n",
       "      <td>Shrestha, Prajwol</td>\n",
       "      <td>Incremental N-gram Approach for Language Ident...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26033</th>\n",
       "      <td>W14-3917</td>\n",
       "      <td>Bar, Kfir; Dershowitz, Nachum</td>\n",
       "      <td>The Tel Aviv University System for the Code-Sw...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26034</th>\n",
       "      <td>W14-4101</td>\n",
       "      <td>Wise, Alyssa</td>\n",
       "      <td>Keynote: Data Archeology: A theory informed ap...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>W14-4102</td>\n",
       "      <td>Sinha, Tanmay; Jermann, Patrick; Li, Nan; Dill...</td>\n",
       "      <td>Your click decides your fate: Inferring Inform...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26036</th>\n",
       "      <td>W14-4103</td>\n",
       "      <td>Moon, Seungwhan; Potdar, Saloni; Martin, Lara</td>\n",
       "      <td>Identifying Student Leaders from MOOC Discussi...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26037</th>\n",
       "      <td>W14-4104</td>\n",
       "      <td>Yang, Diyi; Wen, Miaomiao; Ros&amp;eacute;, Caroly...</td>\n",
       "      <td>Towards Identifying the Resolvability of Threa...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26038</th>\n",
       "      <td>W14-4105</td>\n",
       "      <td>Elouazizi, Noureddine</td>\n",
       "      <td>Point-of-View Mining and Cognitive Presence in...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26039</th>\n",
       "      <td>W14-4106</td>\n",
       "      <td>Jermann, Patrick</td>\n",
       "      <td>Keynote Talk: Analytics: climbing up the ladde...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26040</th>\n",
       "      <td>W14-4107</td>\n",
       "      <td>Ros&amp;eacute;, Carolyn Penstein; Siemens, George</td>\n",
       "      <td>Shared Task on Prediction of Dropout Over Time...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26041</th>\n",
       "      <td>W14-4108</td>\n",
       "      <td>Sinha, Tanmay; Li, Nan; Jermann, Patrick; Dill...</td>\n",
       "      <td>Capturing attrition intensifying structural tr...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26042</th>\n",
       "      <td>W14-4109</td>\n",
       "      <td>Sharkey, Mike; Sanders, Robert</td>\n",
       "      <td>A Process for Predicting MOOC Attrition</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>W14-4110</td>\n",
       "      <td>Amnueypornsakul, Bussaba; Bhat, Suma; Chinprut...</td>\n",
       "      <td>Predicting Attrition Along the Way: The UIUC M...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>W14-4111</td>\n",
       "      <td>Kloft, Marius; Stiehler, Felix; Zheng, Zhilin;...</td>\n",
       "      <td>Predicting MOOC Dropout over Weeks Using Machi...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>W14-4201</td>\n",
       "      <td>Habash, Nizar</td>\n",
       "      <td>INVITED TALK 1: Computational Processing of Ar...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>W14-4202</td>\n",
       "      <td>Kanayama, Hiroshi; Park, Youngja; Tsuboi, Yuta...</td>\n",
       "      <td>Learning from a Neighbor: Adapting a Japanese ...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>W14-4203</td>\n",
       "      <td>AgiÄ, Å½eljko; AgiÄ, Å½eljko; Tiedemann, JÃ¶...</td>\n",
       "      <td>Cross-lingual Dependency Parsing of Related La...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26048</th>\n",
       "      <td>W14-4204</td>\n",
       "      <td>Maier, Wolfgang; GÃ³mez-RodrÃ­guez, Carlos</td>\n",
       "      <td>Language variety identification in Spanish tweets</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26049</th>\n",
       "      <td>W14-4205</td>\n",
       "      <td>Abbas, Qaiser</td>\n",
       "      <td>Exploiting Language Variants Via Grammar Parsi...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26050</th>\n",
       "      <td>W14-4206</td>\n",
       "      <td>Bhat, Riyaz Ahmad; Jain, Naman; Vaidya, Ashwin...</td>\n",
       "      <td>Adapting Predicate Frames for Urdu PropBanking</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26051</th>\n",
       "      <td>W14-4207</td>\n",
       "      <td>Nouri, Javad; Yangarber, Roman</td>\n",
       "      <td>Measuring Language Closeness by Modeling Regul...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26052</th>\n",
       "      <td>W14-4208</td>\n",
       "      <td>Petrov, Slav</td>\n",
       "      <td>INVITED TALK 2: Towards Universal Syntactic Pr...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26053</th>\n",
       "      <td>W14-4209</td>\n",
       "      <td>Miyazaki, Taro; Kato, Naoto; Inoue, Seiki; Ume...</td>\n",
       "      <td>Proper Name Machine Translation from Japanese ...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26054</th>\n",
       "      <td>W14-4210</td>\n",
       "      <td>PopoviÄ, Maja; LjubeÅ¡iÄ, Nikola</td>\n",
       "      <td>Exploring cross-language statistical machine t...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26055</th>\n",
       "      <td>W14-4211</td>\n",
       "      <td>Singla, Karan; Singh, Anupam; Shastri, Nishkar...</td>\n",
       "      <td>Exploring System Combination approaches for In...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26056</th>\n",
       "      <td>W14-4212</td>\n",
       "      <td>Kubon, Vladislav; Kubo&amp;#x148;, Vladislav; Vici...</td>\n",
       "      <td>A Comparison of MT Methods for Closely Related...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26057</th>\n",
       "      <td>W14-4213</td>\n",
       "      <td>Aminian, Maryam; Ghoneim, Mahmoud; Diab, Mona</td>\n",
       "      <td>Handling OOV Words in Dialectal Arabic to Engl...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26058 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                             author  \\\n",
       "0      E03-1001                                   Oard, Douglas W.   \n",
       "1      E03-1002                                Henderson, James B.   \n",
       "2      E03-1003                  Burstein, Jill; Wolska, Magdalena   \n",
       "3      E03-1004         Cmejrek, Martin; Curin, Jan; Havelka, Jiri   \n",
       "4      E03-1005                                          Bod, Rens   \n",
       "5      E03-1006  Smets, Martine; Gamon, Michael; Corston-Oliver...   \n",
       "6      E03-1007                      Ueffing, Nicola; Ney, Hermann   \n",
       "7      E03-1008  Steedman, Mark; Osborne, Miles; Sarkar, Anoop;...   \n",
       "8      E03-1009                                   Clark, Alexander   \n",
       "9      E03-1010  Yasuda, Keiji; Sugaya, Fumiaki; Takezawa, Tosh...   \n",
       "10     E03-1011  Dingli, Alexiei; Ciravegna, Fabio; Guthrie, Da...   \n",
       "11     E03-1012  Alexin, Zoltan; Gyimothy, Tibor; Hatvani, Csab...   \n",
       "12     E03-1013      Hosaka, Junko; Koh, Judice; Konagaya, Akihiko   \n",
       "13     E03-1014  &#x17D;abokrtsk&yacute;, Zden&#x11B;k; Smr&zca...   \n",
       "14     E03-1015                                   Poibeau, Thierry   \n",
       "15     E03-1017                                    Horacek, Helmut   \n",
       "16     E03-1018                Bentivogli, Luisa; Pianta, Emanuele   \n",
       "17     E03-1019                                        Piwek, Paul   \n",
       "18     E03-1020                     Dorow, Beate; Widdows, Dominic   \n",
       "19     E03-1021  Sripada, Somayajulu G.; Reiter, Ehud; Hunter, ...   \n",
       "20     E03-1022       Nerima, Luka; Seretan, Violeta; Wehrli, Eric   \n",
       "21     E03-1023  Utsuro, Takehito; Horiuchi, Takashi; Hamamoto,...   \n",
       "22     E03-1024  Koller, Alexander; Niehren, Joachim; Thater, S...   \n",
       "23     E03-1025                                     Preiss, Judita   \n",
       "24     E03-1026                               Tiedemann, J&ouml;rg   \n",
       "25     E03-1027                      Erk, Katrin; Niehren, Joachim   \n",
       "26     E03-1028                                       Penn, Gerald   \n",
       "27     E03-1029  Imamura, Kenji; Sumita, Eiichiro; Matsumoto, Yuji   \n",
       "28     E03-1030                  Gardent, Claire; Kallmeyer, Laura   \n",
       "29     E03-1031                                    Yli-Jyra, Anssi   \n",
       "...         ...                                                ...   \n",
       "26028  W14-3912  King, Levi; Baucom, Eric; Gilmanov, Timur; KÃ¼...   \n",
       "26029  W14-3913                                    Carpuat, Marine   \n",
       "26030  W14-3914  Bali, Kalika; Sharma, Jatin; Choudhury, Monoji...   \n",
       "26031  W14-3915  Barman, Utsab; Wagner, Joachim; ChrupaÅa, Grz...   \n",
       "26032  W14-3916                                  Shrestha, Prajwol   \n",
       "26033  W14-3917                      Bar, Kfir; Dershowitz, Nachum   \n",
       "26034  W14-4101                                       Wise, Alyssa   \n",
       "26035  W14-4102  Sinha, Tanmay; Jermann, Patrick; Li, Nan; Dill...   \n",
       "26036  W14-4103      Moon, Seungwhan; Potdar, Saloni; Martin, Lara   \n",
       "26037  W14-4104  Yang, Diyi; Wen, Miaomiao; Ros&eacute;, Caroly...   \n",
       "26038  W14-4105                              Elouazizi, Noureddine   \n",
       "26039  W14-4106                                   Jermann, Patrick   \n",
       "26040  W14-4107     Ros&eacute;, Carolyn Penstein; Siemens, George   \n",
       "26041  W14-4108  Sinha, Tanmay; Li, Nan; Jermann, Patrick; Dill...   \n",
       "26042  W14-4109                     Sharkey, Mike; Sanders, Robert   \n",
       "26043  W14-4110  Amnueypornsakul, Bussaba; Bhat, Suma; Chinprut...   \n",
       "26044  W14-4111  Kloft, Marius; Stiehler, Felix; Zheng, Zhilin;...   \n",
       "26045  W14-4201                                      Habash, Nizar   \n",
       "26046  W14-4202  Kanayama, Hiroshi; Park, Youngja; Tsuboi, Yuta...   \n",
       "26047  W14-4203  AgiÄ, Å½eljko; AgiÄ, Å½eljko; Tiedemann, JÃ¶...   \n",
       "26048  W14-4204         Maier, Wolfgang; GÃ³mez-RodrÃ­guez, Carlos   \n",
       "26049  W14-4205                                      Abbas, Qaiser   \n",
       "26050  W14-4206  Bhat, Riyaz Ahmad; Jain, Naman; Vaidya, Ashwin...   \n",
       "26051  W14-4207                     Nouri, Javad; Yangarber, Roman   \n",
       "26052  W14-4208                                       Petrov, Slav   \n",
       "26053  W14-4209  Miyazaki, Taro; Kato, Naoto; Inoue, Seiki; Ume...   \n",
       "26054  W14-4210                 PopoviÄ, Maja; LjubeÅ¡iÄ, Nikola   \n",
       "26055  W14-4211  Singla, Karan; Singh, Anupam; Shastri, Nishkar...   \n",
       "26056  W14-4212  Kubon, Vladislav; Kubo&#x148;, Vladislav; Vici...   \n",
       "26057  W14-4213      Aminian, Maryam; Ghoneim, Mahmoud; Diab, Mona   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Multilingual Access To Large Spoken Archives (...   \n",
       "1      Neural Network Probability Estimation For Broa...   \n",
       "2      Toward Evaluation Of Writing Style: Overly Rep...   \n",
       "3      Czech-English Dependency Tree-Based Machine Tr...   \n",
       "4         An Efficient Implementation Of A New DOP Model   \n",
       "5      French Amalgam: A Quick Adaptation Of A Senten...   \n",
       "6      Using POS Information For SMT Into Morphologic...   \n",
       "7      Bootstrapping Statistical Parsers From Small D...   \n",
       "8      Combining Distributional And Morphological Inf...   \n",
       "9      Automatic Evaluation For A Palpable Measure Of...   \n",
       "10     Mining Web Sites Using Unsupervised Adaptive I...   \n",
       "11                   Manually Annotated Hungarian Corpus   \n",
       "12     Effect Of Utilizing Terminology On Extraction ...   \n",
       "13     Arabic Syntactic Trees: From Constituency To D...   \n",
       "14     The Multilingual Named Entity Recognition Fram...   \n",
       "15     A Best-First Search Algorithm For Generating R...   \n",
       "16     Beyond Lexical Units: Enriching WordNets With ...   \n",
       "17     A Flexible Pragmatics-Driven Language Generato...   \n",
       "18               Discovering Corpus-Specific Word Senses   \n",
       "19                 Summarizing Neonatal Time Series Data   \n",
       "20     Creating A Multilingual Collocations Dictionar...   \n",
       "21     Effect Of Cross-Language IR In Bilingual Lexic...   \n",
       "22     Underspecification Formalisms: Hole Semantics ...   \n",
       "23        Using Grammatical Relations To Compare Parsers   \n",
       "24                    Combining Clues For Word Alignment   \n",
       "25     Well-Nested Parallelism Constraints For Ellips...   \n",
       "26      AVM Description Compilation Using Types As Modes   \n",
       "27     Automatic Construction Of Machine Translation ...   \n",
       "28                        Semantic Construction In F-TAG   \n",
       "29     Describing Syntax With Star-Free Regular Expre...   \n",
       "...                                                  ...   \n",
       "26028  The IUCL+ System: Word-Level Language Identifi...   \n",
       "26029  Mixed Language and Code-Switching in the Canad...   \n",
       "26030  I am borrowing ya mixing ? An Analysis of Engl...   \n",
       "26031  DCU-UVT: Word-Level Language Classification wi...   \n",
       "26032  Incremental N-gram Approach for Language Ident...   \n",
       "26033  The Tel Aviv University System for the Code-Sw...   \n",
       "26034  Keynote: Data Archeology: A theory informed ap...   \n",
       "26035  Your click decides your fate: Inferring Inform...   \n",
       "26036  Identifying Student Leaders from MOOC Discussi...   \n",
       "26037  Towards Identifying the Resolvability of Threa...   \n",
       "26038  Point-of-View Mining and Cognitive Presence in...   \n",
       "26039  Keynote Talk: Analytics: climbing up the ladde...   \n",
       "26040  Shared Task on Prediction of Dropout Over Time...   \n",
       "26041  Capturing attrition intensifying structural tr...   \n",
       "26042            A Process for Predicting MOOC Attrition   \n",
       "26043  Predicting Attrition Along the Way: The UIUC M...   \n",
       "26044  Predicting MOOC Dropout over Weeks Using Machi...   \n",
       "26045  INVITED TALK 1: Computational Processing of Ar...   \n",
       "26046  Learning from a Neighbor: Adapting a Japanese ...   \n",
       "26047  Cross-lingual Dependency Parsing of Related La...   \n",
       "26048  Language variety identification in Spanish tweets   \n",
       "26049  Exploiting Language Variants Via Grammar Parsi...   \n",
       "26050     Adapting Predicate Frames for Urdu PropBanking   \n",
       "26051  Measuring Language Closeness by Modeling Regul...   \n",
       "26052  INVITED TALK 2: Towards Universal Syntactic Pr...   \n",
       "26053  Proper Name Machine Translation from Japanese ...   \n",
       "26054  Exploring cross-language statistical machine t...   \n",
       "26055  Exploring System Combination approaches for In...   \n",
       "26056  A Comparison of MT Methods for Closely Related...   \n",
       "26057  Handling OOV Words in Dialectal Arabic to Engl...   \n",
       "\n",
       "                                                   venue  year  \n",
       "0                                                   EACL  2003  \n",
       "1                                                   EACL  2003  \n",
       "2                                                   EACL  2003  \n",
       "3                                                   EACL  2003  \n",
       "4                                                   EACL  2003  \n",
       "5                                                   EACL  2003  \n",
       "6                                                   EACL  2003  \n",
       "7                                                   EACL  2003  \n",
       "8                                                   EACL  2003  \n",
       "9                                                   EACL  2003  \n",
       "10                                                  EACL  2003  \n",
       "11                                                  EACL  2003  \n",
       "12                                                  EACL  2003  \n",
       "13                                                  EACL  2003  \n",
       "14                                                  EACL  2003  \n",
       "15                                                  EACL  2003  \n",
       "16                                                  EACL  2003  \n",
       "17                                                  EACL  2003  \n",
       "18                                                  EACL  2003  \n",
       "19                                                  EACL  2003  \n",
       "20                                                  EACL  2003  \n",
       "21                                                  EACL  2003  \n",
       "22                                                  EACL  2003  \n",
       "23                                                  EACL  2003  \n",
       "24                                                  EACL  2003  \n",
       "25                                                  EACL  2003  \n",
       "26                                                  EACL  2003  \n",
       "27                                                  EACL  2003  \n",
       "28                                                  EACL  2003  \n",
       "29                                                  EACL  2003  \n",
       "...                                                  ...   ...  \n",
       "26028  Workshop on Computational Approaches to Code S...  2014  \n",
       "26029  Workshop on Computational Approaches to Code S...  2014  \n",
       "26030  Workshop on Computational Approaches to Code S...  2014  \n",
       "26031  Workshop on Computational Approaches to Code S...  2014  \n",
       "26032  Workshop on Computational Approaches to Code S...  2014  \n",
       "26033  Workshop on Computational Approaches to Code S...  2014  \n",
       "26034  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26035  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26036  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26037  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26038  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26039  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26040  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26041  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26042  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26043  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26044  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "26045                                       LT4CloseLang  2014  \n",
       "26046                                       LT4CloseLang  2014  \n",
       "26047                                       LT4CloseLang  2014  \n",
       "26048                                       LT4CloseLang  2014  \n",
       "26049                                       LT4CloseLang  2014  \n",
       "26050                                       LT4CloseLang  2014  \n",
       "26051                                       LT4CloseLang  2014  \n",
       "26052                                       LT4CloseLang  2014  \n",
       "26053                                       LT4CloseLang  2014  \n",
       "26054                                       LT4CloseLang  2014  \n",
       "26055                                       LT4CloseLang  2014  \n",
       "26056                                       LT4CloseLang  2014  \n",
       "26057                                       LT4CloseLang  2014  \n",
       "\n",
       "[26058 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop_duplicates('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv('papers_meta.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23775, 5)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/Анна/Desktop/cite_data/aan_release2014/aan/release/2014/acl.txt', 'r', encoding = 'latin-1') as f:\n",
    "    links = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C08-3004 ==> A00-1002',\n",
       " 'D09-1141 ==> A00-1002',\n",
       " 'D12-1027 ==> A00-1002',\n",
       " 'E06-1047 ==> A00-1002',\n",
       " 'H05-1110 ==> A00-1002',\n",
       " 'N01-1020 ==> A00-1002',\n",
       " 'N13-1036 ==> A00-1002',\n",
       " 'P13-2001 ==> A00-1002',\n",
       " 'P13-2073 ==> A00-1002',\n",
       " 'W11-2602 ==> A00-1002',\n",
       " 'W13-2702 ==> A00-1002',\n",
       " 'C10-1054 ==> A00-1004',\n",
       " 'P15-1001 ==> A00-1004',\n",
       " 'W06-1008 ==> A00-1004',\n",
       " 'W03-0704 ==> A00-1005',\n",
       " 'W03-1206 ==> A00-1005',\n",
       " 'P00-1054 ==> A00-1006',\n",
       " 'W02-0208 ==> A00-1007',\n",
       " 'W03-2128 ==> A00-1007',\n",
       " 'W08-0123 ==> A00-1008']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [tuple(link.split(' ==> ')) for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.DataFrame(data=links, columns = ['citing', 'cited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124843, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.to_csv('papers_citations.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slurp(path):\n",
    "    with open(path, 'r', encoding = 'utf-8') as file_object:\n",
    "        return file_object.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03-1001</td>\n",
       "      <td>Oard, Douglas W.</td>\n",
       "      <td>Multilingual Access To Large Spoken Archives (...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E03-1002</td>\n",
       "      <td>Henderson, James B.</td>\n",
       "      <td>Neural Network Probability Estimation For Broa...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E03-1003</td>\n",
       "      <td>Burstein, Jill; Wolska, Magdalena</td>\n",
       "      <td>Toward Evaluation Of Writing Style: Overly Rep...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E03-1004</td>\n",
       "      <td>Cmejrek, Martin; Curin, Jan; Havelka, Jiri</td>\n",
       "      <td>Czech-English Dependency Tree-Based Machine Tr...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E03-1005</td>\n",
       "      <td>Bod, Rens</td>\n",
       "      <td>An Efficient Implementation Of A New DOP Model</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                      author  \\\n",
       "0  E03-1001                            Oard, Douglas W.   \n",
       "1  E03-1002                         Henderson, James B.   \n",
       "2  E03-1003           Burstein, Jill; Wolska, Magdalena   \n",
       "3  E03-1004  Cmejrek, Martin; Curin, Jan; Havelka, Jiri   \n",
       "4  E03-1005                                   Bod, Rens   \n",
       "\n",
       "                                               title venue  year  \n",
       "0  Multilingual Access To Large Spoken Archives (...  EACL  2003  \n",
       "1  Neural Network Probability Estimation For Broa...  EACL  2003  \n",
       "2  Toward Evaluation Of Writing Style: Overly Rep...  EACL  2003  \n",
       "3  Czech-English Dependency Tree-Based Machine Tr...  EACL  2003  \n",
       "4     An Efficient Implementation Of A New DOP Model  EACL  2003  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = 'D:/Анна/Desktop/cite_data/aan_release2014/aan/papers_text/'\n",
    "\n",
    "texts = []\n",
    "for path in tqdm_notebook(metadata.id):\n",
    "    path += '.txt'\n",
    "    text = ''\n",
    "    try:\n",
    "        text = slurp(foldername + path)\n",
    "    except:\n",
    "#         print(path)\n",
    "        pass\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26058, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26058"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.DataFrame(data = list(zip(metadata.id.values, texts)), columns = ['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.drop_duplicates('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23775, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(825, 2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[papers.text == ''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_len = lambda x: len(x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['text_len'] = papers.apply(f_len, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Text Mining - Next Steps for Drug Discovery \\n \\nWilliam S Hayes, PhD, Discovery IS/IX, AstraZeneca R&D \\n35 Gatehouse Dr, Waltham, MA, 02451 USA \\nWilliam.S.Hayes@astrazeneca.com \\n \\nThe text mining community has shown significant impact for use of text mining in \\ndrug discovery and basic research.  So far, there have been a lot of point \\nsolutions that have solved a particular problem or augmented a valuable \\ndatabase.  The next step is integrating text mining as part of the entire literature \\nanalytic solution and delivering it effectively and comprehensively to support \\nresearch in academia, biotechs and pharmaceuticals. \\n \\n                                            Association for Computational Linguistics.\\n                      Linking Biological Literature, Ontologies and Databases, pg. 49.\\n                                                HLT-NAACL 2004 Workshop: Biolink 2004,\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[papers.id == 'W04-3107'].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.to_csv('papers_text.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214465"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.text_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_text = papers[papers.text_len > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22761, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_text.text_len.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124843, 2)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_with_text = links[(links.citing.isin(papers_with_text.id.values))&(links.cited.isin(papers_with_text.id.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_with_text.to_csv('papers_links_with_text.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_text.to_csv('papers_with_text.to_csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata.id.isin(papers_with_text.id.values)].to_csv('metadata_with_text.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Flexible Pragmatics-driven Language Generator for Animated Agents\\nPaul Piwek\\nITRI ? Information Technology Research Institute\\nUniversity of Brighton\\nPaul.Piwek@itri.bton.ac.uk\\nAbstract\\nThis paper describes the NECA MNLG;\\na fully implemented Multimodal Natu-\\nral Language Generation module. The\\nMNLG is deployed as part of the NECA\\nsystem which generates dialogues be-\\ntween animated agents. The genera-\\ntion module supports the seamless inte-\\ngration of full grammar rules, templates\\nand canned text. The generator takes in-\\nput which allows for the specification of\\nsyntactic, semantic and pragmatic con-\\nstraints on the output.\\n1 Introduction\\nThis paper introduces the NECA MNLG; a Multi-\\nmodal Natural Language Generator. It has been\\ndeveloped in the context of the NECA system.1\\nThe NECA system generates dialogue scripts for\\nanimated characters. A first demonstrator in the\\ncar sales domain (ESHOWROOM) has been imple-\\nmented. It allows a user to browse a database of\\ncars, select a car, select two characters and their\\nattributes, and subsequently view an automatically\\ngenerated film of a dialogue about the selected car.\\nThe demonstrator takes the following input:\\n? A database with facts about the selected car (maximum\\nspeed, horse power, etc.).\\n? A database which correlates facts with value judge-\\nments.\\n1NECA stands for ?Net Environment for Embodied Emo-\\ntional Conversational Agents? and is an EU-IST project.\\n? Information about the characters: 1. Personality traits\\nsuch as extroversion and agreeableness. 2. Personal\\npreferences concerning cars (e.g., a preference for safe\\ncars). 3. Role of the character (seller or customer).\\nThis input is processed in a pipeline that consists\\nof the following modules in this order:\\n? A DIALOGUE PLANNER, which produces an abstract\\ndescription of the dialogue (the dialogue plan).\\n? A MULTI-MODAL NATURAL LANGUAGE GENERA-\\nTOR which specifies linguistic and non-linguistic real-\\nizations for the dialogue acts in the dialogue plan.\\n? A SPEECH SYNTHESIS MODULE, which adds infor-\\nmation for Speech.\\n? A GESTURE ASSIGNMENT MODULE, which controls\\nthe temporal coordination of gestures and speech.\\n? A PLAYER, which plays the animated characters and\\nthe corresponding speech sound files.\\nEach step in the pipeline adds more concrete in-\\nformation to the dialogue plan/script until finally\\na player can render it. A single XML compliant\\nrepresentation language, called RRL, has been de-\\nveloped for representing the Dialogue Script at its\\nvarious stages of completion (Piwek et al, 2002).\\nIn this paper, we describe the requirements for\\nthe NECA MNLG, how these have been translated\\ninto design solutions and finally some of aspects\\nof the implementation.\\n2 Requirements\\nThe requirements in this section derive primarly\\nfrom the use case of the NECA system. We do,\\nhowever, try to indicate in what respects these re-\\nquirements transcend this specific application and\\nare desirable for generation systems in general.\\nREQUIREMENT 1: The linguistic resources of the gen-\\nerator should support seamless integration of canned text,\\ntemplates and full grammar rules.\\nIn the NECA system, the dialogue planner creates\\na dialogue plan consisting of (1) a description\\nof the participants, (2) a characterization of the\\ncommon ground at the outset of the dialogue in\\nterms of Discourse Representation Theory (Kamp\\nand Reyle, 1993) and (3) a set of dialogue acts\\nand their temporal ordering. For each dialogue\\nact, the type, speaker, set of addressees, semantic\\ncontent, what it is a reaction to (i.e., its rhetorical\\nrelation to other dialogue acts), and emotions\\nof the speaker can be specified. The amount of\\ninformation which the dialogue planner actually\\nprovides for each of these attributes varies,\\nhowever, per dialogue act: for some dialogue acts,\\na full semantic content can be provided ?in the\\nform of a Discourse Representation Structure?\\nwhereas for other acts, no semantic content is\\navailable at all. Typically, the dialogue planner\\ncan provide detailed semantics for utterances\\nwhose content is covered by the domain model\\n(e.g., the car domain) whereas this is not possible\\nfor utterances which play an important role in the\\nconversation but are not part of the domain model\\n(e.g., greetings). This state of affairs is shared\\nwith most real-world applications.\\nSince generation by grammar rules is primarily\\ndriven by the input semantics, for certain dialogue\\nacts full grammar rules cannot be used. These\\ndialogue acts may be primarily characterized in\\nterms of their, possibly domain specific, dialogue\\nact type (greeting, refusal, etc.). Thus, we need\\na generator which can cope with both types of\\ninput, and map them to the appropriate output.\\nInput with little or no semantic content can typ-\\nically be dealt with through templates or canned\\ntext, whereas input with fully specified semantic\\ncontent can be dealt with through proper grammar\\nrules. Summarizing, we need a generator which\\ncan cope with (linguistic) resources that contain\\nan arbritary combination of grammar rules,\\ntemplates and canned text.\\nREQUIREMENT 2: The generator should allow for\\ncombinations of different types of constraints on its the out-\\nput, such as syntactic, semantic and pragmatic constraints\\nIn the NECA project the aim is to generate\\nbehaviour for animated agents which simulates\\naffective situated face-to-face conversational\\ninteraction. This means that the utterances of the\\nagents have to be adapted not only to the content\\nof the information which is exchanged but also to\\nmany other properties of the interlocutors, such as\\ntheir emotional state, gender, cultural background,\\netc. The generator should therefore allow for such\\nparameters to be part of its input.\\nREQUIREMENT 3: The generator should be sufficiently fast\\nto be of use in real-world applications\\nThe application in which our generator is\\nbeing used is currently fielded as part of a net-\\nenvironment. The application will be evaluated\\nwith users through online questionnaires which\\nare integrated in the application and analysis of\\nlog files (to answer questions such as ?Do users\\ntry different settings of the application??, etc. See\\nKrenn et al, 2002). Therefore, the generator will\\nhave to be fast in order for it not to negatively\\naffect the user experience of the system.\\n3 Design Solutions\\nThe NECA MNLG adopts the conventional pipeline\\narchitecture for generators (Reiter and Dale,\\n2000). Its input is a RRL dialogue plan. This\\nis parsed and internally represented as a PROFIT\\ntyped feature structure (Erbach, 1995). Subse-\\nquently, the dialogue acts in the plan are realized\\nin accordance with their temporal order. For each\\nact, first a deep syntactic structure is generated.\\nThe deep structure of referring expressions is dealt\\nwith in a separate module, which takes the com-\\nmon ground of the interlocutors into account. Sub-\\nsequently, lexical realization (agreement, inflec-\\ntion) and punctuation is performed. Finally, turn-\\ntaking gestures are added and the output is mapped\\nback into the RRL XML format.\\nHere let us concentrate on our approach to the\\ngeneration of deep syntactic structure and how it\\nsatisfies the first two requirements. The input to\\nthe MNLG is a node (i.e., feature structure) stipu-\\nlating the syntactic type of the output (e.g., sen-\\ntence: <s), semantics and further information on\\nthe current dialogue act in PROFIT:2\\n(<s &\\nsem!drs([c_27],\\n[type(c_27,prestigious),\\narg1(c_27,x_1)])&\\ncurrentAct!speaker!\\n(name!john &\\npolite!yes & ...)\\n)\\nThus various types of information are combined\\nwithin one input node. Generation consists of tak-\\ning the input node and using it to create a tree\\nrepresentation of the output. For this purpose,\\nthe MNLG tries to match the input node with the\\nmother node of one of the trees in its tree repos-\\nitory. This tree repository contains trees which\\ncan represent proper grammar rules, templates and\\ncanned text. Matching trees might in turn have in-\\ncomplete daughter nodes. These are recursively\\nexpanded by matching them with the trees in the\\nrepository, until all daughters are complete.\\nA daughter node is complete if it is lexically\\nrealized (i.e., the attribute form of the node has\\na value) or it is of the type <np and the seman-\\ntics is an open variable. In the latter instance, the\\nnode is expanded in a separate step by the refer-\\nring expressions generation module. This module\\nfinds the discourse referent in the common ground\\nwhich binds the open variable and constructs a de-\\nscription of the object in question. The descrip-\\ntion is composed of the properties which the ob-\\nject has according to the common ground, but can\\nalso be empty if the object is highly salient. The\\nmodule is based on the work of Krahmer and The-\\nune (2002). The (empty) description is mapped\\nto a deep syntactic structure using the tree repos-\\nitory. Lexicalization subsequently yields expres-\\nsions such as ?it? (empty descriptive content) or,\\nfor instance, ?the red car?.\\nLet us return to the tree repository and illus-\\ntrate how templates and rules can be represented\\nuniformly. The representation of a tree is of the\\n2That is, PROLOG with some sugaring for the rep-\\nresentation of feature structures. Feature structures are\\nalso used in the FUF/SURGE generator. It is different\\nfrom the NECA MNLG in that it takes as input thematic\\ntrees with content words. Furthermore, it allows for con-\\ntrol annotations in the grammar and uses a special inter-\\npreter for unification, rather than directly PROLOG. See\\nhttp://www.cs.bgu.ac.il/surge/.\\nform (Node,[Tree1,Tree2,...]), where\\nthe list of trees can be empty, yielding a tree con-\\nsisting of one node: (Node,[]). The following\\nis a template for dialogue acts of type greeting\\nwith no semantic content and a polite speaker.\\n(<s &\\ncurrentAct!\\n(type!greeting &\\nspeaker!polite!\"yes\" &\\nspeaker!name!Speaker) &\\nsem!\"none\",\\n[(<s & form!\"hello!\",[]),\\n(<fragment &\\nform!\"My name is\",[]),\\n(<np &\\nsem!concept(Speaker),[])\\n]).\\nThis is a template for the text ?Hello! My name is\\nSPEAKER?. Where SPEAKER is a variable which\\nis bound to the name of the speaker of the utter-\\nance. The noun phrase (<np) for this name is gen-\\nerated by the referring expression generation mod-\\nule. The following is a tree representing a gram-\\nmar rule of the familiar type S ? NP VP:\\n(<s &\\ncurrentAct!type!statement &\\ncurrentAct!CA &\\nargGap!ArgGap &\\nauxGap!AuxGap &\\nsem!drs(_,[negation(\\ndrs(_,\\n[type(E,Type)\\narg1(E,X)|R]))]\\n),\\n[(<np &\\ncurrentAct!CA &\\nsem!X,[]),\\n(<vp &\\nargGap!ArgGap &\\nauxGap!AuxGap &\\nnegated!<true &\\nsem!drs(_,[type(E,Type)|R]) &\\ncurrentAct!CA,_)\\n]).\\nNote that this rule applies to an input node whose\\nsemantic content contains a negation. The nega-\\ntion is passed on to the VP subtree via the feature\\nnegated. The attributes argGap and auxGap\\nallow us to capture unbounded dependencies via\\nfeature perlocation. Our use of trees is related to\\nthe Tree Adjoining Grammar approach to genera-\\ntion (e.g., Stone and Doran, 1997).3\\n3Their generation algorithm is, however, very different\\nfrom the one proposed here. Whereas they propose an in-\\ntegrated planning approach, we advocate a very modular sys-\\nThe value of the attribute currentAct is\\npassed on from the mother node to the daughter\\nnodes. Thus any pragmatic information (personal-\\nity, politeness, emotion, etc.) is passed on through\\nthe tree and can be accessed at a later stage, for\\ninstance, when lexical items are selected.\\n4 Implementation\\nThe NECA MNLG has been implemented in PRO-\\nLOG. The output is in the form of an RRL XML\\ndocument. Table 1 provides a sample of the re-\\nsponse times of the compiled code running on a\\nPentium III Mobile 1200 Mhz with Sicstus 3.8.5\\nPROLOG. We timed the complete generation pro-\\ncess from parsing the XML input to producing\\nXML output, including generation of deep syn-\\ntactic structure, referring expressions, turn taking\\ngestures (not discussed in this paper), etc.\\ninput # acts = 1 ? 10\\nA 19 0.230s 0.741s\\nB 22 0.290s 0.872s\\nC 23 0.290s 0.801s\\nD 31 0.431s 1.372s\\nTable 1: Response Times of the MNLG\\nThe results show generation times for entire di-\\nalogues and according to whether the generator\\nwas asked to produce exactly one solution or se-\\nlect at random a solution from a set of at most ten\\ngenerated solutions (the latter strategy was imple-\\nmented to obtain more variation in the generator\\noutput). On average for = 1 the generation time\\nfor an individual dialogue act is almost 1100 of a\\nsecond. For ? 10 it is 4100 of a second. The\\ngenerator uses a repository of 138 trees (includ-\\ning the two examples given above). The repos-\\nitory has been developed for and integrated into\\nthe ESHOWROOM system which is currently be-\\ning fielded. A start is being made with porting the\\nMNLG to a new domain and documentation is be-\\ning created to allow our project partners to carry\\nout this task. We hope that our efforts will con-\\ntribute to addressing a challenge expressed in (Re-\\ntem, supporting fast generation. Moreover, by using features\\nfor unbounded dependencies we do not require the adjunction\\noperation, which is incompatible with our topdown genera-\\ntion approach. We follow Nicolov et al (1996), who also use\\nTAG, in their commitment to flat semantics. Their generator\\ndoes, however, not take pragmatic constraints into account.\\niter, 1999): ?We hope that future systems such as\\nSTOP will be able to make more use of deep tech-\\nniques, because of advances in linguistics and the\\ndevelopment of reusable wide-coverage NLG com-\\nponents that are robust, well-documented and well\\nengineered as software artifacts.?\\nIn our view the best way to approach this goal\\nis by providing a framework which allows for the\\nflexible integration of shallow and deep genera-\\ntion, thus making it possible that in the course of\\nvarious projects, deep analyses can be developed\\nalongside the shallow solutions which are diffi-\\ncult to avoid altogether in software development\\nprojects, due to the pressure to deliver a complete\\nsystem within a certain span of time.\\nAcknowledgements\\nThis research is supported by the EU Project NECA\\nIST-2000-28580. For comments and discussion\\nthanks are due the EACL reviewers and my col-\\nleagues in the NECA project.\\nReferences\\nGregor Erbach. 1995. PROFIT 1.54 user?s guide. University\\nof the Saarland, December 3, 1995.\\nHans Kamp and Uwe Reyle. 1993. From Discourse to\\nLogic. Kluwer, Dordrecht.\\nEmiel Krahmer and Marie?t Theune. 2002. Efficient context-\\nsensitive generation of referring expressions. In: Kees\\nVan Deemter and Rodger Kibble (eds.), Information\\nSharing, CSLI, Stanford.\\nBrigitte Krenn, Erich Gstrein, Barbara Neumayr and Mar-\\ntine Grice. 2002. What can we learn from users\\nof avatars in net environments?. In: Proc. of the\\nAAMAS workshop ?Embodied conversational agents -\\nlet?s specify and evaluate them!?, Bologna, Italy.\\nNicholas Nicolov, Chris Mellish & Graeme Ritchie. 1996.\\nApproximate Generation from Non-Hierarchical Rep-\\nresentattions, Proc. 8th International Workshop on\\nNatural Language Generation, Herstmonceux Castle,\\nUK.\\nPaul Piwek, Brigitte Krenn, Marc Schro?der, Martine Grice,\\nStefan Baumann and Hannes Pirker. 2002. RRL: A\\nRich Representation Language for the Description of\\nAgent Behaviour in NECA. Proc. of the AAMAS work-\\nshop ?Embodied conversational agents - let?s specify\\nand evaluate them!?, Bologna, Italy.\\nEhud Reiter. 1999. Shallow vs. Deep Techniques for han-\\ndling Linguistic Constraints and Optimisations. Proc.\\nof KI-99 Workshop ?May I speak freely?.\\nEhud Reiter and Robert Dale. 2000. Building natural\\nlanguage generation systems. Cambridge University\\nPress, Cambridge.\\nMatthew Stone and Christy Doran. 1997. Sentence Plan-\\nning as Description Using Tree-Adjoining Grammar.\\nProc. ACL 1997, Madrid, Spain.\\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_text.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_f = lambda x: x.replace(' \\n', '\\n').replace('\\n ', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "papers_with_text['text'] = papers_with_text['text'].apply(space_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16269, 3)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_text[papers_with_text.text.str.contains('\\nAbstract\\n')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_abstract = papers_with_text[papers_with_text.text.str.contains('\\nAbstract\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16269, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_with_abstract = metadata[metadata.id.isin(papers_with_abstract.id.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_with_abstract = links[(links.citing.isin(papers_with_abstract.id.values))&\\\n",
    "                            (links.cited.isin(papers_with_abstract.id.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75009, 2)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_with_abstract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_abstract.to_csv('papers_with_abstract.csv', encoding='utf-8', index=False)\n",
    "metadata_with_abstract.to_csv('metadata_with_abstract.csv', encoding='utf-8', index=False)\n",
    "links_with_abstract.to_csv('links_with_abstract.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 3)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract[~papers_with_abstract.text.str.contains('Introduction')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>E06-1001</td>\n",
       "      <td>Inheritance and the CCG Lexicon\\nMark McConvil...</td>\n",
       "      <td>28328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>E06-1048</td>\n",
       "      <td>Unifying Synchronous Tree-Adjoining Grammars a...</td>\n",
       "      <td>33699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>E06-1049</td>\n",
       "      <td>A Machine Learning Approach to Extract Tempora...</td>\n",
       "      <td>29888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>E09-1079</td>\n",
       "      <td>Proceedings of the 12th Conference of the Euro...</td>\n",
       "      <td>32255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>E12-1001</td>\n",
       "      <td>Proceedings of the 13th Conference of the Euro...</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>E12-1039</td>\n",
       "      <td>Proceedings of the 13th Conference of the Euro...</td>\n",
       "      <td>30485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>E12-1040</td>\n",
       "      <td>Proceedings of the 13th Conference of the Euro...</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>E12-1061</td>\n",
       "      <td>Proceedings of the 13th Conference of the Euro...</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>E14-1050</td>\n",
       "      <td>Proceedings of the 14th Conference of the Euro...</td>\n",
       "      <td>37715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>E14-2010</td>\n",
       "      <td>Proceedings of the Demonstrations at the 14th ...</td>\n",
       "      <td>12956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>E14-4022</td>\n",
       "      <td>Proceedings of the 14th Conference of the Euro...</td>\n",
       "      <td>21990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>E14-4037</td>\n",
       "      <td>Proceedings of the 14th Conference of the Euro...</td>\n",
       "      <td>18494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>E85-1008</td>\n",
       "      <td>Effective Parsing With Generalised Phrase Stru...</td>\n",
       "      <td>25515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>E87-1030</td>\n",
       "      <td>NATURAL AND S IMULATED POINT ING\\nDagmar Schma...</td>\n",
       "      <td>31715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>E89-1010</td>\n",
       "      <td>Ambiguity Resolution in the DMTRANS PLUS\\nHiro...</td>\n",
       "      <td>36620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>E89-1018</td>\n",
       "      <td>Collocations in Multilingual Generation\\nUlric...</td>\n",
       "      <td>20832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>E89-1021</td>\n",
       "      <td>PLAN REVISION IN PERSON-MACHINE\\nDIALOGUE\\nCld...</td>\n",
       "      <td>20640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>E89-1029</td>\n",
       "      <td>EXTENDED GRAPH UNIFICATION\\nAllan Ramsay\\nScho...</td>\n",
       "      <td>19895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>E91-1001</td>\n",
       "      <td>A. ZAMPOLLI\\nTowards Reusable Linquistic Resou...</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>E91-1018</td>\n",
       "      <td>Analysis of Unknown Words\\nthrough\\nMorphologi...</td>\n",
       "      <td>24433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>E91-1025</td>\n",
       "      <td>Parsing without lexicon: the MorP system\\nAbst...</td>\n",
       "      <td>18024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>E91-1031</td>\n",
       "      <td>Prediction in Chart Parsing Algorithms for\\nCa...</td>\n",
       "      <td>25590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>E93-1002</td>\n",
       "      <td>The Incremental Generation of Passive Sentence...</td>\n",
       "      <td>33589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>E93-1005</td>\n",
       "      <td>Decidability and Undecidability\\nin stand-alon...</td>\n",
       "      <td>32170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>E93-1006</td>\n",
       "      <td>Using an Annotated Corpus as a Stochastic Gram...</td>\n",
       "      <td>25169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>E93-1008</td>\n",
       "      <td>Disjunctions and Inheritance\\nin the  Context ...</td>\n",
       "      <td>27107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>E93-1010</td>\n",
       "      <td>Head-driven Parsing for Lexicalist Grammars:\\n...</td>\n",
       "      <td>42846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>E93-1011</td>\n",
       "      <td>An Endogeneous Corpus-Based Method for Structu...</td>\n",
       "      <td>22501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>E93-1013</td>\n",
       "      <td>LFG Semant ics  v ia  Const ra in ts \\nMary Da...</td>\n",
       "      <td>41949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>E93-1014</td>\n",
       "      <td>On the  not ion  o f  un iqueness  *\\nJoke Dor...</td>\n",
       "      <td>28473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25610</th>\n",
       "      <td>W14-2613</td>\n",
       "      <td>Proceedings of the 5th Workshop on Computation...</td>\n",
       "      <td>21290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25629</th>\n",
       "      <td>W14-0207</td>\n",
       "      <td>Proceedings of the of the EACL 2014 Workshop o...</td>\n",
       "      <td>19699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25640</th>\n",
       "      <td>W14-0305</td>\n",
       "      <td>Workshop on Humans and Computer-assisted Trans...</td>\n",
       "      <td>2065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25643</th>\n",
       "      <td>W14-0308</td>\n",
       "      <td>Workshop on Humans and Computer-assisted Trans...</td>\n",
       "      <td>43611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25694</th>\n",
       "      <td>W14-2115</td>\n",
       "      <td>Proceedings of the First Workshop on Argumenta...</td>\n",
       "      <td>8837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25697</th>\n",
       "      <td>W14-2118</td>\n",
       "      <td>Proceedings of the First Workshop on Argumenta...</td>\n",
       "      <td>7774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25717</th>\n",
       "      <td>W14-2406</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Semant...</td>\n",
       "      <td>15873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25728</th>\n",
       "      <td>W14-2501</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25729</th>\n",
       "      <td>W14-2502</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25730</th>\n",
       "      <td>W14-2503</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>3434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25731</th>\n",
       "      <td>W14-2504</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735</th>\n",
       "      <td>W14-2508</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>20863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25741</th>\n",
       "      <td>W14-2514</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25746</th>\n",
       "      <td>W14-2519</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25747</th>\n",
       "      <td>W14-2520</td>\n",
       "      <td>Proceedings of the ACL 2014 Workshop on Langua...</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25759</th>\n",
       "      <td>W14-2712</td>\n",
       "      <td>Proceedings of the Joint Workshop on Social Dy...</td>\n",
       "      <td>22991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25764</th>\n",
       "      <td>W14-2802</td>\n",
       "      <td>Proceedings of the 2014 Joint Meeting of SIGMO...</td>\n",
       "      <td>37283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25770</th>\n",
       "      <td>W14-2808</td>\n",
       "      <td>Proceedings of the 2014 Joint Meeting of SIGMO...</td>\n",
       "      <td>21371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25772</th>\n",
       "      <td>W14-3002</td>\n",
       "      <td>Proceedings of Frame Semantics in NLP: A Works...</td>\n",
       "      <td>16472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25773</th>\n",
       "      <td>W14-3003</td>\n",
       "      <td>Proceedings of Frame Semantics in NLP: A Works...</td>\n",
       "      <td>11432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25775</th>\n",
       "      <td>W14-3005</td>\n",
       "      <td>Proceedings of Frame Semantics in NLP: A Works...</td>\n",
       "      <td>17974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25777</th>\n",
       "      <td>W14-3007</td>\n",
       "      <td>Proceedings of Frame Semantics in NLP: A Works...</td>\n",
       "      <td>15815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25841</th>\n",
       "      <td>W10-3402</td>\n",
       "      <td>Proceedings of the 2nd Workshop on Cognitive A...</td>\n",
       "      <td>37328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25850</th>\n",
       "      <td>W10-3411</td>\n",
       "      <td>Proceedings of the 2nd Workshop on Cognitive A...</td>\n",
       "      <td>39041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25861</th>\n",
       "      <td>W14-4711</td>\n",
       "      <td>Zock/Rapp/Huang (eds.): Proceedings of the 4th...</td>\n",
       "      <td>6061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25927</th>\n",
       "      <td>W14-5418</td>\n",
       "      <td>Proceedings of the 25th International Conferen...</td>\n",
       "      <td>12024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25935</th>\n",
       "      <td>W14-5604</td>\n",
       "      <td>Proceedings of the Workshop on Automatic Text ...</td>\n",
       "      <td>36321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25967</th>\n",
       "      <td>W14-5901</td>\n",
       "      <td>Proceedings of the Second Workshop on Natural ...</td>\n",
       "      <td>1833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26034</th>\n",
       "      <td>W14-4101</td>\n",
       "      <td>Proceedings of the 2014 Conference on Empirica...</td>\n",
       "      <td>6414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26040</th>\n",
       "      <td>W14-4107</td>\n",
       "      <td>Proceedings of the 2014 Conference on Empirica...</td>\n",
       "      <td>13179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  text_len\n",
       "110    E06-1001  Inheritance and the CCG Lexicon\\nMark McConvil...     28328\n",
       "157    E06-1048  Unifying Synchronous Tree-Adjoining Grammars a...     33699\n",
       "158    E06-1049  A Machine Learning Approach to Extract Tempora...     29888\n",
       "280    E09-1079  Proceedings of the 12th Conference of the Euro...     32255\n",
       "319    E12-1001  Proceedings of the 13th Conference of the Euro...      1616\n",
       "357    E12-1039  Proceedings of the 13th Conference of the Euro...     30485\n",
       "358    E12-1040  Proceedings of the 13th Conference of the Euro...      1529\n",
       "379    E12-1061  Proceedings of the 13th Conference of the Euro...      1271\n",
       "484    E14-1050  Proceedings of the 14th Conference of the Euro...     37715\n",
       "522    E14-2010  Proceedings of the Demonstrations at the 14th ...     12956\n",
       "573    E14-4022  Proceedings of the 14th Conference of the Euro...     21990\n",
       "588    E14-4037  Proceedings of the 14th Conference of the Euro...     18494\n",
       "637    E85-1008  Effective Parsing With Generalised Phrase Stru...     25515\n",
       "700    E87-1030  NATURAL AND S IMULATED POINT ING\\nDagmar Schma...     31715\n",
       "731    E89-1010  Ambiguity Resolution in the DMTRANS PLUS\\nHiro...     36620\n",
       "739    E89-1018  Collocations in Multilingual Generation\\nUlric...     20832\n",
       "742    E89-1021  PLAN REVISION IN PERSON-MACHINE\\nDIALOGUE\\nCld...     20640\n",
       "750    E89-1029  EXTENDED GRAPH UNIFICATION\\nAllan Ramsay\\nScho...     19895\n",
       "764    E91-1001  A. ZAMPOLLI\\nTowards Reusable Linquistic Resou...      2664\n",
       "781    E91-1018  Analysis of Unknown Words\\nthrough\\nMorphologi...     24433\n",
       "788    E91-1025  Parsing without lexicon: the MorP system\\nAbst...     18024\n",
       "794    E91-1031  Prediction in Chart Parsing Algorithms for\\nCa...     25590\n",
       "819    E93-1002  The Incremental Generation of Passive Sentence...     33589\n",
       "822    E93-1005  Decidability and Undecidability\\nin stand-alon...     32170\n",
       "823    E93-1006  Using an Annotated Corpus as a Stochastic Gram...     25169\n",
       "825    E93-1008  Disjunctions and Inheritance\\nin the  Context ...     27107\n",
       "827    E93-1010  Head-driven Parsing for Lexicalist Grammars:\\n...     42846\n",
       "828    E93-1011  An Endogeneous Corpus-Based Method for Structu...     22501\n",
       "830    E93-1013  LFG Semant ics  v ia  Const ra in ts \\nMary Da...     41949\n",
       "831    E93-1014  On the  not ion  o f  un iqueness  *\\nJoke Dor...     28473\n",
       "...         ...                                                ...       ...\n",
       "25610  W14-2613  Proceedings of the 5th Workshop on Computation...     21290\n",
       "25629  W14-0207  Proceedings of the of the EACL 2014 Workshop o...     19699\n",
       "25640  W14-0305  Workshop on Humans and Computer-assisted Trans...      2065\n",
       "25643  W14-0308  Workshop on Humans and Computer-assisted Trans...     43611\n",
       "25694  W14-2115  Proceedings of the First Workshop on Argumenta...      8837\n",
       "25697  W14-2118  Proceedings of the First Workshop on Argumenta...      7774\n",
       "25717  W14-2406  Proceedings of the ACL 2014 Workshop on Semant...     15873\n",
       "25728  W14-2501  Proceedings of the ACL 2014 Workshop on Langua...      2559\n",
       "25729  W14-2502  Proceedings of the ACL 2014 Workshop on Langua...      1556\n",
       "25730  W14-2503  Proceedings of the ACL 2014 Workshop on Langua...      3434\n",
       "25731  W14-2504  Proceedings of the ACL 2014 Workshop on Langua...      1876\n",
       "25735  W14-2508  Proceedings of the ACL 2014 Workshop on Langua...     20863\n",
       "25741  W14-2514  Proceedings of the ACL 2014 Workshop on Langua...      1229\n",
       "25746  W14-2519  Proceedings of the ACL 2014 Workshop on Langua...      1886\n",
       "25747  W14-2520  Proceedings of the ACL 2014 Workshop on Langua...      1672\n",
       "25759  W14-2712  Proceedings of the Joint Workshop on Social Dy...     22991\n",
       "25764  W14-2802  Proceedings of the 2014 Joint Meeting of SIGMO...     37283\n",
       "25770  W14-2808  Proceedings of the 2014 Joint Meeting of SIGMO...     21371\n",
       "25772  W14-3002  Proceedings of Frame Semantics in NLP: A Works...     16472\n",
       "25773  W14-3003  Proceedings of Frame Semantics in NLP: A Works...     11432\n",
       "25775  W14-3005  Proceedings of Frame Semantics in NLP: A Works...     17974\n",
       "25777  W14-3007  Proceedings of Frame Semantics in NLP: A Works...     15815\n",
       "25841  W10-3402  Proceedings of the 2nd Workshop on Cognitive A...     37328\n",
       "25850  W10-3411  Proceedings of the 2nd Workshop on Cognitive A...     39041\n",
       "25861  W14-4711  Zock/Rapp/Huang (eds.): Proceedings of the 4th...      6061\n",
       "25927  W14-5418  Proceedings of the 25th International Conferen...     12024\n",
       "25935  W14-5604  Proceedings of the Workshop on Automatic Text ...     36321\n",
       "25967  W14-5901  Proceedings of the Second Workshop on Natural ...      1833\n",
       "26034  W14-4101  Proceedings of the 2014 Conference on Empirica...      6414\n",
       "26040  W14-4107  Proceedings of the 2014 Conference on Empirica...     13179\n",
       "\n",
       "[1025 rows x 3 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract[~papers_with_abstract.text.str.contains('Introduction')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 472?481,\n",
      "Gothenburg, Sweden, April 26-30 2014.\n",
      "c?2014 Association for Computational Linguistics\n",
      "Using Distributional Similarity of Multi-way Translations to Predict\n",
      "Multiword Expression Compositionality\n",
      "Bahar Salehi,\n",
      "??\n",
      "Paul Cook\n",
      "?\n",
      "and Timothy Baldwin\n",
      "??\n",
      "? NICTA Victoria Research Laboratory\n",
      "? Department of Computing and Information Systems\n",
      "The University of Melbourne\n",
      "Victoria 3010, Australia\n",
      "bsalehi@student.unimelb.edu.au, paulcook@unimelb.edu.au, tb@ldwin.net\n",
      "Abstract\n",
      "We predict the compositionality of multi-\n",
      "word expressions using distributional sim-\n",
      "ilarity between each component word and\n",
      "the overall expression, based on transla-\n",
      "tions into multiple languages. We evaluate\n",
      "the method over English noun compounds,\n",
      "English verb particle constructions and\n",
      "German noun compounds. We show that\n",
      "the estimation of compositionality is im-\n",
      "proved when using translations into multi-\n",
      "ple languages, as compared to simply us-\n",
      "ing distributional similarity in the source\n",
      "language. We further find that string sim-\n",
      "ilarity complements distributional similar-\n",
      "ity.\n",
      "1 Compositionality of MWEs\n",
      "Multiword expressions (hereafter MWEs) are\n",
      "combinations of words which are lexically, syntac-\n",
      "tically, semantically or statistically idiosyncratic\n",
      "(Sag et al., 2002; Baldwin and Kim, 2009). Much\n",
      "research has been carried out on the extraction and\n",
      "identification of MWEs\n",
      "1\n",
      "in English (Schone and\n",
      "Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009)\n",
      "and other languages (Dias, 2003; Evert and Krenn,\n",
      "2005; Salehi et al., 2012). However, considerably\n",
      "less work has addressed the task of predicting the\n",
      "meaning of MWEs, especially in non-English lan-\n",
      "guages. As a step in this direction, the focus of\n",
      "this study is on predicting the compositionality of\n",
      "MWEs.\n",
      "An MWE is fully compositional if its meaning\n",
      "is predictable from its component words, and it is\n",
      "non-compositional (or idiomatic) if not. For ex-\n",
      "ample, stand up ?rise to one?s feet? is composi-\n",
      "1\n",
      "In this paper, we follow Baldwin and Kim (2009) in\n",
      "considering MWE ?identification? to be a token-level disam-\n",
      "biguation task, and MWE ?extraction? to be a type-level lex-\n",
      "icon induction task.\n",
      "tional, because its meaning is clear from the mean-\n",
      "ing of the components stand and up. However, the\n",
      "meaning of strike up ?to start playing? is largely\n",
      "unpredictable from the component words strike\n",
      "and up.\n",
      "In this study, following McCarthy et al. (2003)\n",
      "and Reddy et al. (2011), we consider composition-\n",
      "ality to be graded, and aim to predict the degree\n",
      "of compositionality. For example, in the dataset\n",
      "of Reddy et al. (2011), climate change is judged\n",
      "to be 99% compositional, while silver screen is\n",
      "48% compositional and ivory tower is 9% com-\n",
      "positional. Formally, we model compositionality\n",
      "prediction as a regression task.\n",
      "An explicit handling of MWEs has been shown\n",
      "to be useful in NLP applications (Ramisch, 2012).\n",
      "As an example, Carpuat and Diab (2010) proposed\n",
      "two strategies for integrating MWEs into statisti-\n",
      "cal machine translation. They show that even a\n",
      "large scale bilingual corpus cannot capture all the\n",
      "necessary information to translate MWEs, and that\n",
      "in adding the facility to model the compositional-\n",
      "ity of MWEs into their system, they could improve\n",
      "translation quality. Acosta et al. (2011) showed\n",
      "that treating non-compositional MWEs as a sin-\n",
      "gle unit in information retrieval improves retrieval\n",
      "effectiveness. For example, while searching for\n",
      "documents related to ivory tower, we are almost\n",
      "certainly not interested in documents relating to\n",
      "elephant tusks.\n",
      "Our approach is to use a large-scale multi-way\n",
      "translation lexicon to source translations of MWEs\n",
      "and their component words, and then model the\n",
      "relative similarity between each of the component\n",
      "words and the MWE, using distributional similar-\n",
      "ity based on monolingual corpora for the source\n",
      "language and each of the target languages. Our\n",
      "hypothesis is that using distributional similarity\n",
      "in more than one language will improve the pre-\n",
      "diction of compositionality. Importantly, in order\n",
      "to make the method as language-independent and\n",
      "472\n",
      "broadly-applicable as possible, we make no use of\n",
      "corpus preprocessing such as lemmatisation, and\n",
      "rely only on the availability of a translation dictio-\n",
      "nary and monolingual corpora.\n",
      "Our results confirm our hypothesis that distri-\n",
      "butional similarity over the source language in ad-\n",
      "dition to multiple target languages improves the\n",
      "quality of compositionality prediction. We also\n",
      "show that our method can be complemented with\n",
      "string similarity (Salehi and Cook, 2013) to further\n",
      "improve compositionality prediction. We achieve\n",
      "state-of-the-art results over two datasets.\n",
      "2 Related Work\n",
      "Most recent work on predicting the composi-\n",
      "tionality of MWEs can be divided into two\n",
      "categories: language/construction-specific and\n",
      "general-purpose. This can be at either the token-\n",
      "level (over token occurrences of an MWE in a cor-\n",
      "pus) or type-level (over the MWE string, indepen-\n",
      "dent of usage). The bulk of work on composition-\n",
      "ality has been language/construction-specific and\n",
      "operated at the token-level, using dedicated meth-\n",
      "ods to identify instances of a given MWE, and\n",
      "specific properties of the MWE in that language\n",
      "to predict compositionality (Lin, 1999; Kim and\n",
      "Baldwin, 2007; Fazly et al., 2009).\n",
      "General-purpose token-level approaches such\n",
      "as distributional similarity have been commonly\n",
      "applied to infer the semantics of a word/MWE\n",
      "(Schone and Jurafsky, 2001; Baldwin et al., 2003;\n",
      "Reddy et al., 2011). These techniques are based\n",
      "on the assumption that the meaning of a word is\n",
      "predictable from its context of use, via the neigh-\n",
      "bouring words of token-level occurrences of the\n",
      "MWE. In order to predict the compositionality of\n",
      "a given MWE using distributional similarity, the\n",
      "different contexts of the MWE are compared with\n",
      "the contexts of its components, and the MWE is\n",
      "considered to be compositional if the MWE and\n",
      "component words occur in similar contexts.\n",
      "Identifying token instances of MWEs is not al-\n",
      "ways easy, especially when the component words\n",
      "do not occur sequentially. For example consider\n",
      "put on in put your jacket on, and put your jacket\n",
      "on the chair. In the first example put on is an\n",
      "MWE while in the second example, put on is a\n",
      "simple verb with prepositional phrase and not an\n",
      "instance of an MWE. Moreover, if we adopt a con-\n",
      "servative identification method, the number of to-\n",
      "ken occurrences will be limited and the distribu-\n",
      "tional scores may not be reliable. Additionally,\n",
      "for morphologically-rich languages, it can be dif-\n",
      "ficult to predict the different word forms a given\n",
      "MWE type will occur across, posing a challenge\n",
      "for our requirement of no language-specific pre-\n",
      "processing.\n",
      "Pichotta and DeNero (2013) proposed a token-\n",
      "based method for identifying English phrasal\n",
      "verbs based on parallel corpora for 50 languages.\n",
      "They show that they can identify phrasal verbs bet-\n",
      "ter when they combine information from multiple\n",
      "languages, in addition to the information they get\n",
      "from a monolingual corpus. This finding lends\n",
      "weight to our hypothesis that using translation data\n",
      "and distributional similarity from each of a range\n",
      "of target languages, can improve compositionality\n",
      "prediction. Having said that, the general applica-\n",
      "bility of the method is questionable ? there are\n",
      "many parallel corpora involving English, but for\n",
      "other languages, this tends not to be the case.\n",
      "Salehi and Cook (2013) proposed a general-\n",
      "purpose type-based approach using translation\n",
      "data from multiple languages, and string similar-\n",
      "ity between the MWE and each of the compo-\n",
      "nent words. They use training data to identify the\n",
      "best-10 languages for a given family of MWEs, on\n",
      "which to base the string similarity, and once again\n",
      "find that translation data improves their results\n",
      "substantially. Among the four string similarity\n",
      "measures they experimented with, longest com-\n",
      "mon substring was found to perform best. Their\n",
      "proposed method is general and applicable to dif-\n",
      "ferent families of MWEs in different languages. In\n",
      "this paper, we reimplement the method of Salehi\n",
      "and Cook (2013) using longest common substring\n",
      "(LCS), and both benchmark against this method\n",
      "and combine it with our distributional similarity-\n",
      "based method.\n",
      "3 Our Approach\n",
      "To predict the compositionality of a given MWE,\n",
      "we first measure the semantic similarity between\n",
      "the MWE and each of its component words\n",
      "2\n",
      "using\n",
      "distributional similarity based on a monolingual\n",
      "corpus in the source language. We then repeat the\n",
      "process for translations of the MWE and its com-\n",
      "ponent words into each of a range of target lan-\n",
      "guages, calculating distributional similarity using\n",
      "2\n",
      "Note that we will always assume that there are two\n",
      "component words, but the method is easily generalisable to\n",
      "MWEs with more than two components.\n",
      "473\n",
      "MWE component1 component2\n",
      "score1 score2\n",
      "Translations\n",
      "Translate\n",
      "(using Panlex)\n",
      "DS\n",
      "(using Wikiepdia)\n",
      "Translate\n",
      "(using Panlex)\n",
      "Translate\n",
      "(using Panlex)\n",
      "DS\n",
      "(using Wikiepdia)\n",
      "Figure 1: Outline of our approach to computing\n",
      "the distributional similarity (DS) of translations\n",
      "of an MWE with each of its component words,\n",
      "for a given target language. score\n",
      "1\n",
      "and score\n",
      "2\n",
      "are the similarity for the first and second compo-\n",
      "nents, respectively. We obtain translations from\n",
      "Panlex, and use Wikipedia as our corpus for each\n",
      "language.\n",
      "a monolingual corpus in the target language (Fig-\n",
      "ure 1). We additionally use supervised learning to\n",
      "identify which target languages (or what weights\n",
      "for each language) optimise the prediction of com-\n",
      "positionality (Figure 2). We hypothesise that by\n",
      "using multiple translations ? rather than only in-\n",
      "formation from the source language ? we will be\n",
      "able to better predict compositionality.\n",
      "We optionally combine our proposed approach\n",
      "with string similarity, calculated based on the\n",
      "method of Salehi and Cook (2013), using LCS.\n",
      "Below, we detail our method for calculating dis-\n",
      "tributional similarity in a given language, the dif-\n",
      "ferent methods for combining distributional simi-\n",
      "larity scores into a single estimate of composition-\n",
      "ality, and finally the method for selecting the target\n",
      "languages to use in calculating compositionality.\n",
      "3.1 Calculating Distributional Similarity\n",
      "In order to be consistent across all languages and\n",
      "be as language-independent as possible, we calcu-\n",
      "CSmethod CSmethod\n",
      "Score1 for each language Score2 for each language\n",
      "21 )1( ss ?? ??\n",
      "Compositionality  score\n",
      "s1 s2\n",
      "Figure 2: Outline of the method for combin-\n",
      "ing distributional similarity scores from multiple\n",
      "languages, across the components of the MWE.\n",
      "CS\n",
      "method\n",
      "refers to one of the methods described\n",
      "in Section 3.2 for calculating compositionality.\n",
      "late distributional similarity in the following man-\n",
      "ner for a given language.\n",
      "Tokenisation is based on whitespace delimiters\n",
      "and punctuation; no lemmatisation or case-folding\n",
      "is carried out. Token instances of a given MWE\n",
      "or component word are identified by full-token n-\n",
      "gram matching over the token stream. We assume\n",
      "that all full stops and equivalent characters for\n",
      "other orthographies are sentence boundaries, and\n",
      "chunk the corpora into (pseudo-)sentences on the\n",
      "basis of them. For each language, we identify the\n",
      "51st?1050th most frequent words, and consider\n",
      "them to be content-bearing words, in the manner\n",
      "of Sch?utze (1997). This is based on the assump-\n",
      "tion that the top-50 most frequent words are stop\n",
      "words, and not a good choice of word for calculat-\n",
      "ing distributional similarity over. That is not to say\n",
      "that we can?t calculate the distributional similarity\n",
      "for stop words, however (as we will for the verb\n",
      "particle construction dataset ? see Section 4.3.2)\n",
      "they are simply not used as the dimensions in our\n",
      "calculation of distributional similarity.\n",
      "We form a vector of content-bearing words\n",
      "across all token occurrences of the target word,\n",
      "474\n",
      "on the basis of these content-bearing words. Dis-\n",
      "tributional similarity is calculated over these con-\n",
      "text vectors using cosine similarity. Accord-\n",
      "ing to Weeds (2003), using dependency rela-\n",
      "tions with the neighbouring words of the target\n",
      "word can better predict the meaning of the target\n",
      "word. However, in line with our assumption of no\n",
      "language-specific preprocessing, we just use word\n",
      "co-occurrence.\n",
      "3.2 Calculating Compositionality\n",
      "First, we need to calculate a combined composi-\n",
      "tionality score from the individual distributional\n",
      "similarities between each component word and the\n",
      "MWE. Following Reddy et al. (2011), we combine\n",
      "the component scores using the weighted mean (as\n",
      "shown in Figure 2):\n",
      "comp = ?s\n",
      "1\n",
      "+ (1? ?)s\n",
      "2\n",
      "(1)\n",
      "where s\n",
      "1\n",
      "and s\n",
      "2\n",
      "are the scores for the first and\n",
      "the second component, respectively. We use dif-\n",
      "ferent ? settings for each dataset, as detailed in\n",
      "Section 4.3.\n",
      "We experiment with a range of methods for cal-\n",
      "culating compositionality, as follows:\n",
      "CS\n",
      "L1\n",
      ": calculate distributional similarity using\n",
      "only distributional similarity in the source\n",
      "language corpus (This is the approach used\n",
      "by Reddy et al. (2011), as discussed in Sec-\n",
      "tion 2).\n",
      "CS\n",
      "L2N\n",
      ": exclude the source language, and com-\n",
      "pute the mean of the distributional similarity\n",
      "scores for the best-N target languages. The\n",
      "value of N is selected according to training\n",
      "data, as detailed in Section 3.3.\n",
      "CS\n",
      "L1+L2N\n",
      ": calculate distributional similarity\n",
      "over both the source language (CS\n",
      "L1\n",
      ") and\n",
      "the mean of the best-N languages (CS\n",
      "L2N\n",
      "),\n",
      "and combine via the arithmetic mean.\n",
      "3\n",
      "This\n",
      "is to examine the hypothesis that using\n",
      "multiple target languages is better than just\n",
      "using the source language.\n",
      "CS\n",
      "SVR(L1+L2 )\n",
      ": train a support vector regressor\n",
      "(SVR: Smola and Sch?olkopf (2004)) over the\n",
      "distributional similarities for all 52 languages\n",
      "(source and target languages).\n",
      "3\n",
      "We also experimented with taking the mean over all the\n",
      "languages ? target and source ? but found it best to com-\n",
      "bine the scores for the target languages first, to give more\n",
      "weight to the source language.\n",
      "CS\n",
      "string\n",
      ": calculate string similarity using the\n",
      "LCS-based method of Salehi and Cook\n",
      "(2013).\n",
      "4\n",
      "CS\n",
      "string+L1\n",
      ": calculate the mean of the string\n",
      "similarity (CS\n",
      "string\n",
      ") and distributional sim-\n",
      "ilarity in the source language (Salehi and\n",
      "Cook, 2013).\n",
      "CS\n",
      "all\n",
      ": calculate the mean of the string similarity\n",
      "(CS\n",
      "string\n",
      ") and distributional similarity scores\n",
      "(CS\n",
      "L1\n",
      "and CS\n",
      "L2N\n",
      ").\n",
      "3.3 Selecting Target Languages\n",
      "We experiment with two approaches for combin-\n",
      "ing the compositionality scores from multiple tar-\n",
      "get languages.\n",
      "First, inCS\n",
      "L2N\n",
      "(andCS\n",
      "L1+L2N\n",
      "andCS\n",
      "all\n",
      "that\n",
      "build off it), we use training data to rank the target\n",
      "languages according to Pearson?s correlation be-\n",
      "tween the predicted compositionality scores and\n",
      "the gold-standard compositionality judgements.\n",
      "Based on this ranking, we take the best-N lan-\n",
      "guages, and combine the individual composition-\n",
      "ality scores by taking the arithmetic mean. We se-\n",
      "lect N by determining the value that optimises the\n",
      "correlation over the training data. In other words,\n",
      "the selection ofN and accordingly the best-N lan-\n",
      "guages are based on nested cross-validation over\n",
      "training data, independently of the test data for that\n",
      "iteration of cross-validation.\n",
      "Second in CS\n",
      "SVR(L1+L2 )\n",
      ", we combine the\n",
      "compositionality scores from the source and all 51\n",
      "target languages into a feature vector, and train an\n",
      "SVR over the data using LIBSVM.\n",
      "5\n",
      "4 Resources\n",
      "In this section, we describe the resources required\n",
      "by our method, and also the datasets used to eval-\n",
      "uate our method.\n",
      "4.1 Monolingual Corpora for Different\n",
      "Languages\n",
      "We collected monolingual corpora for each of 52\n",
      "languages (51 target languages + 1 source lan-\n",
      "guage) from XML dumps of Wikipedia. These\n",
      "languages are based on the 54 target languages\n",
      "4\n",
      "Due to differences in our random partitioning, our re-\n",
      "ported results over the two English datasets differ slightly\n",
      "over the results of Salehi and Cook (2013) using the same\n",
      "method.\n",
      "5\n",
      "http://www.csie.ntu.edu.tw/\n",
      "?\n",
      "cjlin/libsvm\n",
      "475\n",
      "used by Salehi and Cook (2013), excluding Span-\n",
      "ish because we happened not to have a dump of\n",
      "Spanish Wikipedia, and also Chinese and Japanese\n",
      "because of the need for a language-specific word\n",
      "tokeniser. The raw corpora were preprocessed us-\n",
      "ing the WP2TXT toolbox\n",
      "6\n",
      "to eliminate XML tags,\n",
      "HTML tags and hyperlinks, and then tokenisa-\n",
      "tion based on whitespace and punctuation was per-\n",
      "formed. The corpora vary in size from roughly\n",
      "750M tokens for English, to roughly 640K tokens\n",
      "for Marathi.\n",
      "4.2 Multilingual Dictionary\n",
      "To translate the MWEs and their components,\n",
      "we follow Salehi and Cook (2013) in using Pan-\n",
      "lex (Baldwin et al., 2010). This online dictio-\n",
      "nary is massively multilingual, covering more than\n",
      "1353 languages. For each MWE dataset (see Sec-\n",
      "tion 4.3), we translate the MWE and component\n",
      "words from the source language into each of the\n",
      "51 languages.\n",
      "In instances where there is no direct translation\n",
      "in a given language for a term, we use a pivot lan-\n",
      "guage to find translation(s) in the target language.\n",
      "For example, the English noun compound silver\n",
      "screen has direct translations in only 13 languages\n",
      "in Panlex, including Vietnamese (ma`n bac) but\n",
      "not French. There is, however, a translation of\n",
      "ma`n bac into French (cine?ma), allowing us to\n",
      "infer an indirect translation between silver screen\n",
      "and cine?ma. In this way, if there are no direct\n",
      "translations into a particular target language, we\n",
      "search for a single-pivot translation via each of our\n",
      "other target languages, and combine them all to-\n",
      "gether as our set of translations for the target lan-\n",
      "guage of interest.\n",
      "In the case that no translation (direct or indirect)\n",
      "can be found for a given source language term into\n",
      "a particular target language, the compositionality\n",
      "score for that target language is set to the average\n",
      "across all target languages for which scores can be\n",
      "calculated for the given term. If no translations are\n",
      "available for any target language (e.g. the term is\n",
      "not in Panlex) the compositionality score for each\n",
      "target language is set to the average score for that\n",
      "target language across all other source language\n",
      "terms.\n",
      "6\n",
      "http://wp2txt.rubyforge.org/\n",
      "4.3 Datasets\n",
      "We evaluate our proposed method over three\n",
      "datasets (two English, one German), as described\n",
      "below.\n",
      "4.3.1 English Noun Compounds (ENC)\n",
      "Our first dataset is made up of 90 binary English\n",
      "noun compounds, from the work of Reddy et al.\n",
      "(2011). Each noun compound was annotated by\n",
      "multiple annotators using the integer scale 0 (fully\n",
      "non-compositional) to 5 (fully compositional). A\n",
      "final compositionality score was then calculated\n",
      "as the mean of the scores from the annotators.\n",
      "If we simplistically consider 2.5 as the threshold\n",
      "for compositionality, the dataset is relatively well\n",
      "balanced, containing 48% compositional and 52%\n",
      "non-compositional noun compounds. Following\n",
      "Reddy et al. (2011), in combining the component-\n",
      "wise distributional similarities for this dataset, we\n",
      "weight the first component in Equation 1 higher\n",
      "than the second (? = 0.7).\n",
      "4.3.2 English Verb Particle Constructions\n",
      "(EVPC)\n",
      "The second dataset contains 160 English verb par-\n",
      "ticle constructions (VPCs), from the work of Ban-\n",
      "nard (2006). In this dataset, a verb particle con-\n",
      "struction consists of a verb (the head) and a prepo-\n",
      "sitional particle (e.g. hand in, look up or battle on).\n",
      "For each component word (the verb and parti-\n",
      "cle, respectively), multiple annotators were asked\n",
      "whether the VPC entails the component word. In\n",
      "order to translate the dataset into a regression task,\n",
      "we calculate the overall compositionality as the\n",
      "number of annotations of entailment for the verb,\n",
      "divided by the total number of verb annotations for\n",
      "that VPC. That is, following Bannard et al. (2003),\n",
      "we only consider the compositionality of the verb\n",
      "component in our experiments (and as such ? = 1\n",
      "in Equation 1).\n",
      "One area of particular interest with this dataset\n",
      "will be the robustness of the method to function\n",
      "words (the particles), both under translation and\n",
      "in terms of calculating distributional similarity, al-\n",
      "though the findings of Baldwin (2006) for English\n",
      "prepositions are at least encouraging in this re-\n",
      "spect. Additionally, English VPCs can occur in\n",
      "?split? form (e.g. put your jacket on, from our\n",
      "earlier example), which will complicate identifi-\n",
      "cation, and the verb component will often be in-\n",
      "flected and thus not match under our identification\n",
      "strategy (for both VPCs and the component verbs).\n",
      "476\n",
      "Dataset Language Frequency Family\n",
      "ENC\n",
      "Italian 100 Romance\n",
      "French 99 Romance\n",
      "German 86 Germanic\n",
      "Vietnamese 83 Viet-Muong\n",
      "Portuguese 62 Romance\n",
      "EVPC\n",
      "Bulgarian 100 Slavic\n",
      "Breton 100 Celtic\n",
      "Occitan 100 Romance\n",
      "Indonesian 100 Indonesian\n",
      "Slovenian 100 Slavic\n",
      "GNC\n",
      "Polish 100 Slavic\n",
      "Lithuanian 99 Baltic\n",
      "Finnish 74 Uralic\n",
      "Bulgarian 72 Slavic\n",
      "Czech 40 Slavic\n",
      "Table 1: The 5 best languages for the ENC, EVPC\n",
      "and GNC datasets. The language family is based\n",
      "on Voegelin and Voegelin (1977).\n",
      "4.3.3 German Noun Compounds (GNC)\n",
      "Our final dataset is made up of 246 German noun\n",
      "compounds (von der Heide and Borgwaldt, 2009;\n",
      "Schulte im Walde et al., 2013). Multiple anno-\n",
      "tators were asked to rate the compositionality of\n",
      "each German noun compound on an integer scale\n",
      "of 1 (non-compositional) to 7 (compositional).\n",
      "The overall compositionality score is then calcu-\n",
      "lated as the mean across the annotators. Note that\n",
      "the component words are provided as part of the\n",
      "dataset, and that there is no need to perform de-\n",
      "compounding. Following Schulte im Walde et al.\n",
      "(2013), we weight the first component higher in\n",
      "Equation 1 (? = 0.8) when calculating the overall\n",
      "compositionality score.\n",
      "This dataset is significant in being non-English,\n",
      "and also in that German has relatively rich mor-\n",
      "phology, which we expect to impact on the iden-\n",
      "tification of both the MWE and the component\n",
      "words.\n",
      "5 Results\n",
      "All experiments are carried out using 10 iterations\n",
      "of 10-fold cross validation, randomly partitioning\n",
      "the data independently on each of the 10 iterations,\n",
      "and averaging across all 100 test partitions in our\n",
      "presented results. In the case of CS\n",
      "L2N\n",
      "and other\n",
      "methods that make use of it (i.e. CS\n",
      "L1+L2N\n",
      "and\n",
      "CS\n",
      "all\n",
      "), the languages selected for a given training\n",
      "fold are then used to compute the compositionality\n",
      "scores for the instances in the test set. Figures 3a,\n",
      "3b and 3c are histograms of the number of times\n",
      "each N is selected over 100 folds on ENC, EVPC\n",
      "and GNC datasets, respectively. From the his-\n",
      "tograms, N = 6, N = 15 and N = 2 are the most\n",
      "commonly selected settings for ENC, EVPC and\n",
      "GNC, respectively. That is, multiple languages are\n",
      "generally used, but more languages are used for\n",
      "English VPCs than either of the compound noun\n",
      "datasets. The 5 most-selected languages for ENC,\n",
      "EVPC and GNC are shown in Table 1. As we\n",
      "can see, there are some languages which are al-\n",
      "ways selected for a given dataset, but equally the\n",
      "commonly-selected languages vary considerably\n",
      "between datasets.\n",
      "Further analysis reveals that 32 (63%) target\n",
      "languages for ENC, 25 (49%) target languages\n",
      "for EVPC, and only 5 (10%) target languages for\n",
      "GNC have a correlation of r ? 0.1 with gold-\n",
      "standard compositionality judgements. On the\n",
      "other hand, 8 (16%) target languages for ENC, 2\n",
      "(4%) target languages for EVPC, and no target lan-\n",
      "guages for GNC have a correlation of r ? ?0.1.\n",
      "5.1 ENC Results\n",
      "English noun compounds are relatively easy to\n",
      "identify in a corpus,\n",
      "7\n",
      "because the components oc-\n",
      "cur sequentially, and the only morphological vari-\n",
      "ation is in noun number (singular vs. plural). In\n",
      "other words, the precision for our token match-\n",
      "ing method is very high, and the recall is also\n",
      "acceptably high. Partly as a result of the ease\n",
      "of identification, we get a high correlation of\n",
      "r = 0.700 for CS\n",
      "L1\n",
      "(using only source language\n",
      "data). Using only target languages (CS\n",
      "L2N\n",
      "), the\n",
      "results drop to r = 0.434, but when we combine\n",
      "the two (CS\n",
      "L1+L2N\n",
      "), the correlation is higher\n",
      "than using only source or target language data, at\n",
      "r = 0.725. When we combine all languages us-\n",
      "ing SVR, the results rise slightly higher again to\n",
      "r = 0.744, which is slightly above the correla-\n",
      "tion of the state-of-the-art method of Salehi and\n",
      "Cook (2013), which combines their method with\n",
      "the method of Reddy et al. (2011) (CS\n",
      "string+L1\n",
      ").\n",
      "These last two results support our hypothesis that\n",
      "using translation data can improve the prediction\n",
      "of compositionality. The results for string similar-\n",
      "ity on its own (CS\n",
      "string\n",
      ", r = 0.644) are slightly\n",
      "lower than those using only source language dis-\n",
      "tributional similarity, but when combined with\n",
      "7\n",
      "Although see Lapata and Lascarides (2003) for discus-\n",
      "sion of the difficulty of reliably identifying low-frequency\n",
      "English noun compounds.\n",
      "477\n",
      "0 5 10 15 20 250\n",
      "5\n",
      "1015\n",
      "2025\n",
      "bestN\n",
      "Frequency\n",
      "(a) ENC\n",
      "0 5 10 15 20 2502\n",
      "468\n",
      "101214\n",
      "161820\n",
      "best N\n",
      "Frequency\n",
      "(b) EVPC\n",
      "0 5 10 15 20 2502\n",
      "468\n",
      "101214\n",
      "161820\n",
      "best N\n",
      "Frequency\n",
      "(c) GNC\n",
      "Figure 3: Histograms displaying how many times a given N is selected as the best number of languages\n",
      "over each dataset. For example, according to the GNC chart, there is a peak for N = 2, which shows\n",
      "that over 100 folds, the best-2 languages achieved the highest correlation on 18 folds.\n",
      "Method Summary of the Method ENC EVPC GNC\n",
      "CS\n",
      "L1\n",
      "Source language 0.700 0.177 0.141\n",
      "CS\n",
      "L2N\n",
      "Best-N target languages 0.434 0.398 0.113\n",
      "CS\n",
      "L1+L2N\n",
      "Source + best-N target languages 0.725 0.312 0.178\n",
      "CS\n",
      "SVR(L1+L2 )\n",
      "SVR (Source + all 51 target languages) 0.744 0.389 0.085\n",
      "CS\n",
      "string\n",
      "String Similarity (Salehi and Cook, 2013) 0.644 0.385 0.372\n",
      "CS\n",
      "string+L1\n",
      "CS\n",
      "string\n",
      "+CS\n",
      "L1\n",
      "(Salehi and Cook, 2013) 0.739 0.360 0.353\n",
      "CS\n",
      "all\n",
      "CS\n",
      "L1\n",
      "+ CS\n",
      "L2N\n",
      "+ CS\n",
      "string\n",
      "0.732 0.417 0.364\n",
      "Table 2: Pearson?s correlation on the ENC, EVPC and GNC datasets\n",
      "CS\n",
      "L1+L2N\n",
      "(i.e. CS\n",
      "all\n",
      ") there is a slight rise in cor-\n",
      "relation (from r = 0.725 to r = 0.732).\n",
      "5.2 EVPC Results\n",
      "English VPCs are hard to identify. As discussed\n",
      "in Section 2, VPC components may not occur se-\n",
      "quentially, and even when they do occur sequen-\n",
      "tially, they may not be a VPC. As such, our sim-\n",
      "plistic identification method has low precision and\n",
      "recall (hand analysis of 927 identified VPC in-\n",
      "stances would suggest a precision of around 74%).\n",
      "There is no question that this is a contributor to\n",
      "the low correlation for the source language method\n",
      "(CS\n",
      "L1\n",
      "; r = 0.177). When we use target lan-\n",
      "guages instead of the source language (CS\n",
      "L2N\n",
      "),\n",
      "the correlation jumps substantially to r = 0.398.\n",
      "When we combine English and the target lan-\n",
      "guages (CS\n",
      "L1+L2N\n",
      "), the results are actually lower\n",
      "than just using the target languages, because of\n",
      "the high weight on the target language, which is\n",
      "not desirable for VPCs, based on the source lan-\n",
      "guage results. Even for CS\n",
      "SVR(L1+L2 )\n",
      ", the re-\n",
      "sults (r = 0.389) are slightly below the target\n",
      "language-only results. This suggests that when\n",
      "predicting the compositionality of MWEs which\n",
      "are hard to identify in the source language, it may\n",
      "actually be better to use target languages only. The\n",
      "results for string similarity (CS\n",
      "string\n",
      ": r = 0.385)\n",
      "are similar to those for CS\n",
      "L2N\n",
      ". However, as with\n",
      "the ENC dataset, when we combine string simi-\n",
      "larity and distributional similarity (CS\n",
      "all\n",
      "), the re-\n",
      "sults improve, and we achieve the state-of-the-art\n",
      "for the dataset.\n",
      "In Table 3, we present classification-based eval-\n",
      "478\n",
      "Method Precision Recall F-score (? = 1) Accuracy\n",
      "Bannard et al. (2003) 60.8 66.6 63.6 60.0\n",
      "Salehi and Cook (2013) 86.2 71.8 77.4 69.3\n",
      "CS\n",
      "all\n",
      "79.5 89.3 82.0 74.5\n",
      "Table 3: Results (%) for the binary compositionality prediction task on the EVPC dataset\n",
      "uation over a subset of EVPC, binarising the com-\n",
      "positionality judgements in the manner of Bannard\n",
      "et al. (2003). Our method achieves state-of-the-art\n",
      "results in terms of overall F-score and accuracy.\n",
      "5.3 GNC Results\n",
      "German is a morphologically-rich language, with\n",
      "marking of number and case on nouns. Given\n",
      "that we do not perform any lemmatization or other\n",
      "language-specific preprocessing, we inevitably\n",
      "achieve low recall for the identification of noun\n",
      "compound tokens, although the precision should\n",
      "be nearly 100%. Partly because of the resultant\n",
      "sparseness in the distributional similarity method,\n",
      "the results for CS\n",
      "L1\n",
      "are low (r = 0.141), al-\n",
      "though they are lower again when using target lan-\n",
      "guages (r = 0.113). However, when we combine\n",
      "the source and target languages (CS\n",
      "L1+L2N\n",
      ") the\n",
      "results improve to r = 0.178. The results for\n",
      "CS\n",
      "SVR(L1+L2 )\n",
      ", on the other hand, are very low\n",
      "(r = 0.085). Ultimately, simple string similar-\n",
      "ity achieves the best results for the dataset (r =\n",
      "0.372), and this result actually drops slightly when\n",
      "combined with the distributional similarities.\n",
      "To better understand the reason for the lacklus-\n",
      "tre results using SVR, we carried out error analysis\n",
      "and found that, unlike the other two datasets, about\n",
      "half of the target languages return scores which\n",
      "correlate negatively with the human judgements.\n",
      "When we filter these languages from the data, the\n",
      "score for SVR improves appreciably. For example,\n",
      "over the best-3 languages overall, we get a corre-\n",
      "lation score of r = 0.179, which is slightly higher\n",
      "than CS\n",
      "L1+L2N\n",
      ".\n",
      "We further investigated the reason for getting\n",
      "very low and sometimes negative correlations with\n",
      "many of our target languages. We noted that\n",
      "about 24% of the German noun compounds in\n",
      "the dataset do not have entries in Panlex. This\n",
      "contrasts with ENC where only one instance does\n",
      "not have an entry in Panlex, and EVPC where all\n",
      "VPCs have translations in at least one language in\n",
      "Panlex. We experimented with using string sim-\n",
      "ilarity scores in the case of such missing transla-\n",
      "tions, as opposed to the strategy described in Sec-\n",
      "tion 4.2. The results for CS\n",
      "SVR(L1+L2 )\n",
      "rose to\n",
      "r = 0.269, although this is still below the correla-\n",
      "tion for just using string similarity.\n",
      "Our results on the GNC dataset using string\n",
      "similarity are competitive with the state-of-the-art\n",
      "results (r = 0.45) using a window-based distribu-\n",
      "tional similarity approach over monolingual Ger-\n",
      "man data (Schulte im Walde et al., 2013). Note,\n",
      "however, that their method used part-of-speech in-\n",
      "formation and lemmatisation, where ours does not,\n",
      "in keeping with the language-independent philos-\n",
      "ophy of this research.\n",
      "6 Conclusion and Future Work\n",
      "In this study, we proposed a method to predict the\n",
      "compositionality of MWEs based on monolingual\n",
      "distributional similarity between the MWE and\n",
      "each of its component words, under translation\n",
      "into multiple target languages. We showed that\n",
      "using translation and multiple target languages en-\n",
      "hances compositionality modelling, and also that\n",
      "there is strong complementarity between our ap-\n",
      "proach and an approach based on string similarity.\n",
      "In future work, we hope to address the ques-\n",
      "tion of translation sparseness, as observed for the\n",
      "GNC dataset. We also plan to experiment with un-\n",
      "supervised morphological analysis methods to im-\n",
      "prove identification recall, and explore the impact\n",
      "of tokenization. Furthermore, we would like to in-\n",
      "vestigate the optimal number of stop words and\n",
      "content-bearing words for each language, and to\n",
      "look into the development of general unsupervised\n",
      "methods for compositionality prediction.\n",
      "Acknowledgements\n",
      "We thank the anonymous reviewers for their\n",
      "insightful comments and valuable suggestions.\n",
      "NICTA is funded by the Australian government as\n",
      "represented by Department of Broadband, Com-\n",
      "munication and Digital Economy, and the Aus-\n",
      "tralian Research Council through the ICT Centre\n",
      "of Excellence programme.\n",
      "479\n",
      "References\n",
      "Otavio Acosta, Aline Villavicencio, and Viviane Mor-\n",
      "eira. 2011. Identification and treatment of multi-\n",
      "word expressions applied to information retrieval.\n",
      "In Proceedings of the Workshop on Multiword Ex-\n",
      "pressions: from Parsing and Generation to the Real\n",
      "World, pages 101?109, Portland, USA.\n",
      "Timothy Baldwin and Su Nam Kim. 2009. Multiword\n",
      "expressions. In Nitin Indurkhya and Fred J. Dam-\n",
      "erau, editors, Handbook of Natural Language Pro-\n",
      "cessing. CRC Press, Boca Raton, USA, 2nd edition.\n",
      "Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and\n",
      "Dominic Widdows. 2003. An empirical model\n",
      "of multiword expression decomposability. In Pro-\n",
      "ceedings of the ACL-2003 Workshop on Multiword\n",
      "Expressions: Analysis, Acquisition and Treatment,\n",
      "pages 89?96, Sapporo, Japan.\n",
      "Timothy Baldwin, Jonathan Pool, and Susan M Colow-\n",
      "ick. 2010. Panlex and lextract: Translating all\n",
      "words of all languages of the world. In Proceed-\n",
      "ings of the 23rd International Conference on Com-\n",
      "putational Linguistics: Demonstrations, pages 37?\n",
      "40, Beijing, China.\n",
      "Timothy Baldwin. 2006. Distributional similarity and\n",
      "preposition semantics. In Patrick Saint-Dizier, ed-\n",
      "itor, Computational Linguistics Dimensions of Syn-\n",
      "tax and Semantics of Prepositions, pages 197?210.\n",
      "Springer, Dordrecht, Netherlands.\n",
      "Colin Bannard, Timothy Baldwin, and Alex Las-\n",
      "carides. 2003. A statistical approach to the seman-\n",
      "tics of verb-particles. In Proceedings of the ACL\n",
      "2003 workshop on Multiword expressions: analysis,\n",
      "acquisition and treatment-Volume 18, pages 65?72,\n",
      "Sapporo, Japan.\n",
      "Colin James Bannard. 2006. Acquiring Phrasal Lexi-\n",
      "cons from Corpora. Ph.D. thesis, University of Ed-\n",
      "inburgh.\n",
      "Marine Carpuat and Mona Diab. 2010. Task-based\n",
      "evaluation of multiword expressions: a pilot study\n",
      "in statistical machine translation. In Human Lan-\n",
      "guage Technologies: The 2010 Annual Conference\n",
      "of the North American Chapter of the Association\n",
      "for Computational Linguistics, pages 242?245, Los\n",
      "Angeles, USA.\n",
      "Ga?el Dias. 2003. Multiword unit hybrid extraction. In\n",
      "Proceedings of the ACL 2003 Workshop on Multi-\n",
      "word Expressions: Analysis, Acquisition and Treat-\n",
      "ment, pages 41?48, Sapporo, Japan.\n",
      "Stefan Evert and Brigitte Krenn. 2005. Using small\n",
      "random samples for the manual evaluation of statis-\n",
      "tical association measures. Computer Speech and\n",
      "Language, Special Issue on Multiword Expressions,\n",
      "19(4):450?466.\n",
      "Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.\n",
      "2009. Unsupervised type and token identification of\n",
      "idiomatic expressions. Computational Linguistics,\n",
      "35(1):61?103.\n",
      "Su Nam Kim and Timothy Baldwin. 2007. Detecting\n",
      "compositionality of English verb-particle construc-\n",
      "tions using semantic similarity. In Proceedings of\n",
      "the 7th Meeting of the Pacific Association for Com-\n",
      "putational Linguistics (PACLING 2007), pages 40?\n",
      "48, Melbourne, Australia.\n",
      "Mirella Lapata and Alex Lascarides. 2003. Detect-\n",
      "ing novel compounds: The role of distributional ev-\n",
      "idence. In Proceedings of the 11th Conference of\n",
      "the European Chapter for the Association of Compu-\n",
      "tational Linguistics (EACL-2003), pages 235?242,\n",
      "Budapest, Hungary.\n",
      "Dekang Lin. 1999. Automatic identification of\n",
      "non-compositional phrases. In Proceedings of the\n",
      "37th annual meeting of the Association for Compu-\n",
      "tational Linguistics on Computational Linguistics,\n",
      "pages 317?324, College Park, USA.\n",
      "Diana McCarthy, Bill Keller, and John Carroll.\n",
      "2003. Detecting a continuum of compositionality\n",
      "in phrasal verbs. In Proceedings of the ACL 2003\n",
      "workshop on Multiword expressions: analysis, ac-\n",
      "quisition and treatment-Volume 18, pages 73?80,\n",
      "Sapporo, Japan.\n",
      "Pavel Pecina. 2008. Lexical Association Measures:\n",
      "Collocation Extraction. Ph.D. thesis, Faculty of\n",
      "Mathematics and Physics, Charles University in\n",
      "Prague, Prague, Czech Republic.\n",
      "Karl Pichotta and John DeNero. 2013. Identify-\n",
      "ing phrasal verbs using many bilingual corpora. In\n",
      "Proceedings of the 2013 Conference on Empirical\n",
      "Methods in Natural Language Processing (EMNLP\n",
      "2013), Seattle, USA.\n",
      "Carlos Ramisch. 2012. A generic framework for mul-\n",
      "tiword expressions treatment: from acquisition to\n",
      "applications. In Proceedings of ACL 2012 Student\n",
      "Research Workshop, pages 61?66, Jeju Island, Ko-\n",
      "rea.\n",
      "Siva Reddy, Diana McCarthy, and Suresh Manandhar.\n",
      "2011. An empirical study on compositionality in\n",
      "compound nouns. In Proceedings of IJCNLP, pages\n",
      "210?218, Chiang Mai, Thailand.\n",
      "Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-\n",
      "take, and Dan Flickinger. 2002. Multiword ex-\n",
      "pressions: A pain in the neck for NLP. In Pro-\n",
      "ceedings of the 3rd International Conference on\n",
      "Intelligent Text Processing Computational Linguis-\n",
      "tics (CICLing-2002), pages 189?206, Mexico City,\n",
      "Mexico.\n",
      "Bahar Salehi and Paul Cook. 2013. Predicting\n",
      "the compositionality of multiword expressions using\n",
      "translations in multiple languages. In Proceedings\n",
      "of the Second Joint Conference on Lexical and Com-\n",
      "putational Semantics, volume 1, pages 266?275, At-\n",
      "lanta, USA.\n",
      "480\n",
      "Bahar Salehi, Narjes Askarian, and Afsaneh Fazly.\n",
      "2012. Automatic identification of Persian light verb\n",
      "constructions. In Proceedings of the 13th Inter-\n",
      "national Conference on Intelligent Text Processing\n",
      "Computational Linguistics (CICLing-2012), pages\n",
      "201?210, New Delhi, India.\n",
      "Patrick Schone and Dan Jurafsky. 2001. Is knowledge-\n",
      "free induction of multiword unit dictionary head-\n",
      "words a solved problem. In Proceedings of the 6th\n",
      "Conference on Empirical Methods in Natural Lan-\n",
      "guage Processing (EMNLP 2001), pages 100?108,\n",
      "Hong Kong, China.\n",
      "Sabine Schulte im Walde, Stefan M?uller, and Stephen\n",
      "Roller. 2013. Exploring vector space models to\n",
      "predict the compositionality of German noun-noun\n",
      "compounds. In Proceedings of the Second Joint\n",
      "Conference on Lexical and Computational Seman-\n",
      "tics, Atlanta, USA.\n",
      "Hinrich Sch?utze. 1997. Ambiguity Resolution in Lan-\n",
      "guage Learning. CSLI Publications, Stanford, USA.\n",
      "Alex J Smola and Bernhard Sch?olkopf. 2004. A tu-\n",
      "torial on support vector regression. Statistics and\n",
      "Computing, 14(3):199?222.\n",
      "Charles Frederick Voegelin and Florence Marie\n",
      "Voegelin. 1977. Classification and index of the\n",
      "world?s languages, volume 4. New York: Elsevier.\n",
      "Claudia von der Heide and Susanne Borgwaldt. 2009.\n",
      "Assoziationen zu Unter, Basis und Oberbegriffen.\n",
      "Eine explorative Studie. In Proceedings of the 9th\n",
      "Norddeutsches Linguistisches Kolloquium, pages\n",
      "51?74.\n",
      "Julie Elizabeth Weeds. 2003. Measures and applica-\n",
      "tions of lexical distributional similarity. Ph.D. the-\n",
      "sis, University of Sussex.\n",
      "481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(papers_with_abstract.loc[484].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper describes the NECA MNLG;\\na fully implemented Multimodal Natu-\\nral Language Generation module. The\\nMNLG is deployed as part of the NECA\\nsystem which generates dialogues be-\\ntween animated agents. The genera-\\ntion module supports the seamless inte-\\ngration of full grammar rules, templates\\nand canned text. The generator takes in-\\nput which allows for the specification of\\nsyntactic, semantic and pragmatic con-\\nstraints on the output.'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract.iloc[0].text.split('\\nAbstract\\n')[-1].split('\\n1 ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We predict the compositionality of multi-\\nword expressions using distributional sim-\\nilarity between each component word and\\nthe overall expression, based on transla-\\ntions into multiple languages. We evaluate\\nthe method over English noun compounds,\\nEnglish verb particle constructions and\\nGerman noun compounds. We show that\\nthe estimation of compositionality is im-\\nproved when using translations into multi-\\nple languages, as compared to simply us-\\ning distributional similarity in the source\\nlanguage. We further find that string sim-\\nilarity complements distributional similar-\\nity.'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract.loc[484].text.split('\\nAbstract\\n')[-1].split('\\n1 ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning has become the dominant approach to building natural-language processing sys-\\ntems. However, current approaches generally require a great deal of laboriously constructed human-\\nannotated training data. Ideally, a computer would be able to acquire language like a child by being\\nexposed to linguistic input in the context of a relevant but ambiguous perceptual environment. As\\na step in this direction, we have developed systems that learn to sportscast simulated robot soccer\\ngames and to follow navigation instructions in virtual environments by simply observing sample hu-\\nman linguistic behavior in context. This work builds on our earlier work on supervised learning of\\nsemantic parsers that map natural language into a formal meaning representation. In order to apply\\nsuch methods to learning from observation, we have developed methods that estimate the meaning of\\nsentences given just their ambiguous perceptual context.\\n602\\n'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract.loc[379].text.split('\\nAbstract\\n')[-1].split('\\n1 ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ref = lambda x: x.split('\\nAcknowledgements')[0].split('\\nReferences')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_title = lambda x: x.split('\\nAbstract\\n')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "papers_with_abstract['text'] = papers_with_abstract['text'].apply(no_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "papers_with_abstract['text'] = papers_with_abstract['text'].apply(no_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_abstract.to_csv('papers_with_abstract.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_abstract  = pd.read_csv('papers_with_abstract.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_abstract = lambda x: x.split('\\nAbstract\\n')[-1].split('\\n1 ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_abstract = papers_with_abstract[papers_with_abstract.text.notnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper describes the NECA MNLG;\\na fully implemented Multimodal Natu-\\nral Language Generation module. The\\nMNLG is deployed as part of the NECA\\nsystem which generates dialogues be-\\ntween animated agents. The genera-\\ntion module supports the seamless inte-\\ngration of full grammar rules, templates\\nand canned text. The generator takes in-\\nput which allows for the specification of\\nsyntactic, semantic and pragmatic con-\\nstraints on the output.'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract.iloc[0].text.split('\\nAbstract\\n')[-1].split('\\n1 ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_text = pd.read_csv('papers_with_text.to_csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_abstract['abstract'] = papers_with_abstract['text'].apply(get_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This paper describes the NECA MNLG;\\r\\na fully implemented Multimodal Natu-\\r\\nral Language Generation module. The\\r\\nMNLG is deployed as part of the NECA\\r\\nsystem which generates dialogues be-\\r\\ntween animated agents. The genera-\\r\\ntion module supports the seamless inte-\\r\\ngration of full grammar rules, templates\\r\\nand canned text. The generator takes in-\\r\\nput which allows for the specification of\\r\\nsyntactic, semantic and pragmatic con-\\r\\nstraints on the output.\\r'\n",
      " 'I propose a uniform approach to the elim-\\r\\nination of redundancy in CCG lexicons,\\r\\nwhere grammars incorporate inheritance\\r\\nhierarchies of lexical types, defined over\\r\\na simple, feature-based category descrip-\\r\\ntion language. The resulting formalism is\\r\\npartially ?constraint-based?, in that the cat-\\r\\negory notation is interpreted against an un-\\r\\nderlying set of tree-like feature structures.\\r\\nI argue that this version of CCG subsumes\\r\\na number of other proposed category no-\\r\\ntations devised to allow for the construc-\\r\\ntion of more efficient lexicons. The for-\\r\\nmalism retains desirable properties such\\r\\nas tractability and strong competence, and\\r\\nprovides a way of approaching the prob-\\r\\nlem of how to generalise CCG lexicons\\r\\nwhich have been automatically induced\\r\\nfrom treebanks.\\r'\n",
      " 'We present a new method for detecting and\\r\\ndisambiguating named entities in open do-\\r\\nmain text. A disambiguation SVM kernel\\r\\nis trained to exploit the high coverage and\\r\\nrich structure of the knowledge encoded\\r\\nin an online encyclopedia. The resulting\\r\\nmodel significantly outperforms a less in-\\r\\nformed baseline.\\r'\n",
      " ...\n",
      " 'Statistical Machine Translation (SMT)\\r\\nsystems are heavily dependent on the qual-\\r\\nity of parallel corpora used to train transla-\\r\\ntion models. Translation quality between\\r\\ncertain Indian languages is often poor due\\r\\nto the lack of training data of good qual-\\r\\nity. We used triangulation as a technique\\r\\nto improve the quality of translations in\\r\\ncases where the direct translation model\\r\\ndid not perform satisfactorily. Triangula-\\r\\ntion uses a third language as a pivot be-\\r\\ntween the source and target languages to\\r\\nachieve an improved and more efficient\\r\\ntranslation model in most cases. We also\\r\\ncombined multi-pivot models using linear\\r\\nmixture and obtained significant improve-\\r\\nment in BLEU scores compared to the di-\\r\\nrect source-target models.\\r'\n",
      " 'This paper describes an experiment compar-\\r\\ning results of machine translation between two\\r\\nclosely related languages, Czech and Slovak.\\r\\nThe comparison is performed by means of two\\r\\nMT systems, one representing rule-based ap-\\r\\nproach, the other one representing statistical\\r\\napproach to the task. Both sets of results are\\r\\nmanually evaluated by native speakers of the\\r\\ntarget language. The results are discussed both\\r\\nfrom the linguistic and quantitative points of\\r\\nview.\\r'\n",
      " 'Dialects and standard forms of a language\\r\\ntypically share a set of cognates that could\\r\\nbear the same meaning in both varieties or\\r\\nonly be shared homographs but serve as\\r\\nfaux amis. Moreover, there are words that\\r\\nare used exclusively in the dialect or the\\r\\nstandard variety. Both phenomena, faux\\r\\namis and exclusive vocabulary, are consid-\\r\\nered out of vocabulary (OOV) phenomena.\\r\\nIn this paper, we present this problem of\\r\\nOOV in the context of machine translation.\\r\\nWe present a new approach for dialect\\r\\nto English Statistical Machine Translation\\r\\n(SMT) enhancement based on normaliz-\\r\\ning dialectal language into standard form\\r\\nto provide equivalents to address both as-\\r\\npects of the OOV problem posited by di-\\r\\nalectal language use. We specifically fo-\\r\\ncus on Arabic to English SMT. We use\\r\\ntwo publicly available dialect identifica-\\r\\ntion tools: AIDA and MADAMIRA, to\\r\\nidentify and replace dialectal Arabic OOV\\r\\nwords with their modern standard Arabic\\r\\n(MSA) equivalents. The results of evalua-\\r\\ntion on two blind test sets show that using\\r\\nAIDA to identify and replace MSA equiv-\\r\\nalents enhances translation results by 0.4%\\r\\nabsolute BLEU (1.6% relative BLEU) and\\r\\nusing MADAMIRA achieves 0.3% ab-\\r\\nsolute BLEU (1.2% relative BLEU) en-\\r\\nhancement over the baseline. We show\\r\\nour replacement scheme reaches a notice-\\r\\nable enhancement in SMT performance\\r\\nfor faux amis words.\\r']\n"
     ]
    }
   ],
   "source": [
    "print(papers_with_abstract['abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from stop_words import get_stop_words\n",
    "stopwords = get_stop_words('english') \n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provid\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('provides'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'provides'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer.lemmatize('provides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stopwords):\n",
    "    text = text.replace('-\\n', '').replace('\\n', ' ').lower()\n",
    "    tokens = re.findall(r'[a-z]+', text)\n",
    "    return ' '.join([token for token in tokens if token not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'limited coverage lexical semantic re sources significant problem nlp sys tems can alleviated automati cally classifying unknown words su persense tagging assigns unknown nouns one broad semantic categories used lex icographers organise manual inser tion wordnet ciaramita johnson present tagger uses synonym set glosses annotated training examples describe unsupervised approach based vector space similarity require annotated examples significantly outper forms tagger also demonstrate use extremely large shallow parsed corpus calculating vector space semantic similarity'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(papers_with_abstract.iloc[1000]['abstract'], stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The limited coverage of lexical-semantic re-\\r\\nsources is a significant problem for NLP sys-\\r\\ntems which can be alleviated by automati-\\r\\ncally classifying the unknown words. Su-\\r\\npersense tagging assigns unknown nouns one\\r\\nof 26 broad semantic categories used by lex-\\r\\nicographers to organise their manual inser-\\r\\ntion into WORDNET. Ciaramita and Johnson\\r\\n(2003) present a tagger which uses synonym\\r\\nset glosses as annotated training examples. We\\r\\ndescribe an unsupervised approach, based on\\r\\nvector-space similarity, which does not require\\r\\nannotated examples but significantly outper-\\r\\nforms their tagger. We also demonstrate the use\\r\\nof an extremely large shallow-parsed corpus for\\r\\ncalculating vector-space semantic similarity.\\r'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_abstract.iloc[1000]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
