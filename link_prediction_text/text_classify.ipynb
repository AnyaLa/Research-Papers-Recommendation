{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test, \\\n",
    "        precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, \\\n",
    "        f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, \\\n",
    "        roc_auc_train, roc_auc_test, logloss_train, logloss_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_links_connected = pd.read_csv('aan_links_connected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_05_no_isolated.csv')\n",
    "aan_train = pd.read_csv('train_2013_05_no_isolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407a7820c3704b94b640c4fdf1f7f13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74860), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13506\n",
      "Number of edges: 74860\n",
      "Average in degree:   5.5427\n",
      "Average out degree:   5.5427\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_links_connected.index):\n",
    "    G.add_edge(aan_links_connected.iloc[i]['citing'], aan_links_connected.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacd5a77f8d340c3be62672204d211d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64024), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13493\n",
      "Number of edges: 64024\n",
      "Average in degree:   4.7450\n",
      "Average out degree:   4.7450\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges(graph, count_gen_edges, part_neg_directed):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    edges = list(graph.edges())\n",
    "\n",
    "    count_neg_directed = int(part_neg_directed*count_gen_edges)\n",
    "    for a, b in edges:\n",
    "        if len(negative_edges) >= count_neg_directed:\n",
    "            break\n",
    "        if not graph.has_edge(b, a):\n",
    "            negative_edges.add((b, a))       \n",
    "    \n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if (i != j) and not graph.has_edge(nodes[i], nodes[j]):\n",
    "            negative_edges.add((nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges_test(graph, test_nodes, count_gen_edges):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(test_nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if i == j:\n",
    "            continue\n",
    "        if graph.has_edge(test_nodes[i], nodes[j]):\n",
    "            continue\n",
    "        negative_edges.add((test_nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_preprocess(positive_df, neg_list):\n",
    "    pairs = list(zip(list(positive_df['citing']), list(positive_df['cited']), [1]*len(positive_df)))\n",
    "    neg_pairs = list(zip(list(zip(*neg_list))[0],list(zip(*neg_list))[1], [0]*len(neg_list)))\n",
    "    pairs += neg_pairs\n",
    "    random.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(u,v):\n",
    "    return u*v\n",
    "def mean(u,v):\n",
    "    return (u+v)/2\n",
    "def l1(u,v):\n",
    "    return np.abs(u-v)\n",
    "def l2(u,v):\n",
    "    return (u-v)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(u,v):\n",
    "    return np.concatenate([u, v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./asymproj_edge_dnn-master/datasets/aan_graph/index.pkl', 'rb') as f:\n",
    "    index_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_mean_emb = np.load('X_mean_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 600\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = concat(ft_mean_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    ft_mean_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = concat(ft_mean_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    ft_mean_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128048, 600)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7960253596683736\n",
      "Recall: 0.6025286083425618\n",
      "Accuracy: 0.7240679217423404\n",
      "F1-macro: 0.7199307941302755\n",
      "F1-micro: 0.7240679217423405\n",
      "Logloss: 9.530418077153314\n",
      "ROC-AUC: 0.7240679217423404\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.85      0.75     10836\n",
      "          1       0.80      0.60      0.69     10836\n",
      "\n",
      "avg / total       0.74      0.72      0.72     21672\n",
      "\n",
      "[[9163 1673]\n",
      " [4307 6529]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_weight_emb = np.load('X_tfidf_text_emb_13506.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 600\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = concat(ft_weight_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    ft_weight_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = concat(ft_weight_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    ft_weight_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7917684416218856\n",
      "Recall: 0.5982834994462901\n",
      "Accuracy: 0.7204688076781101\n",
      "F1-macro: 0.7162323699150104\n",
      "F1-micro: 0.7204688076781101\n",
      "Logloss: 9.654728253690818\n",
      "ROC-AUC: 0.72046880767811\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.84      0.75     10836\n",
      "          1       0.79      0.60      0.68     10836\n",
      "\n",
      "avg / total       0.73      0.72      0.72     21672\n",
      "\n",
      "[[9131 1705]\n",
      " [4353 6483]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "tfidf_matrix = sparse.load_npz(\"X_tfidf_13506.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=300, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(300)\n",
    "svd.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_svd = svd.transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 600\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = concat(tfidf_svd[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    tfidf_svd[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = concat(tfidf_svd[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    tfidf_svd[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8152764067127345\n",
      "Recall: 0.6097268364710225\n",
      "Accuracy: 0.7357881136950905\n",
      "F1-macro: 0.7315216038639952\n",
      "F1-micro: 0.7357881136950905\n",
      "Logloss: 9.125610494398835\n",
      "ROC-AUC: 0.7357881136950905\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.86      0.77     10836\n",
      "          1       0.82      0.61      0.70     10836\n",
      "\n",
      "avg / total       0.75      0.74      0.73     21672\n",
      "\n",
      "[[9339 1497]\n",
      " [4229 6607]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
