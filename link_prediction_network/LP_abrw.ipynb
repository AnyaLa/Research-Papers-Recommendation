{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/houchengbin/OpenANE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test, \\\n",
    "        precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, \\\n",
    "        f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, \\\n",
    "        roc_auc_train, roc_auc_test, logloss_train, logloss_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_links_connected = pd.read_csv('aan_links_connected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74860, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c45540bb70943cd8ce15f4587b66c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74860), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13506\n",
      "Number of edges: 74860\n",
      "Average in degree:   5.5427\n",
      "Average out degree:   5.5427\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_links_connected.index):\n",
    "    G.add_edge(aan_links_connected.iloc[i]['citing'], aan_links_connected.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('G_aan_13506')\n",
    "G_train = nx.read_gpickle('G_aan_13506_train_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges(graph, count_gen_edges, part_neg_directed):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    edges = list(graph.edges())\n",
    "\n",
    "    count_neg_directed = int(part_neg_directed*count_gen_edges)\n",
    "    for a, b in edges:\n",
    "        if len(negative_edges) >= count_neg_directed:\n",
    "            break\n",
    "        if not graph.has_edge(b, a):\n",
    "            negative_edges.add((b, a))       \n",
    "    \n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if (i != j) and not graph.has_edge(nodes[i], nodes[j]):\n",
    "            negative_edges.add((nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges_test(graph, test_nodes, count_gen_edges):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(test_nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if i == j:\n",
    "            continue\n",
    "        if graph.has_edge(test_nodes[i], nodes[j]):\n",
    "            continue\n",
    "        negative_edges.add((test_nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_time(links_df, meta_df):\n",
    "    years = meta_df[['id','year']]\n",
    "    years.columns = ['citing', 'year_citing']\n",
    "    links_df = links_df.merge(years, how = 'left', on = 'citing')\n",
    "    years.columns = ['cited', 'year_cited']\n",
    "    links_df = links_df.merge(years, how='left', on = 'cited')\n",
    "    links_df['out_cites_count'] = links_df.groupby('citing')['cited'].transform(lambda x: x.count())\n",
    "    links_df['in_cites_count'] = links_df.groupby('cited')['citing'].transform(lambda x: x.count())\n",
    "    links_df['cite_rank'] = links_df.groupby('citing')['cited'].transform(lambda x: x.rank())\n",
    "    return links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(links_years_df, year, part=None):\n",
    "    \"\"\"\n",
    "    links_years_df - cite edges dataframe with year of citing paper\n",
    "    year - first year of test period\n",
    "    part - part of test period edges to include into train\"\"\"\n",
    "    if part:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)|\\\n",
    "                               ((links_years_df.year_citing >= year)&\\\n",
    "                                ((links_years_df.cite_rank < part*links_years_df.out_cites_count + 1)|\\\n",
    "                                (links_years_df.in_cites_count == 1)))]\n",
    "        test = links_years_df[((links_years_df.year_citing >= year)&\\\n",
    "                                (links_years_df.cite_rank >= part*links_years_df.out_cites_count + 1)&\\\n",
    "                              (links_years_df.in_cites_count != 1))]\n",
    "    else:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)]\n",
    "        test = links_years_df[(links_years_df.year_citing >= year)]\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(u,v):\n",
    "    return u*v\n",
    "def mean(u,v):\n",
    "    return (u+v)/2\n",
    "def l1(u,v):\n",
    "    return np.abs(u-v)\n",
    "def l2(u,v):\n",
    "    return (u-v)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 links for test nodes ( > 2013) used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_05.csv', index=False)\n",
    "aan_train.to_csv('train_2013_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_05.csv')\n",
    "aan_train = pd.read_csv('train_2013_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_05_no_isolated.csv')\n",
    "aan_train = pd.read_csv('train_2013_05_no_isolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15295217739780925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49dec3a452440b5b0b1cc7537580a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63410), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "# print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13444\n",
      "Number of edges: 63410\n",
      "Average in degree:   4.7166\n",
      "Average out degree:   4.7166\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_preprocess(positive_df, neg_list):\n",
    "    pairs = list(zip(list(positive_df['citing']), list(positive_df['cited']), [1]*len(positive_df)))\n",
    "    neg_pairs = list(zip(list(zip(*neg_list))[0],list(zip(*neg_list))[1], [0]*len(neg_list)))\n",
    "    pairs += neg_pairs\n",
    "    random.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aan_abrw_emb_128.txt', 'r') as f:\n",
    "    abrw_emb = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrw_emb = [(int(emb.split()[0]),[float(num) for num in emb.split()[1:]]) for emb in abrw_emb.split('\\n')[1:] if emb != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13506"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abrw_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrw_emb = sorted(abrw_emb, key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, vecs = zip(*abrw_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrw_emb_matr = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2062004 , -0.19029757,  0.137299  , ..., -0.0541796 ,\n",
       "         0.01296847, -0.12731244],\n",
       "       [ 0.10474256,  0.1137826 , -0.26420864, ..., -0.14131752,\n",
       "         0.07429265,  0.37535784],\n",
       "       [ 0.23076214, -0.12822674,  0.18455397, ...,  0.36645988,\n",
       "        -0.1084687 , -0.17594132],\n",
       "       ...,\n",
       "       [-0.01035675, -0.02917514, -0.00813602, ..., -0.32923788,\n",
       "         0.32808638, -0.10091236],\n",
       "       [-0.15382831,  0.03035559,  0.13049498, ...,  0.02312758,\n",
       "        -0.3340426 ,  0.02827339],\n",
       "       [ 0.1580649 ,  0.13279736,  0.00079761, ...,  0.20646344,\n",
       "        -0.53030384,  0.18626145]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abrw_emb_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abrw_emb_matr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('abrw_emb_matr.npy', abrw_emb_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./asymproj_edge_dnn-master/datasets/aan_graph/index.pkl', 'rb') as f:\n",
    "    index_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5896"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_graph['index'][train_pairs[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean edge aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(abrw_emb_matr[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(abrw_emb_matr[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8107529075698837\n",
      "Recall: 0.6940611353711791\n",
      "Accuracy: 0.7660262008733625\n",
      "F1-macro: 0.7648081491802047\n",
      "F1-micro: 0.7660262008733626\n",
      "Logloss: 8.08123350118622\n",
      "ROC-AUC: 0.7660262008733626\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.84      0.78     11450\n",
      "          1       0.81      0.69      0.75     11450\n",
      "\n",
      "avg / total       0.77      0.77      0.76     22900\n",
      "\n",
      "[[9595 1855]\n",
      " [3503 7947]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(abrw_emb_matr[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(abrw_emb_matr[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9359451290397582\n",
      "Recall: 0.7429863418235512\n",
      "Accuracy: 0.8460686600221484\n",
      "F1-macro: 0.8444154238666042\n",
      "F1-micro: 0.8460686600221485\n",
      "Logloss: 5.316620461037565\n",
      "ROC-AUC: 0.8460686600221484\n"
     ]
    }
   ],
   "source": [
    "# new train/test, no isolated\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9381544502617801\n",
      "Recall: 0.75117903930131\n",
      "Accuracy: 0.8508296943231441\n",
      "F1-macro: 0.849333538232202\n",
      "F1-micro: 0.8508296943231441\n",
      "Logloss: 5.152179630426106\n",
      "ROC-AUC: 0.8508296943231441\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.95      0.86     11450\n",
      "          1       0.94      0.75      0.83     11450\n",
      "\n",
      "avg / total       0.87      0.85      0.85     22900\n",
      "\n",
      "[[10883   567]\n",
      " [ 2849  8601]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l1(abrw_emb_matr[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l1(abrw_emb_matr[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9280798348245011\n",
      "Recall: 0.7066375545851529\n",
      "Accuracy: 0.8259388646288209\n",
      "F1-macro: 0.8234257177288802\n",
      "F1-micro: 0.8259388646288209\n",
      "Logloss: 6.011880526537237\n",
      "ROC-AUC: 0.8259388646288209\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.95      0.84     11450\n",
      "          1       0.93      0.71      0.80     11450\n",
      "\n",
      "avg / total       0.85      0.83      0.82     22900\n",
      "\n",
      "[[10823   627]\n",
      " [ 3359  8091]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l2(abrw_emb_matr[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l2(abrw_emb_matr[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9249547920433996\n",
      "Recall: 0.7147598253275109\n",
      "Accuracy: 0.8283842794759826\n",
      "F1-macro: 0.8261396525778912\n",
      "F1-micro: 0.8283842794759826\n",
      "Logloss: 5.927420181864307\n",
      "ROC-AUC: 0.8283842794759825\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.94      0.85     11450\n",
      "          1       0.92      0.71      0.81     11450\n",
      "\n",
      "avg / total       0.85      0.83      0.83     22900\n",
      "\n",
      "[[10786   664]\n",
      " [ 3266  8184]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best result: Random Forest + product edge function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 links used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2004942559444296"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b972dc4eee46d592d12b6aad04226f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=59851), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13490\n",
      "Number of edges: 59851\n",
      "Average in degree:   4.4367\n",
      "Average out degree:   4.4367\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_03.csv', index=False)\n",
    "aan_train.to_csv('train_2013_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_03.csv')\n",
    "aan_train = pd.read_csv('train_2013_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(abrw_emb_matr[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(abrw_emb_matr[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9380396140172677\n",
      "Recall: 0.7383569858085149\n",
      "Accuracy: 0.8447931241255247\n",
      "F1-macro: 0.843014692277462\n",
      "F1-micro: 0.8447931241255247\n",
      "Logloss: 5.360675079259369\n",
      "ROC-AUC: 0.8447931241255247\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86     15009\n",
      "          1       0.94      0.74      0.83     15009\n",
      "\n",
      "avg / total       0.86      0.84      0.84     30018\n",
      "\n",
      "[[14277   732]\n",
      " [ 3927 11082]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2612343040341972"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ec0afeec974b0ab4cdd5ff794e6a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=55304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13489\n",
      "Number of edges: 55304\n",
      "Average in degree:   4.0999\n",
      "Average out degree:   4.0999\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_01.csv', index=False)\n",
    "aan_train.to_csv('train_2013_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0.5)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(abrw_emb_matr[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(abrw_emb_matr[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    abrw_emb_matr[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9200088144557074\n",
      "Recall: 0.6404683984454899\n",
      "Accuracy: 0.7923910820208632\n",
      "F1-macro: 0.7874861558619524\n",
      "F1-micro: 0.7923910820208631\n",
      "Logloss: 7.170580258955722\n",
      "ROC-AUC: 0.7923910820208632\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
