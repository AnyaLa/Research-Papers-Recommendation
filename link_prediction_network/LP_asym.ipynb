{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test, \\\n",
    "        precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, \\\n",
    "        f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, \\\n",
    "        roc_auc_train, roc_auc_test, logloss_train, logloss_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_links_connected = pd.read_csv('aan_links_connected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74860, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f9c826b1bb47b2b70b526d874e3581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74860), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13506\n",
      "Number of edges: 74860\n",
      "Average in degree:   5.5427\n",
      "Average out degree:   5.5427\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_links_connected.index):\n",
    "    G.add_edge(aan_links_connected.iloc[i]['citing'], aan_links_connected.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('G_aan_13506')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = nx.read_gpickle('G_aan_13506_train_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges(graph, count_gen_edges, part_neg_directed):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    edges = list(graph.edges())\n",
    "\n",
    "    count_neg_directed = int(part_neg_directed*count_gen_edges)\n",
    "    for a, b in edges:\n",
    "        if len(negative_edges) >= count_neg_directed:\n",
    "            break\n",
    "        if not graph.has_edge(b, a):\n",
    "            negative_edges.add((b, a))       \n",
    "    \n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if (i != j) and not graph.has_edge(nodes[i], nodes[j]):\n",
    "            negative_edges.add((nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges_test(graph, test_nodes, count_gen_edges):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(test_nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if i == j:\n",
    "            continue\n",
    "        if graph.has_edge(test_nodes[i], nodes[j]):\n",
    "            continue\n",
    "        negative_edges.add((test_nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_time(links_df, meta_df):\n",
    "    years = meta_df[['id','year']]\n",
    "    years.columns = ['citing', 'year_citing']\n",
    "    links_df = links_df.merge(years, how = 'left', on = 'citing')\n",
    "    years.columns = ['cited', 'year_cited']\n",
    "    links_df = links_df.merge(years, how='left', on = 'cited')\n",
    "    links_df['out_cites_count'] = links_df.groupby('citing')['cited'].transform(lambda x: x.count())\n",
    "    links_df['in_cites_count'] = links_df.groupby('cited')['citing'].transform(lambda x: x.count())\n",
    "    links_df['cite_rank'] = links_df.groupby('citing')['cited'].transform(lambda x: x.rank())\n",
    "    return links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(links_years_df, year, part=None):\n",
    "    \"\"\"\n",
    "    links_years_df - cite edges dataframe with year of citing paper\n",
    "    year - first year of test period\n",
    "    part - part of test period edges to include into train\"\"\"\n",
    "    if part:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)|\\\n",
    "                               ((links_years_df.year_citing >= year)&\\\n",
    "                                ((links_years_df.cite_rank < part*links_years_df.out_cites_count + 1)|\\\n",
    "                                (links_years_df.in_cites_count == 1)))]\n",
    "        test = links_years_df[((links_years_df.year_citing >= year)&\\\n",
    "                                (links_years_df.cite_rank >= part*links_years_df.out_cites_count + 1)&\\\n",
    "                              (links_years_df.in_cites_count != 1))]\n",
    "    else:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)]\n",
    "        test = links_years_df[(links_years_df.year_citing >= year)]\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(u,v):\n",
    "    return u*v\n",
    "def mean(u,v):\n",
    "    return (u+v)/2\n",
    "def l1(u,v):\n",
    "    return np.abs(u-v)\n",
    "def l2(u,v):\n",
    "    return (u-v)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undirected asym_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 links for test nodes ( > 2013) used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_05_no_isolated.csv', index=False)\n",
    "aan_train.to_csv('train_2013_05_no_isolated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_05_no_isolated.csv')\n",
    "aan_train = pd.read_csv('train_2013_05_no_isolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14475020037403152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_test) + len(aan_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb88ea63657347aaa0d6a8769767b4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63410), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "# print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13444\n",
      "Number of edges: 63410\n",
      "Average in degree:   4.7166\n",
      "Average out degree:   4.7166\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_preprocess(positive_df, neg_list):\n",
    "    pairs = list(zip(list(positive_df['citing']), list(positive_df['cited']), [1]*len(positive_df)))\n",
    "    neg_pairs = list(zip(list(zip(*neg_list))[0],list(zip(*neg_list))[1], [0]*len(neg_list)))\n",
    "    pairs += neg_pairs\n",
    "    random.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_emb = np.load('asymproj_edge_dnn-master/datasets/aan_graph/dumps/test.d100_f100x100_g32_embeddings.npy.best')\n",
    "\n",
    "# asym_emb = np.load('asymproj_edge_dnn-master/datasets/aan_custom_datasets/dumps/dumps/test.d100_f100x100_g32_embeddings.npy.best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asym_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./asymproj_edge_dnn-master/datasets/aan_graph/index.pkl', 'rb') as f:\n",
    "    index_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean edge aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(asym_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(asym_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5301375144582958\n",
      "Recall: 0.3806755260243632\n",
      "Accuracy: 0.521640826873385\n",
      "F1-macro: 0.5119425314746969\n",
      "F1-micro: 0.521640826873385\n",
      "Logloss: 16.522075406711142\n",
      "ROC-AUC: 0.521640826873385\n"
     ]
    }
   ],
   "source": [
    "# new test, no isolated, emb on custon train/test\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5333248698743176\n",
      "Recall: 0.3876891842008121\n",
      "Accuracy: 0.5242248062015504\n",
      "F1-macro: 0.5151869325981351\n",
      "F1-micro: 0.5242248062015504\n",
      "Logloss: 16.432828660394865\n",
      "ROC-AUC: 0.5242248062015504\n"
     ]
    }
   ],
   "source": [
    "# new train/test no isolated\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.539189837008629\n",
      "Recall: 0.39292576419213976\n",
      "Accuracy: 0.5285589519650655\n",
      "F1-macro: 0.5197236138859492\n",
      "F1-micro: 0.5285589519650655\n",
      "Logloss: 16.283131197012004\n",
      "ROC-AUC: 0.5285589519650655\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.66      0.58     11450\n",
      "          1       0.54      0.39      0.45     11450\n",
      "\n",
      "avg / total       0.53      0.53      0.52     22900\n",
      "\n",
      "[[7605 3845]\n",
      " [6951 4499]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(asym_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(asym_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5166193006301742\n",
      "Recall: 0.38584348468069396\n",
      "Accuracy: 0.5124123292727943\n",
      "F1-macro: 0.504474167764043\n",
      "F1-micro: 0.5124123292727943\n",
      "Logloss: 16.840825867025103\n",
      "ROC-AUC: 0.5124123292727943\n"
     ]
    }
   ],
   "source": [
    "# new emb on custom train/test\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5106407995296884\n",
      "Recall: 0.3793013100436681\n",
      "Accuracy: 0.5079039301310043\n",
      "F1-macro: 0.499628468561906\n",
      "F1-micro: 0.5079039301310043\n",
      "Logloss: 16.996541446233756\n",
      "ROC-AUC: 0.5079039301310044\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.64      0.56     11450\n",
      "          1       0.51      0.38      0.44     11450\n",
      "\n",
      "avg / total       0.51      0.51      0.50     22900\n",
      "\n",
      "[[7288 4162]\n",
      " [7107 4343]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l1(asym_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l1(asym_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5063750146215932\n",
      "Recall: 0.37807860262008736\n",
      "Accuracy: 0.504759825327511\n",
      "F1-macro: 0.49668251987460815\n",
      "F1-micro: 0.504759825327511\n",
      "Logloss: 17.10513700418504\n",
      "ROC-AUC: 0.504759825327511\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.63      0.56     11450\n",
      "          1       0.51      0.38      0.43     11450\n",
      "\n",
      "avg / total       0.51      0.50      0.50     22900\n",
      "\n",
      "[[7230 4220]\n",
      " [7121 4329]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l2(asym_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l2(asym_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5046544100535257\n",
      "Recall: 0.37877729257641923\n",
      "Accuracy: 0.5034934497816594\n",
      "F1-macro: 0.4956487093513078\n",
      "F1-micro: 0.5034934497816594\n",
      "Logloss: 17.14887735792117\n",
      "ROC-AUC: 0.5034934497816593\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.63      0.56     11450\n",
      "          1       0.50      0.38      0.43     11450\n",
      "\n",
      "avg / total       0.50      0.50      0.50     22900\n",
      "\n",
      "[[7193 4257]\n",
      " [7113 4337]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best result: Random Forest + product edge function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 links used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2004942559444296"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca398b4e049948229bbe504c90b60000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=59851), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13490\n",
      "Number of edges: 59851\n",
      "Average in degree:   4.4367\n",
      "Average out degree:   4.4367\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_03.csv', index=False)\n",
    "aan_train.to_csv('train_2013_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_03.csv')\n",
    "aan_train = pd.read_csv('train_2013_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(asym_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(asym_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5480158364791455\n",
      "Recall: 0.39656206276234257\n",
      "Accuracy: 0.5347458191751616\n",
      "F1-macro: 0.5256889683491461\n",
      "F1-micro: 0.5347458191751616\n",
      "Logloss: 16.06944088064186\n",
      "ROC-AUC: 0.5347458191751615\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.67      0.59     15009\n",
      "          1       0.55      0.40      0.46     15009\n",
      "\n",
      "avg / total       0.54      0.53      0.53     30018\n",
      "\n",
      "[[10100  4909]\n",
      " [ 9057  5952]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2612343040341972"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005a4950751d4c0c8f21f2b66a9b268d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=55304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13489\n",
      "Number of edges: 55304\n",
      "Average in degree:   4.0999\n",
      "Average out degree:   4.0999\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_01.csv', index=False)\n",
    "aan_train.to_csv('train_2013_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(asym_emb[index_graph['index'][train_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][train_pairs[i][1]]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(asym_emb[index_graph['index'][test_pairs[i][0]]],\n",
    "                                    asym_emb[index_graph['index'][test_pairs[i][1]]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5461166798875027\n",
      "Recall: 0.3872468807527102\n",
      "Accuracy: 0.5327009613417877\n",
      "F1-macro: 0.522600676580169\n",
      "F1-micro: 0.5327009613417877\n",
      "Logloss: 16.140065678973418\n",
      "ROC-AUC: 0.5327009613417877\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asym_emb = np.load('asymproj_edge_dnn-master/datasets/aan_graph/dumps/test.d100_f100x100_g32_embeddings.npy.best')\n",
    "\n",
    "asym_emb = np.load('asymproj_edge_dnn-master/datasets/aan_custom_datasets/directed/dumps/test.d100_f100x100_g32_embeddings.npy.best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./asymproj_edge_dnn-master/datasets/aan_graph/dumps/test.d100_f100x100_g32_net.pkl.best', 'rb') as f:\n",
    "#     test_net = pickle.load(f)\n",
    "\n",
    "with open('./asymproj_edge_dnn-master/datasets/aan_custom_datasets/directed/dumps/test.d100_f100x100_g32_net.pkl.best', 'rb') as f:\n",
    "    test_net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = list(test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fully_connected/weights:0', array([[ 0.10851946, -0.14215657,  0.05383222, ..., -0.116536  ,\n",
      "         0.1275872 , -0.00754973],\n",
      "       [-0.11152562, -0.09869028,  0.01061374, ...,  0.2220751 ,\n",
      "         0.09539881, -0.02197587],\n",
      "       [ 0.06320386, -0.12298661, -0.03535729, ..., -0.04209198,\n",
      "        -0.05899743, -0.11664581],\n",
      "       ...,\n",
      "       [-0.03499449,  0.03586356, -0.0738299 , ..., -0.01834275,\n",
      "        -0.11007538, -0.12166001],\n",
      "       [ 0.06282356, -0.15001814,  0.11422365, ...,  0.15422584,\n",
      "         0.04278898, -0.06598209],\n",
      "       [-0.11736944,  0.01918805, -0.05994429, ..., -0.09034131,\n",
      "        -0.09074124, -0.04744608]], dtype=float32))\n",
      "(100, 100)\n",
      "('fully_connected/BatchNorm/beta:0', array([-6.68858047e-05, -9.59280660e-05, -3.73361290e-05, -4.82153810e-05,\n",
      "       -4.86363206e-06, -8.79082581e-05,  5.07633195e-05, -7.27905281e-05,\n",
      "        2.11354145e-05, -6.15264507e-05,  1.32817404e-05, -1.89321290e-05,\n",
      "       -7.24329730e-05, -4.26166980e-06, -5.79720836e-05, -9.20653983e-05,\n",
      "       -1.59362899e-05, -4.92373738e-06,  1.26602508e-05, -4.97242836e-05,\n",
      "       -6.64359613e-05, -4.88287469e-06,  5.89563115e-06, -6.67828062e-05,\n",
      "       -3.91704416e-05, -7.73226293e-06, -1.46682778e-05,  1.05975205e-05,\n",
      "       -4.00460922e-05,  2.03404466e-06,  5.17843591e-06, -3.63530962e-05,\n",
      "       -2.70461496e-05, -2.02687061e-05, -4.59745570e-05, -5.79181396e-05,\n",
      "       -6.74729235e-05, -1.45337945e-05, -6.37880803e-05, -1.65549573e-05,\n",
      "       -6.92507892e-05, -4.12639165e-05, -5.02994735e-05,  2.94027759e-05,\n",
      "        3.93900518e-05,  3.14684039e-05, -3.02904446e-05, -2.15685868e-05,\n",
      "        2.36331325e-05, -6.62129532e-05,  1.02296663e-05, -3.67597677e-05,\n",
      "       -4.65304001e-05, -1.34476177e-05, -4.35019984e-07,  1.23668178e-05,\n",
      "       -8.27174372e-05, -2.98496016e-05, -7.84992953e-05, -5.53131576e-05,\n",
      "       -8.82212116e-05, -1.26360910e-05, -3.66037284e-06,  2.13130006e-05,\n",
      "       -3.16541336e-05, -3.58202815e-05,  1.06823818e-05,  2.01951843e-05,\n",
      "       -4.81611714e-05, -2.01351413e-05, -3.54467156e-05, -5.68524083e-05,\n",
      "       -1.45379199e-05, -1.82247095e-05, -1.48899380e-05, -3.45468143e-05,\n",
      "        4.52981794e-06, -7.40043106e-05, -1.09944822e-05, -1.31142542e-05,\n",
      "       -1.42930303e-05, -1.70138026e-06, -3.24391585e-05, -6.66539927e-05,\n",
      "       -1.46968086e-05,  1.73194530e-05, -1.45761835e-04,  5.91103981e-06,\n",
      "       -9.31295654e-05, -5.26061231e-05, -6.09521485e-05, -1.75093846e-05,\n",
      "        1.81718260e-05, -8.32235964e-05,  4.61885320e-05, -6.20109568e-05,\n",
      "       -2.98662762e-05, -7.70226616e-05,  3.20827166e-05, -5.60136068e-05],\n",
      "      dtype=float32))\n",
      "(100,)\n",
      "('fully_connected/BatchNorm/moving_mean:0', array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32))\n",
      "(100,)\n",
      "('fully_connected/BatchNorm/moving_variance:0', array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32))\n",
      "(100,)\n",
      "('fully_connected_1/weights:0', array([[ 0.13085961,  0.04423498,  0.02486122, ...,  0.01293452,\n",
      "        -0.15032211,  0.06078013],\n",
      "       [-0.11739524,  0.10756911, -0.19356963, ..., -0.16739868,\n",
      "        -0.05356044,  0.01634906],\n",
      "       [ 0.02045152,  0.00645698, -0.06149504, ..., -0.05674067,\n",
      "        -0.21616457,  0.17217262],\n",
      "       ...,\n",
      "       [ 0.01584617, -0.11561806,  0.01368015, ...,  0.09581516,\n",
      "         0.0873592 ,  0.11850792],\n",
      "       [-0.04849695,  0.18197083, -0.04320763, ..., -0.08472937,\n",
      "        -0.15109485, -0.06529094],\n",
      "       [-0.00438583, -0.13845555, -0.10703826, ..., -0.01163826,\n",
      "         0.01672372,  0.10411817]], dtype=float32))\n",
      "(100, 100)\n",
      "('fully_connected_1/BatchNorm/beta:0', array([ 5.97992903e-06, -1.27188823e-05, -2.52365862e-05, -8.06775091e-08,\n",
      "       -4.04932325e-06, -1.93030046e-05, -1.53091605e-05, -1.30374283e-05,\n",
      "       -1.28590300e-05,  5.63690774e-05, -8.48388026e-06, -6.29711894e-06,\n",
      "       -2.54177030e-05, -1.08833256e-05, -9.18845853e-06,  3.23335844e-05,\n",
      "        2.86975774e-06, -1.76125775e-06,  1.35720404e-06,  5.45904959e-06,\n",
      "       -4.18359195e-05, -8.38264168e-06,  2.06587902e-05, -4.09370987e-05,\n",
      "       -2.44899365e-05, -5.52602360e-05,  2.33511873e-05, -2.92007117e-05,\n",
      "       -8.81720371e-06, -2.97573133e-05, -1.79794097e-05, -1.56011338e-05,\n",
      "        1.20226446e-06,  1.91660056e-05,  3.69623365e-07, -1.18977723e-05,\n",
      "       -3.29217219e-05, -1.02212553e-05,  4.80570725e-06, -4.71603198e-05,\n",
      "       -1.80840834e-05, -1.50028918e-05,  6.81562096e-06,  2.79898195e-05,\n",
      "       -1.78858154e-05,  1.35782475e-05, -4.06037589e-06, -2.18871955e-05,\n",
      "       -1.27309359e-05,  5.20823887e-05, -7.17997755e-05, -1.96871133e-05,\n",
      "       -2.39836390e-05, -3.08366725e-05, -5.19049809e-06, -2.08698038e-05,\n",
      "       -6.80169137e-07,  4.38662137e-05, -2.72691486e-05,  3.79623816e-05,\n",
      "       -6.37688863e-05, -4.87960824e-06, -3.34799843e-05, -2.76659648e-05,\n",
      "        1.11749923e-05, -2.67503983e-05,  1.35787423e-05, -2.23075358e-06,\n",
      "       -1.07787446e-05,  1.87621445e-05,  2.79060569e-05,  4.41100696e-07,\n",
      "       -4.70623017e-05, -9.00818213e-06, -2.25715871e-06, -4.67569262e-05,\n",
      "        1.66321825e-05, -1.84832561e-06, -9.18257410e-06, -1.07185588e-05,\n",
      "        1.46028660e-05, -4.29237616e-06, -9.23771950e-06, -1.22252450e-05,\n",
      "       -1.21273069e-05, -1.86354850e-06,  2.34787440e-05, -1.04815908e-05,\n",
      "       -1.60792497e-05,  1.67109956e-05,  7.14738690e-06,  6.25098664e-06,\n",
      "       -3.14830359e-05, -4.81415882e-05, -4.06505278e-05, -1.49530761e-05,\n",
      "        8.34084494e-06, -1.94368549e-05, -1.71528118e-05, -4.74556582e-05],\n",
      "      dtype=float32))\n",
      "(100,)\n",
      "('fully_connected_1/BatchNorm/moving_mean:0', array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32))\n",
      "(100,)\n",
      "('fully_connected_1/BatchNorm/moving_variance:0', array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32))\n",
      "(100,)\n",
      "('g_left:0', array([[ 0.13074009, -0.1786658 ,  0.12236551, ..., -0.05330602,\n",
      "        -0.10633823,  0.02398905],\n",
      "       [-0.18183403,  0.11230171,  0.09532856, ...,  0.01113057,\n",
      "         0.12415051, -0.0601553 ],\n",
      "       [-0.00811259, -0.10462162, -0.05264353, ..., -0.13090682,\n",
      "         0.12585282, -0.14152476],\n",
      "       ...,\n",
      "       [ 0.07632019,  0.03295211, -0.04828682, ...,  0.00373183,\n",
      "         0.10367346,  0.09602206],\n",
      "       [ 0.17806982,  0.03435183, -0.1389141 , ...,  0.06618363,\n",
      "        -0.01476525,  0.07031165],\n",
      "       [ 0.06562898,  0.08741657,  0.10386968, ..., -0.0265063 ,\n",
      "        -0.04218221, -0.21058035]], dtype=float32))\n",
      "(100, 32)\n",
      "('g_right:0', array([[ 0.23072237, -0.24183567, -0.11369858, ...,  0.07121497,\n",
      "         0.16690587,  0.03068932],\n",
      "       [-0.1597904 ,  0.11805556, -0.13853312, ..., -0.04680726,\n",
      "         0.00654743,  0.15254463],\n",
      "       [ 0.07807544,  0.13409285, -0.09592288, ..., -0.02956019,\n",
      "         0.03075163,  0.0444291 ],\n",
      "       ...,\n",
      "       [ 0.02777527,  0.11327885, -0.14924508, ..., -0.10165169,\n",
      "         0.25833565, -0.01633171],\n",
      "       [ 0.04791202,  0.02998243,  0.01897023, ...,  0.08741158,\n",
      "         0.04590172,  0.04375883],\n",
      "       [ 0.11388669, -0.10291623, -0.08377764, ...,  0.03635124,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.06116296, -0.22983904]], dtype=float32))\n",
      "(32, 100)\n"
     ]
    }
   ],
   "source": [
    "for i in test_net:\n",
    "    print(i)\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.zeros((32, 100))\n",
    "L = np.zeros((100, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_net:\n",
    "    if i[0] == 'g_right:0':\n",
    "        R = i[1]\n",
    "    if i[0] == 'g_left:0':\n",
    "        L = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0.5)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([asym_emb[index_graph['index'][train_pairs[0][0]]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10851453], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([asym_emb[index_graph['index'][train_pairs[0][0]]]]).dot(L)).dot(R.dot(asym_emb[index_graph['index'][train_pairs[0][1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.transpose().dot(asym_emb[index_graph['index'][train_pairs[0][0]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.dot(asym_emb[index_graph['index'][train_pairs[0][1]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01485016,  0.10077673,  0.01040589, -0.02123228,  0.06818286,\n",
       "       -0.11407711, -0.04643111,  0.02280432,  0.018169  , -0.09937138,\n",
       "        0.02358127, -0.05552548,  0.03697368, -0.06532729,  0.04324254,\n",
       "       -0.01721333,  0.05355959, -0.07544747, -0.04646574, -0.04331411,\n",
       "        0.07283127, -0.00477601,  0.02687544,  0.02302699,  0.03585663,\n",
       "       -0.08086304, -0.00852232, -0.0351202 ,  0.03220697, -0.05776621,\n",
       "        0.12200874, -0.00615464], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(L.transpose().dot(asym_emb[index_graph['index'][train_pairs[0][0]]]), R.dot(asym_emb[index_graph['index'][train_pairs[0][1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(L.transpose().dot(asym_emb[index_graph['index'][train_pairs[i][0]]]), \n",
    "                         R.dot(asym_emb[index_graph['index'][train_pairs[i][1]]]))\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(L.transpose().dot(asym_emb[index_graph['index'][test_pairs[i][0]]]), \n",
    "                         R.dot(asym_emb[index_graph['index'][test_pairs[i][1]]]))    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.521570996978852\n",
      "Recall: 0.3983019564414913\n",
      "Accuracy: 0.5164728682170543\n",
      "F1-macro: 0.5096250943468668\n",
      "F1-micro: 0.5164728682170543\n",
      "Logloss: 16.700581554470986\n",
      "ROC-AUC: 0.5164728682170543\n"
     ]
    }
   ],
   "source": [
    "# new emb, new train/test\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5372179416620804\n",
      "Recall: 0.3993147883002659\n",
      "Accuracy: 0.5276641439967273\n",
      "F1-macro: 0.5197527637241232\n",
      "F1-micro: 0.5276641439967273\n",
      "Logloss: 16.314040039156595\n",
      "ROC-AUC: 0.5276641439967273\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
