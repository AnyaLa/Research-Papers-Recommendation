{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test, \\\n",
    "        precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, \\\n",
    "        f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, \\\n",
    "        roc_auc_train, roc_auc_test, logloss_train, logloss_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_links_connected = pd.read_csv('aan_links_connected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74860, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_links_connected.index):\n",
    "    G.add_edge(aan_links_connected.iloc[i]['citing'], aan_links_connected.iloc[i]['cited'])\n",
    "    \n",
    "# print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('G_aan_13506')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = nx.read_gpickle('G_aan_13506_train_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges(graph, count_gen_edges, part_neg_directed):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    edges = list(graph.edges())\n",
    "\n",
    "    count_neg_directed = int(part_neg_directed*count_gen_edges)\n",
    "    for a, b in edges:\n",
    "        if len(negative_edges) >= count_neg_directed:\n",
    "            break\n",
    "        if not graph.has_edge(b, a):\n",
    "            negative_edges.add((b, a))       \n",
    "    \n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if (i != j) and not graph.has_edge(nodes[i], nodes[j]):\n",
    "            negative_edges.add((nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges_test(graph, test_nodes, count_gen_edges):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(test_nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if i == j:\n",
    "            continue\n",
    "        if graph.has_edge(test_nodes[i], nodes[j]):\n",
    "            continue\n",
    "        negative_edges.add((test_nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_time(links_df, meta_df):\n",
    "    years = meta_df[['id','year']]\n",
    "    years.columns = ['citing', 'year_citing']\n",
    "    links_df = links_df.merge(years, how = 'left', on = 'citing')\n",
    "    years.columns = ['cited', 'year_cited']\n",
    "    links_df = links_df.merge(years, how='left', on = 'cited')\n",
    "    links_df['out_cites_count'] = links_df.groupby('citing')['cited'].transform(lambda x: x.count())\n",
    "    links_df['in_cites_count'] = links_df.groupby('cited')['citing'].transform(lambda x: x.count())\n",
    "    links_df['cite_rank'] = links_df.groupby('citing')['cited'].transform(lambda x: x.rank())\n",
    "    return links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(links_years_df, year, part=None):\n",
    "    \"\"\"\n",
    "    links_years_df - cite edges dataframe with year of citing paper\n",
    "    year - first year of test period\n",
    "    part - part of test period edges to include into train\"\"\"\n",
    "    if part:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)|\\\n",
    "                               ((links_years_df.year_citing >= year)&\\\n",
    "                                ((links_years_df.cite_rank < part*links_years_df.out_cites_count + 1)|\\\n",
    "                                (links_years_df.in_cites_count == 1)))]\n",
    "        test = links_years_df[((links_years_df.year_citing >= year)&\\\n",
    "                                (links_years_df.cite_rank >= part*links_years_df.out_cites_count + 1)&\\\n",
    "                              (links_years_df.in_cites_count != 1))]\n",
    "    else:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)]\n",
    "        test = links_years_df[(links_years_df.year_citing >= year)]\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(u,v):\n",
    "    return u*v\n",
    "def mean(u,v):\n",
    "    return (u+v)/2\n",
    "def l1(u,v):\n",
    "    return np.abs(u-v)\n",
    "def l2(u,v):\n",
    "    return (u-v)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 links for test nodes ( > 2013) used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_05.csv', index=False)\n",
    "aan_train.to_csv('train_2013_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aan_test = pd.read_csv('test_2013_05.csv')\n",
    "# aan_train = pd.read_csv('train_2013_05.csv')\n",
    "\n",
    "aan_test = pd.read_csv('test_2013_05_no_isolated.csv')\n",
    "aan_train = pd.read_csv('train_2013_05_no_isolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15295217739780925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b541029219ed413bb06701c30aa1c3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63410), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "# print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13493\n",
      "Number of edges: 64024\n",
      "Average in degree:   4.7450\n",
      "Average out degree:   4.7450\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0.5)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_preprocess(positive_df, neg_list):\n",
    "    pairs = list(zip(list(positive_df['citing']), list(positive_df['cited']), [1]*len(positive_df)))\n",
    "    neg_pairs = list(zip(list(zip(*neg_list))[0],list(zip(*neg_list))[1], [0]*len(neg_list)))\n",
    "    pairs += neg_pairs\n",
    "    random.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y = pd.DataFrame(data = test_pairs, columns = ['citing', 'cited', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_y.to_csv('test_x_y_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pctadw.embedding', 'r') as f:\n",
    "    pctadw_emb = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctadw_emb = [[float(num) for num in emb.split()] for emb in pctadw_emb.split('\\n') if emb != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13506"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pctadw_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctadw_emb_matr = np.array(pctadw_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00089386,  0.16098227, -0.21167406, ...,  0.21111514,\n",
       "         0.02308364, -0.07383676],\n",
       "       [ 0.29594016,  0.13280925, -0.1268356 , ...,  0.46518382,\n",
       "        -0.03072343,  0.65745521],\n",
       "       [-0.13309586,  0.400181  , -0.06074005, ..., -0.80929017,\n",
       "        -0.26320201,  0.01463345],\n",
       "       ...,\n",
       "       [-0.1279396 , -0.14702646, -0.25501603, ..., -0.10139858,\n",
       "         0.0052771 ,  0.21767963],\n",
       "       [ 0.15952791,  0.21629976,  0.11390562, ...,  0.32770464,\n",
       "        -0.04475396, -0.13116851],\n",
       "       [ 0.36052322,  0.01876117,  0.03143245, ...,  0.04357247,\n",
       "        -0.20669529, -0.2407275 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pctadw_emb_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13506, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pctadw_emb_matr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./asymproj_edge_dnn-master/datasets/aan_graph/index.pkl', 'rb') as f:\n",
    "    index_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_graph['index'][train_pairs[i][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean edge aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(pctadw_emb_matr[index_graph['index'][train_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][train_pairs[i][1]], embed_dim:])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(pctadw_emb_matr[index_graph['index'][test_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][test_pairs[i][1]], embed_dim:])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6962891669340178\n",
      "Recall: 0.6008674787744556\n",
      "Accuracy: 0.6693890734588409\n",
      "F1-macro: 0.667829463386362\n",
      "F1-micro: 0.6693890734588409\n",
      "Logloss: 11.419001648497453\n",
      "ROC-AUC: 0.6693890734588409\n"
     ]
    }
   ],
   "source": [
    "# new train/test\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6854469643038748\n",
      "Recall: 0.588646288209607\n",
      "Accuracy: 0.6592576419213974\n",
      "F1-macro: 0.6575501997947237\n",
      "F1-micro: 0.6592576419213974\n",
      "Logloss: 11.768932111979895\n",
      "ROC-AUC: 0.6592576419213975\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.73      0.68     11450\n",
      "          1       0.69      0.59      0.63     11450\n",
      "\n",
      "avg / total       0.66      0.66      0.66     22900\n",
      "\n",
      "[[8357 3093]\n",
      " [4710 6740]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(pctadw_emb_matr[index_graph['index'][train_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][train_pairs[i][1]], embed_dim:])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(pctadw_emb_matr[index_graph['index'][test_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][test_pairs[i][1]], embed_dim:])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6403202164843839\n",
      "Recall: 0.4959825327510917\n",
      "Accuracy: 0.6086899563318777\n",
      "F1-macro: 0.6036552029082989\n",
      "F1-micro: 0.6086899563318777\n",
      "Logloss: 13.515481484305544\n",
      "ROC-AUC: 0.6086899563318778\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.72      0.65     11450\n",
      "          1       0.64      0.50      0.56     11450\n",
      "\n",
      "avg / total       0.61      0.61      0.60     22900\n",
      "\n",
      "[[8260 3190]\n",
      " [5771 5679]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l1(pctadw_emb_matr[index_graph['index'][train_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][train_pairs[i][1]], embed_dim:])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l1(pctadw_emb_matr[index_graph['index'][test_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][test_pairs[i][1]], embed_dim:])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5673087387093264\n",
      "Recall: 0.4552838427947598\n",
      "Accuracy: 0.5540174672489083\n",
      "F1-macro: 0.5496270840728776\n",
      "F1-micro: 0.5540174672489083\n",
      "Logloss: 15.403829804393242\n",
      "ROC-AUC: 0.5540174672489083\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.65      0.59     11450\n",
      "          1       0.57      0.46      0.51     11450\n",
      "\n",
      "avg / total       0.56      0.55      0.55     22900\n",
      "\n",
      "[[7474 3976]\n",
      " [6237 5213]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l2(pctadw_emb_matr[index_graph['index'][train_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][train_pairs[i][1]], embed_dim:])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l2(pctadw_emb_matr[index_graph['index'][test_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][test_pairs[i][1]], embed_dim:])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5669017905588714\n",
      "Recall: 0.45624454148471616\n",
      "Accuracy: 0.5538427947598253\n",
      "F1-macro: 0.5495520896570568\n",
      "F1-micro: 0.5538427947598253\n",
      "Logloss: 15.409863302189796\n",
      "ROC-AUC: 0.5538427947598252\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.65      0.59     11450\n",
      "          1       0.57      0.46      0.51     11450\n",
      "\n",
      "avg / total       0.56      0.55      0.55     22900\n",
      "\n",
      "[[7459 3991]\n",
      " [6226 5224]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best result: Random Forest + product edge function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 links used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2004942559444296"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a54e15efd74a13a1157dbdb3921e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=59851), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13490\n",
      "Number of edges: 59851\n",
      "Average in degree:   4.4367\n",
      "Average out degree:   4.4367\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_03.csv', index=False)\n",
    "aan_train.to_csv('train_2013_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_03.csv')\n",
    "aan_train = pd.read_csv('train_2013_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0.5)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(pctadw_emb_matr[index_graph['index'][train_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][train_pairs[i][1]], embed_dim:])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(pctadw_emb_matr[index_graph['index'][test_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][test_pairs[i][1]], embed_dim:])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6908632928784062\n",
      "Recall: 0.6030381770937437\n",
      "Accuracy: 0.6666000399760144\n",
      "F1-macro: 0.6652476033324394\n",
      "F1-micro: 0.6666000399760144\n",
      "Logloss: 11.515334550265122\n",
      "ROC-AUC: 0.6666000399760145\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.73      0.69     15009\n",
      "          1       0.69      0.60      0.64     15009\n",
      "\n",
      "avg / total       0.67      0.67      0.67     30018\n",
      "\n",
      "[[10959  4050]\n",
      " [ 5958  9051]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2612343040341972"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f33d3e2a2214d72961d1ae23fcfc7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=55304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13489\n",
      "Number of edges: 55304\n",
      "Average in degree:   4.0999\n",
      "Average out degree:   4.0999\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_01.csv', index=False)\n",
    "aan_train.to_csv('train_2013_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0.5)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(pctadw_emb_matr[index_graph['index'][train_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][train_pairs[i][1]], embed_dim:])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(pctadw_emb_matr[index_graph['index'][test_pairs[i][0]], :embed_dim],\n",
    "                                    pctadw_emb_matr[index_graph['index'][test_pairs[i][1]], embed_dim:])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6968371680294099\n",
      "Recall: 0.5621804049907957\n",
      "Accuracy: 0.6588003681734506\n",
      "F1-macro: 0.6555851114697098\n",
      "F1-micro: 0.6588003681734506\n",
      "Logloss: 11.784715572320303\n",
      "ROC-AUC: 0.6588003681734507\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
