{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test, \\\n",
    "        precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, \\\n",
    "        f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, \\\n",
    "        roc_auc_train, roc_auc_test, logloss_train, logloss_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_links_connected = pd.read_csv('aan_links_connected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74860, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a66023fc1134c39b2f586bf2a2df0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74860), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13506\n",
      "Number of edges: 74860\n",
      "Average in degree:   5.5427\n",
      "Average out degree:   5.5427\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_links_connected.index):\n",
    "    G.add_edge(aan_links_connected.iloc[i]['citing'], aan_links_connected.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('G_aan_13506')\n",
    "G_train = nx.read_gpickle('G_aan_13506_train_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges(graph, count_gen_edges, part_neg_directed):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    edges = list(graph.edges())\n",
    "\n",
    "    count_neg_directed = int(part_neg_directed*count_gen_edges)\n",
    "    for a, b in edges:\n",
    "        if len(negative_edges) >= count_neg_directed:\n",
    "            break\n",
    "        if not graph.has_edge(b, a):\n",
    "            negative_edges.add((b, a))       \n",
    "    \n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if (i != j) and not graph.has_edge(nodes[i], nodes[j]):\n",
    "            negative_edges.add((nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_edges_test(graph, test_nodes, count_gen_edges):\n",
    "    negative_edges = set()\n",
    "    nodes = list(graph.nodes())\n",
    "    while len(negative_edges) < count_gen_edges:\n",
    "        i = random.randint(0, len(test_nodes) - 1)\n",
    "        j = random.randint(0, len(nodes) - 1)\n",
    "        if i == j:\n",
    "            continue\n",
    "        if graph.has_edge(test_nodes[i], nodes[j]):\n",
    "            continue\n",
    "        negative_edges.add((test_nodes[i], nodes[j]))\n",
    "    return list(negative_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_time(links_df, meta_df):\n",
    "    years = meta_df[['id','year']]\n",
    "    years.columns = ['citing', 'year_citing']\n",
    "    links_df = links_df.merge(years, how = 'left', on = 'citing')\n",
    "    years.columns = ['cited', 'year_cited']\n",
    "    links_df = links_df.merge(years, how='left', on = 'cited')\n",
    "    links_df['out_cites_count'] = links_df.groupby('citing')['cited'].transform(lambda x: x.count())\n",
    "    links_df['in_cites_count'] = links_df.groupby('cited')['citing'].transform(lambda x: x.count())\n",
    "    links_df['cite_rank'] = links_df.groupby('citing')['cited'].transform(lambda x: x.rank())\n",
    "    return links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(links_years_df, year, part=None):\n",
    "    \"\"\"\n",
    "    links_years_df - cite edges dataframe with year of citing paper\n",
    "    year - first year of test period\n",
    "    part - part of test period edges to include into train\"\"\"\n",
    "    if part:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)|\\\n",
    "                               ((links_years_df.year_citing >= year)&\\\n",
    "                                ((links_years_df.cite_rank < part*links_years_df.out_cites_count + 1)|\\\n",
    "                                (links_years_df.in_cites_count == 1)))]\n",
    "        test = links_years_df[((links_years_df.year_citing >= year)&\\\n",
    "                                (links_years_df.cite_rank >= part*links_years_df.out_cites_count + 1)&\\\n",
    "                              (links_years_df.in_cites_count != 1))]\n",
    "    else:\n",
    "        train = links_years_df[(links_years_df.year_citing < year)]\n",
    "        test = links_years_df[(links_years_df.year_citing >= year)]\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(u,v):\n",
    "    return u*v\n",
    "def mean(u,v):\n",
    "    return (u+v)/2\n",
    "def l1(u,v):\n",
    "    return np.abs(u-v)\n",
    "def l2(u,v):\n",
    "    return (u-v)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>year_citing</th>\n",
       "      <th>year_cited</th>\n",
       "      <th>out_cites_count</th>\n",
       "      <th>in_cites_count</th>\n",
       "      <th>cite_rank</th>\n",
       "      <th>node_citing</th>\n",
       "      <th>node_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C08-3004</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2008</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D09-1141</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D12-1027</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2012</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06-1047</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H05-1110</td>\n",
       "      <td>A00-1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     citing     cited  year_citing  year_cited  out_cites_count  \\\n",
       "0  C08-3004  A00-1002         2008        2000                1   \n",
       "1  D09-1141  A00-1002         2009        2000               14   \n",
       "2  D12-1027  A00-1002         2012        2000               14   \n",
       "3  E06-1047  A00-1002         2006        2000                4   \n",
       "4  H05-1110  A00-1002         2005        2000                2   \n",
       "\n",
       "   in_cites_count  cite_rank  node_citing  node_cited  \n",
       "0              10        1.0          560           0  \n",
       "1              10        1.0         1682           0  \n",
       "2              10        1.0         1995           0  \n",
       "3              10        1.0         2562           0  \n",
       "4              10        1.0         3150           0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan_links_connected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 links for test nodes ( > 2013) used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_05.csv', index=False)\n",
    "aan_train.to_csv('train_2013_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_05.csv')\n",
    "aan_train = pd.read_csv('train_2013_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_05_no_isolated.csv')\n",
    "aan_train = pd.read_csv('train_2013_05_no_isolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14475020037403152"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49dec3a452440b5b0b1cc7537580a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63410), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "# print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13493\n",
      "Number of edges: 64024\n",
      "Average in degree:   4.7450\n",
      "Average out degree:   4.7450\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_preprocess(positive_df, neg_list):\n",
    "    pairs = list(zip(list(positive_df['citing']), list(positive_df['cited']), [1]*len(positive_df)))\n",
    "    neg_pairs = list(zip(list(zip(*neg_list))[0],list(zip(*neg_list))[1], [0]*len(neg_list)))\n",
    "    pairs += neg_pairs\n",
    "    random.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aan_node2vec_128_pq4.txt', 'r') as f:\n",
    "    n2v_emb = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_emb = [(emb.split()[0],np.array([float(num) for num in emb.split()[1:]])) for emb in n2v_emb.split('\\n')[1:] if emb != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13506"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n2v_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P11-2069', 'W13-1715', 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_dict = dict(n2v_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02412121, -0.01680263,  0.03892118,  0.02126633, -0.03291467,\n",
       "        0.01908346, -0.01083011,  0.001769  ,  0.01433998, -0.04676037,\n",
       "       -0.06441756,  0.00492129,  0.01265838, -0.02210326,  0.02850015,\n",
       "       -0.08230983,  0.05349142,  0.02193242,  0.01935636,  0.01810938,\n",
       "       -0.00658814,  0.01739219, -0.01938708,  0.00232244, -0.00019859,\n",
       "        0.03019859,  0.01274948, -0.0202236 ,  0.02031925,  0.03294629,\n",
       "       -0.01076858, -0.02412132, -0.03906479,  0.06376281,  0.07908904,\n",
       "       -0.0249356 , -0.00804732, -0.04933048,  0.0073052 ,  0.01831379,\n",
       "       -0.0031514 ,  0.01841727, -0.02172787, -0.05733622,  0.03863462,\n",
       "        0.00191617, -0.00265193, -0.02926864, -0.00222213,  0.01306296,\n",
       "       -0.00373002, -0.0259631 ,  0.03665261,  0.00354773, -0.00531284,\n",
       "        0.0129802 , -0.0552841 ,  0.02216919, -0.08386905,  0.03618599,\n",
       "        0.01265107, -0.02113252, -0.03763052, -0.06579472,  0.04618946,\n",
       "        0.02085893,  0.00604036,  0.00811745, -0.05084214,  0.01655792,\n",
       "       -0.01109759,  0.01433323, -0.03398513, -0.00455006,  0.049987  ,\n",
       "       -0.00701197, -0.04191606,  0.05438249,  0.03890372,  0.04428019,\n",
       "       -0.00300216,  0.055957  , -0.03212193,  0.01987663,  0.02392355,\n",
       "        0.0817501 , -0.02267518,  0.03942741, -0.05648383, -0.04515167,\n",
       "       -0.00217393, -0.0437448 , -0.00772151,  0.04641479, -0.01661194,\n",
       "        0.01526774, -0.000575  ,  0.02001791, -0.03608226,  0.04158638,\n",
       "       -0.00492   ,  0.04187258,  0.05857589,  0.00366282, -0.0008684 ,\n",
       "       -0.00963522,  0.0591892 , -0.01887307, -0.04449475,  0.07152546,\n",
       "       -0.02135446,  0.00917506,  0.01325369,  0.02210227, -0.01104829,\n",
       "       -0.01268284,  0.00344737, -0.03387425,  0.00278945, -0.00217738,\n",
       "        0.00380149,  0.05767173, -0.02641199,  0.01595022,  0.02277546,\n",
       "        0.00931728, -0.03791632,  0.03870646])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2v_dict['P11-2069']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('n2v_pq4_128.pkl', 'wb') as f:\n",
    "    pickle.dump(n2v_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./asymproj_edge_dnn-master/datasets/aan_graph/index.pkl', 'rb') as f:\n",
    "    index_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5896"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_graph['index'][train_pairs[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean edge aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = mean(n2v_dict[train_pairs[i][0]],\n",
    "                                    n2v_dict[train_pairs[i][1]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = mean(n2v_dict[test_pairs[i][0]],\n",
    "                                    n2v_dict[test_pairs[i][1]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8014227334645073\n",
      "Recall: 0.48864894795127356\n",
      "Accuracy: 0.6837855297157622\n",
      "F1-macro: 0.6712679779116432\n",
      "F1-micro: 0.6837855297157622\n",
      "Logloss: 10.921709288766674\n",
      "ROC-AUC: 0.6837855297157622\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.88      0.74     10836\n",
      "          1       0.80      0.49      0.61     10836\n",
      "\n",
      "avg / total       0.72      0.68      0.67     21672\n",
      "\n",
      "[[9524 1312]\n",
      " [5541 5295]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(n2v_dict[train_pairs[i][0]],\n",
    "                                    n2v_dict[train_pairs[i][1]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(n2v_dict[test_pairs[i][0]],\n",
    "                                    n2v_dict[test_pairs[i][1]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8284247092584202\n",
      "Recall: 0.5061830933923958\n",
      "Accuracy: 0.7006736803248431\n",
      "F1-macro: 0.6889060578185546\n",
      "F1-micro: 0.7006736803248431\n",
      "Logloss: 10.338406737563046\n",
      "ROC-AUC: 0.7006736803248431\n"
     ]
    }
   ],
   "source": [
    "# new train/test, no isolated\n",
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.90      0.75     10836\n",
      "          1       0.83      0.51      0.63     10836\n",
      "\n",
      "avg / total       0.74      0.70      0.69     21672\n",
      "\n",
      "[[9700 1136]\n",
      " [5351 5485]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l1(n2v_dict[train_pairs[i][0]],\n",
    "                                    n2v_dict[train_pairs[i][1]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l1(n2v_dict[test_pairs[i][0]],\n",
    "                                    n2v_dict[test_pairs[i][1]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7560429722470904\n",
      "Recall: 0.4676079734219269\n",
      "Accuracy: 0.6583610188261351\n",
      "F1-macro: 0.6454604873135743\n",
      "F1-micro: 0.6583610188261351\n",
      "Logloss: 11.799852702552466\n",
      "ROC-AUC: 0.6583610188261352\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.95      0.84     11450\n",
      "          1       0.93      0.71      0.80     11450\n",
      "\n",
      "avg / total       0.85      0.83      0.82     22900\n",
      "\n",
      "[[10823   627]\n",
      " [ 3359  8091]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = l2(n2v_dict[train_pairs[i][0]],\n",
    "                                    n2v_dict[train_pairs[i][1]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = l2(n2v_dict[test_pairs[i][0]],\n",
    "                                    n2v_dict[test_pairs[i][1]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7546634830622295\n",
      "Recall: 0.4666851236618679\n",
      "Accuracy: 0.657484311554079\n",
      "F1-macro: 0.6445441805673713\n",
      "F1-micro: 0.657484311554079\n",
      "Logloss: 11.83013343104454\n",
      "ROC-AUC: 0.6574843115540789\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.85      0.71     10836\n",
      "          1       0.75      0.47      0.58     10836\n",
      "\n",
      "avg / total       0.68      0.66      0.64     21672\n",
      "\n",
      "[[9192 1644]\n",
      " [5779 5057]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best result: Random Forest + product edge function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 links used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2004942559444296"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f673400aa4041ee955449f54b1b0dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=59851), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13490\n",
      "Number of edges: 59851\n",
      "Average in degree:   4.4367\n",
      "Average out degree:   4.4367\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_03.csv', index=False)\n",
    "aan_train.to_csv('train_2013_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test = pd.read_csv('test_2013_03.csv')\n",
    "aan_train = pd.read_csv('train_2013_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(n2v_dict[train_pairs[i][0]],\n",
    "                                    n2v_dict[train_pairs[i][1]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(n2v_dict[test_pairs[i][0]],\n",
    "                                    n2v_dict[test_pairs[i][1]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8387206532834297\n",
      "Recall: 0.49270437737357586\n",
      "Accuracy: 0.6989806116330202\n",
      "F1-macro: 0.6856030579614383\n",
      "F1-micro: 0.6989806116330202\n",
      "Logloss: 10.39687922353117\n",
      "ROC-AUC: 0.6989806116330202\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.91      0.75     15009\n",
      "          1       0.84      0.49      0.62     15009\n",
      "\n",
      "avg / total       0.74      0.70      0.69     30018\n",
      "\n",
      "[[13587  1422]\n",
      " [ 7614  7395]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train, aan_test = train_test_split_by_year(aan_links_connected, 2013, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2612343040341972"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aan_test)/(len(aan_links_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c935ebb71d4e32aeceaf1c58e89107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=55304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 13489\n",
      "Number of edges: 55304\n",
      "Average in degree:   4.0999\n",
      "Average out degree:   4.0999\n"
     ]
    }
   ],
   "source": [
    "G_train = nx.DiGraph()\n",
    "\n",
    "for i in tqdm_notebook(aan_train.index):\n",
    "    G_train.add_edge(aan_train.iloc[i]['citing'], aan_train.iloc[i]['cited'])\n",
    "    \n",
    "print(nx.info(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_test.to_csv('test_2013_01.csv', index=False)\n",
    "aan_train.to_csv('train_2013_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_train_neg = generate_negative_edges(G_train, len(G_train.edges()), 0)\n",
    "aan_test_neg = generate_negative_edges_test(G, list(aan_test['citing']), len(aan_test))\n",
    "\n",
    "train_pairs = train_test_preprocess(aan_train, aan_train_neg)\n",
    "test_pairs = train_test_preprocess(aan_test, aan_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "k_train = 0\n",
    "k_test = 0\n",
    "\n",
    "X_train = np.zeros((len(train_pairs), embed_dim))\n",
    "for i in range(len(train_pairs)):\n",
    "    try:\n",
    "        X_train[i] = product(n2v_dict[train_pairs[i][0]],\n",
    "                                    n2v_dict[train_pairs[i][1]])\n",
    "    except KeyError:\n",
    "        k_train += 1\n",
    "        pass\n",
    "y_train = np.array(list(zip(*(train_pairs)))[-1])\n",
    "\n",
    "X_test = np.zeros((len(test_pairs), embed_dim))\n",
    "for i in range(len(test_pairs)):\n",
    "    try:\n",
    "        X_test[i] = product(n2v_dict[test_pairs[i][0]],\n",
    "                                    n2v_dict[test_pairs[i][1]])    \n",
    "    except:\n",
    "        k_test += 1\n",
    "        pass\n",
    "y_test = np.array(list(zip(*(test_pairs)))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "rand_forest, y_pred_train, y_pred_test, precision_train, precision_test, recall_train, recall_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, roc_auc_train, roc_auc_test, logloss_train, logloss_test = \\\n",
    "classify_model(rand_forest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.844543811245362\n",
      "Recall: 0.4539271834731029\n",
      "Accuracy: 0.6851861321333607\n",
      "F1-macro: 0.6673983633394358\n",
      "F1-micro: 0.6851861321333607\n",
      "Logloss: 10.873319193412154\n",
      "ROC-AUC: 0.6851861321333607\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ' + str(precision_test))\n",
    "print('Recall: ' + str(recall_test))\n",
    "print('Accuracy: ' + str(accuracy_test))\n",
    "print('F1-macro: ' + str(f1_macro_test))\n",
    "print('F1-micro: ' + str(f1_micro_test))\n",
    "print('Logloss: ' + str(logloss_test))\n",
    "print('ROC-AUC: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv = np.power(rowsum.astype(float), -1).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    return d_mat_inv.dot(adj).tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.array([[1,1,0,0],\n",
    "            [1,1,0,0],\n",
    "            [0,0,1,0],\n",
    "             [0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in power\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "norm = normalize_adj(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5, 0.5, 0. , 0. ],\n",
       "        [0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0. , 1. , 0. ],\n",
       "        [0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.coo_matrix(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x4 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 5 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsum = np.array(adj.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsum.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in power\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_inv = np.power(rowsum.astype(float), -1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 1. , inf])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_inv[np.isinf(d_inv)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 1. , 0. ])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mat_inv = sp.diags(d_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements (1 diagonals) in DIAgonal format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mat_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5, 0.5, 0. , 0. ],\n",
       "        [0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0. , 1. , 0. ],\n",
       "        [0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mat_inv.dot(adj).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5, 0.5, 0. , 0. ],\n",
       "        [0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0. , 1. , 0. ],\n",
       "        [0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.dot(d_mat_inv).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D^(-1)*A instead of D^(-1/2)*A*D^(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57735027, 0.70710678, 0.70710678, 0.57735027])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = rowsum.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
